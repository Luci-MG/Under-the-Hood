{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Under the Hood","text":"<p>Welcome to Deep Dives by MG</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#coming-soon","title":"Coming soon","text":""},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#under-the-hood-by-mrudhul-guda","title":"Under the Hood by Mrudhul Guda","text":""},{"location":"changelog/#0.4.0","title":"0.4.0 November 16, 2024","text":"<ul> <li>Redesigned the Home Page and Site</li> </ul>"},{"location":"changelog/#0.3.0","title":"0.3.0 November 12, 2024","text":"<ul> <li>Added Header and footer features</li> </ul>"},{"location":"changelog/#0.2.0","title":"0.2.0 November 9, 2024","text":"<ul> <li>Added Dark/Light mode, search features</li> </ul>"},{"location":"changelog/#0.1.0","title":"0.1.0 November 5, 2024","text":"<ul> <li>Initial release</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/","title":"Abstract Factory","text":""},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/#what","title":"What ?","text":"<p>The Abstract Factory Pattern is a creational design pattern that provides an interface for creating families of related or dependent objects without specifying their concrete classes. It promotes loose coupling between client code and the actual implementations, allowing the code to be more flexible and scalable.</p> <p>The Abstract Factory pattern works as a super-factory that creates other factories. Each factory produced by the abstract factory is responsible for creating a family of related objects.</p> <p>Key Characteristics</p> <ul> <li>Encapsulates the creation logic of families of related objects.</li> <li>Supports product families (like buttons and scrollbars for different OS themes).</li> <li>Makes the system open for extension but closed for modification (Open-Closed Principle).</li> <li>Clients interact with the factory interface instead of the concrete classes.</li> </ul> <p>Class Diagram</p> <pre><code>AbstractFactory\n\u251c\u2500\u2500 createProductA()\n\u2514\u2500\u2500 createProductB()\n\nConcreteFactory1 \u2500\u2500\u2500\u2500&gt; ProductA1, ProductB1\nConcreteFactory2 \u2500\u2500\u2500\u2500&gt; ProductA2, ProductB2\n\nClient \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt; AbstractFactory, AbstractProduct\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/#when-to-use","title":"When to Use ?","text":"<ul> <li>When your application needs to create a family of related objects (e.g., GUI components for themes, or different database connections).</li> <li>When the code should be decoupled from the actual product classes.</li> <li>If you need to switch between different configurations (e.g., Light vs Dark theme).</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/#advantages","title":"Advantages","text":"<ul> <li>Abstract factories make it easy to reuse code across product families.</li> <li>Supports the Open/Closed Principle you can introduce new product families without modifying existing code.</li> <li>Encourages Loose Coupling reduces dependencies between client code and the actual implementation of products.</li> <li>Easy Maintenance since product creation logic is centralized, maintenance is simpler.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/#disadvantages","title":"Disadvantages","text":"<ul> <li>The pattern introduces multiple classes and interfaces, which can make the design more complex.</li> <li>If there are too many products or product families, maintaining multiple factories may become cumbersome.</li> <li>For simple object creation tasks, other patterns like Factory Method or just using constructors may be more suitable.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/#how-to-implement","title":"How to Implement ?","text":"Simple Example <p>Let\u2019s go with an example Imagine you are creating a UI component factory. Your application can switch between two themes: Dark Theme and Light Theme. Both themes provide the same types of components (buttons, text fields) but with different appearances.</p> Step-1: Define the Abstract Products<pre><code>// Abstract Product: Button\npublic interface Button {\n    void render();\n}\n\n// Abstract Product: TextField\npublic interface TextField {\n    void render();\n}\n</code></pre> Step-2: Create Concrete Products<pre><code>// Concrete Product: Light Button\npublic class LightButton implements Button {\n    @Override\n    public void render() {\n        System.out.println(\"Rendering a Light Button\");\n    }\n}\n\n// Concrete Product: Dark Button\npublic class DarkButton implements Button {\n    @Override\n    public void render() {\n        System.out.println(\"Rendering a Dark Button\");\n    }\n}\n\n// Concrete Product: Light TextField\npublic class LightTextField implements TextField {\n    @Override\n    public void render() {\n        System.out.println(\"Rendering a Light Text Field\");\n    }\n}\n\n// Concrete Product: Dark TextField\npublic class DarkTextField implements TextField {\n    @Override\n    public void render() {\n        System.out.println(\"Rendering a Dark Text Field\");\n    }\n</code></pre> Step-3:  Define the Abstract Factory Interface<pre><code>public interface UIFactory {\n    Button createButton();\n    TextField createTextField();\n}\n</code></pre> Step-4: Implement Concrete Factories<pre><code>// Concrete Factory for Light Theme\npublic class LightUIFactory implements UIFactory {\n    @Override\n    public Button createButton() {\n        return new LightButton();\n    }\n\n    @Override\n    public TextField createTextField() {\n        return new LightTextField();\n    }\n}\n\n// Concrete Factory for Dark Theme\npublic class DarkUIFactory implements UIFactory {\n    @Override\n    public Button createButton() {\n        return new DarkButton();\n    }\n\n    @Override\n    public TextField createTextField() {\n        return new DarkTextField();\n    }\n}\n</code></pre> Step-5: Using the Abstract Factory in a Client<pre><code>public class Application {\n    private Button button;\n    private TextField textField;\n\n    public Application(UIFactory factory) {\n        this.button = factory.createButton();\n        this.textField = factory.createTextField();\n    }\n\n    public void renderUI() {\n        button.render();\n        textField.render();\n    }\n\n    public static void main(String[] args) {\n        // Client can choose between different factories.\n        UIFactory factory = new DarkUIFactory(); // Could be switched to LightUIFactory\n        Application app = new Application(factory);\n        app.renderUI();\n    }\n}\n</code></pre> <p>Output: <pre><code>Rendering a Dark Button\nRendering a Dark Text Field\n</code></pre></p> Spring Boot Example <p>In Spring Boot, the Abstract Factory pattern can complement dependency injection (DI) by delegating object creation logic to the factory. Here\u2019s how to implement it with Spring Boot.</p> Step-1: Define Factory Beans<pre><code>@Configuration\npublic class UIFactoryConfig {\n\n    @Bean\n    public UIFactory uiFactory(@Value(\"${app.theme}\") String theme) {\n        if (\"dark\".equalsIgnoreCase(theme)) {\n            return new DarkUIFactory();\n        } else {\n            return new LightUIFactory();\n        }\n    }\n}\n</code></pre> Step-2: Use the Factory in a Controller<pre><code>@RestController\n@RequestMapping(\"/ui\")\npublic class UIController {\n\n    private final UIFactory uiFactory;\n\n    @Autowired\n    public UIController(UIFactory uiFactory) {\n        this.uiFactory = uiFactory;\n    }\n\n    @GetMapping(\"/render\")\n    public void renderUI() {\n        Button button = uiFactory.createButton();\n        TextField textField = uiFactory.createTextField();\n\n        button.render();\n        textField.render();\n    }\n}\n</code></pre> Step-3: Configure Application Properties<pre><code># application.properties\napp.theme=dark\n</code></pre> <p>In this example, the theme is configured through the <code>application.properties</code> file, and the factory selection is handled by the Spring context.</p>"},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/#factory-method-comparison","title":"Factory Method Comparison","text":"Aspect Factory Method Abstract Factory Purpose Create one type of product. Create families of related products. Complexity Less complex. More complex, involves multiple classes. Client Knowledge Client knows about individual products. Client works with factories, not specific products. Usage Simple use-cases. Complex, multi-product scenarios."},{"location":"fundamentaldives/DesignPatterns/AbstractFactory/#summary","title":"Summary","text":"<p>The Abstract Factory Pattern is a powerful tool when designing systems that need to create multiple families of related objects. While it adds complexity, the benefits include extensibility, maintainability, and loose coupling. In a Spring Boot application, it works well alongside dependency injection, especially when configurations like themes or environments vary.</p>"},{"location":"fundamentaldives/DesignPatterns/Adapter/","title":"Adapter Design Pattern","text":""},{"location":"fundamentaldives/DesignPatterns/Adapter/#what","title":"What ?","text":"<p>The Adapter Pattern is a structural design pattern in software development that allows objects with incompatible interfaces to work together. It acts as a bridge between two incompatible interfaces, providing a wrapper or a mediator to enable their interaction without changing their existing code.</p> <p>This Pattern converts the interface of a class into another interface that a client expects. This helps integrate two systems with different interfaces so they can work together without altering their code. It is often used when a legacy system needs to be integrated with new components or when third-party APIs are integrated into an existing codebase.</p> <p>Analogy</p> <p>Think of a power plug adapter You have an appliance with a US plug (two flat pins), but you need to connect it to a European socket (two round holes). The adapter ensures that both the incompatible interfaces (US and European plugs) work together without modifying either.</p>"},{"location":"fundamentaldives/DesignPatterns/Adapter/#when-to-use","title":"When to Use ?","text":"<ul> <li>When two interfaces are incompatible but need to work together.</li> <li>When a legacy system needs to integrate with new components.</li> <li>When using third-party libraries or APIs that do not conform to your existing codebase\u2019s interfaces.</li> <li>When you want to reuse an existing class, but its interface is not compatible.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Adapter/#when-not-to-use","title":"When Not to Use ?","text":"<ul> <li>When you have control over the original code (you can modify the existing class).</li> <li>If using the Adapter Pattern makes your design too complex (consider refactoring).</li> <li>If the Adapter adds unnecessary overhead in performance-sensitive environments.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Adapter/#ways-to-implement","title":"Ways to Implement","text":"Simple Example <p>There are two common ways to implement the Adapter Pattern:</p> <ol> <li>Class Adapter (Inheritance-based)</li> <li>Object Adapter (Composition-based)</li> </ol> Class Adapter Pattern (via Inheritance) <p>In this approach, the adapter class extends the adaptee (the class that has the incompatible interface) and implements the interface that the client expects.</p> Class Adapter Java Example<pre><code>// Target Interface - The desired interface that client expects\ninterface MediaPlayer {\n    void play(String audioType, String fileName);\n}\n\n// Adaptee - Incompatible interface that needs adaptation\nclass AdvancedMediaPlayer {\n    void playMp3(String fileName) {\n        System.out.println(\"Playing mp3 file: \" + fileName);\n    }\n\n    void playMp4(String fileName) {\n        System.out.println(\"Playing mp4 file: \" + fileName);\n    }\n}\n\n// Class Adapter - Adapts AdvancedMediaPlayer to MediaPlayer\nclass MediaAdapter extends AdvancedMediaPlayer implements MediaPlayer {\n    @Override\n    public void play(String audioType, String fileName) {\n        if (audioType.equalsIgnoreCase(\"mp3\")) {\n            playMp3(fileName);\n        } else if (audioType.equalsIgnoreCase(\"mp4\")) {\n            playMp4(fileName);\n        }\n    }\n}\n\n// Client Code\npublic class AudioPlayer {\n    public static void main(String[] args) {\n        MediaPlayer player = new MediaAdapter();\n        player.play(\"mp3\", \"song.mp3\");\n        player.play(\"mp4\", \"video.mp4\");\n    }\n}\n</code></pre> Explanation <p><code>MediaAdapter</code> extends <code>AdvancedMediaPlayer</code> (inheriting the original functionality) and implements the <code>MediaPlayer</code> interface (adapting it to what the client expects).</p> Object Adapter Pattern (via Composition) <p>In this approach, the adapter contains an instance of the adaptee class and delegates calls to the appropriate methods.</p> Object Adapter Java Example<pre><code>// Target Interface\ninterface MediaPlayer {\n    void play(String audioType, String fileName);\n}\n\n// Adaptee\nclass AdvancedMediaPlayer {\n    void playMp3(String fileName) {\n        System.out.println(\"Playing mp3 file: \" + fileName);\n    }\n\n    void playMp4(String fileName) {\n        System.out.println(\"Playing mp4 file: \" + fileName);\n    }\n}\n\n// Object Adapter\nclass MediaAdapter implements MediaPlayer {\n    private AdvancedMediaPlayer advancedPlayer;\n\n    public MediaAdapter(AdvancedMediaPlayer advancedPlayer) {\n        this.advancedPlayer = advancedPlayer;\n    }\n\n    @Override\n    public void play(String audioType, String fileName) {\n        if (audioType.equalsIgnoreCase(\"mp3\")) {\n            advancedPlayer.playMp3(fileName);\n        } else if (audioType.equalsIgnoreCase(\"mp4\")) {\n            advancedPlayer.playMp4(fileName);\n        }\n    }\n}\n\n// Client Code\npublic class AudioPlayer {\n    public static void main(String[] args) {\n        AdvancedMediaPlayer advancedPlayer = new AdvancedMediaPlayer();\n        MediaPlayer adapter = new MediaAdapter(advancedPlayer);\n        adapter.play(\"mp3\", \"song.mp3\");\n        adapter.play(\"mp4\", \"video.mp4\");\n    }\n}\n</code></pre> Explanation <p>In this version, <code>MediaAdapter</code> holds a reference to the <code>AdvancedMediaPlayer</code> instance and delegates method calls instead of extending the class.</p> Spring Boot Example <p>In a Spring Boot context, the Adapter Pattern can be used to integrate an external or legacy service with your application's service layer.</p> Integrating a Legacy Payment Service<pre><code>// Legacy Payment Service - Adaptee\nclass LegacyPaymentService {\n    public void payWithCreditCard(String cardNumber) {\n        System.out.println(\"Payment made using Legacy Credit Card: \" + cardNumber);\n    }\n}\n\n// Target Interface\ninterface PaymentService {\n    void processPayment(String cardNumber);\n}\n\n// Adapter Implementation - Integrating LegacyPaymentService with PaymentService\n@Component\nclass PaymentServiceAdapter implements PaymentService {\n    private final LegacyPaymentService legacyService;\n\n    // Constructor injection\n    public PaymentServiceAdapter(LegacyPaymentService legacyService) {\n        this.legacyService = legacyService;\n    }\n\n    @Override\n    public void processPayment(String cardNumber) {\n        legacyService.payWithCreditCard(cardNumber);\n    }\n}\n\n// Spring Boot Controller\n@RestController\n@RequestMapping(\"/payments\")\npublic class PaymentController {\n\n    private final PaymentService paymentService;\n\n    @Autowired\n    public PaymentController(PaymentService paymentService) {\n        this.paymentService = paymentService;\n    }\n\n    @PostMapping\n    public String makePayment(@RequestParam String cardNumber) {\n        paymentService.processPayment(cardNumber);\n        return \"Payment Successful\";\n    }\n}\n</code></pre> Explanation <ul> <li><code>LegacyPaymentService</code> is an old service with an incompatible method.</li> <li><code>PaymentServiceAdapter</code> acts as an adapter by implementing the <code>PaymentService</code> interface and internally calling the legacy service.</li> <li>The <code>PaymentController</code> depends on <code>PaymentService</code>, which can now work seamlessly with the legacy system.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Adapter/#summary","title":"Summary","text":"<p>The Adapter Pattern enhances flexibility by decoupling client code from specific implementations, promotes reusability by enabling compatibility between systems, improves maintainability by isolating legacy or third-party code, and simplifies testing through easy mock or stub usage.</p>"},{"location":"fundamentaldives/DesignPatterns/Bridge/","title":"Bridge","text":""},{"location":"fundamentaldives/DesignPatterns/Bridge/#what","title":"What ?","text":"<p>The Bridge Pattern is a structural design pattern that helps to decouple an abstraction from its implementation so that both can vary independently. This pattern is especially useful when you need to manage complex class hierarchies or have multiple dimensions of variations.</p> <p>When both the abstraction (interface) and its implementation (how it works internally) need to evolve, the code becomes complex and hard to manage. Bridge helps to separate these concerns. The pattern separates the abstraction (interface) from the actual implementation and lets them evolve independently by delegating the concrete work to another interface.</p>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#structure","title":"Structure ?","text":"<p>The structure involves two key parts:</p> <ul> <li>Abstraction: Defines the interface (or abstract class) which client code uses.</li> <li>Implementor: The actual implementations are defined through composition, not inheritance.</li> </ul> <p>The Abstraction contains a reference to the Implementor (interface or class). This lets the abstraction delegate the implementation details to the concrete implementations.</p> <p>Class Diagram</p> <ul> <li>Abstraction: This is an abstract class or interface that defines the methods implemented by Refined Abstraction.</li> <li>Implementor: This is an interface or abstract class that defines the implementation methods.</li> <li>Refined Abstraction: A concrete class that extends the Abstraction.</li> <li>Concrete Implementor: A concrete class that implements the Implementor interface.</li> </ul> <pre><code>Abstraction --&gt; Implementor\n    |                |\nRefinedAbstraction   ConcreteImplementor\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#when-to-use","title":"When to Use ?","text":"<ul> <li>When your class needs to support multiple variations along two or more dimensions (like different types of shapes on different platforms).</li> <li>When you want to decouple the abstraction from its implementation so that both can evolve independently.</li> <li>If you have multiple variations, inheritance might lead to a combinatorial explosion of classes. For example, <code>CircleRed</code>, <code>CircleBlue</code>, <code>SquareRed</code>, <code>SquareBlue</code> this can be avoided with the Bridge pattern.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#where-not-to-use","title":"Where Not to Use ?","text":"<ul> <li>If the system has simple inheritance hierarchies where variations don\u2019t overlap, the added complexity of Bridge isn\u2019t necessary.</li> <li>If abstraction and implementation are unlikely to change, simpler patterns (like inheritance) might be more suitable.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#advantages","title":"Advantages","text":"<ul> <li>Improved Flexibility as Abstraction and implementation can vary independently.</li> <li>Reduced Code Duplication Avoids combinatorial explosion of subclasses.</li> <li>Easier to Extend as You can add new implementations or abstractions without affecting existing code.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#disadvantages","title":"Disadvantages","text":"<ul> <li>Separating abstraction from implementation can introduce additional complexity.</li> <li>You might end up writing more code to implement abstractions and concrete implementations.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#how-to-implement","title":"How to Implement ?","text":"Simple Example <p>Let\u2019s look at a real-world example rendering shapes on different platforms. The rendering logic could vary depending on the platform (Windows, Linux, etc.), but the shape (e.g., Circle, Rectangle) stays the same.</p> Spring Boot Example <p>In a Spring Boot application, you can use the Bridge pattern to switch between different implementations of a service dynamically, such as switching between multiple ways of sending notifications (e.g., Email, SMS). This is helpful when services have multiple implementations, and you need to inject them dynamically without changing the client code.</p>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#rendering-shapes-on-different-platforms","title":"Rendering Shapes on Different Platforms","text":"Step-1: Define the Implementor interface<pre><code>interface Renderer {\n    void render(String shape);\n}\n</code></pre> Step-2: Create Concrete Implementor classes<pre><code>class VectorRenderer implements Renderer {\n    @Override\n    public void render(String shape) {\n        System.out.println(\"Rendering \" + shape + \" as vectors.\");\n    }\n}\n\nclass RasterRenderer implements Renderer {\n    @Override\n    public void render(String shape) {\n        System.out.println(\"Rendering \" + shape + \" as pixels.\");\n    }\n}\n</code></pre> Step-3: Define the Abstraction<pre><code>abstract class Shape {\n    protected Renderer renderer;\n\n    public Shape(Renderer renderer) {\n        this.renderer = renderer;\n    }\n\n    public abstract void draw();\n}\n</code></pre> Step-4: Create Refined Abstraction classes<pre><code>class Circle extends Shape {\n    public Circle(Renderer renderer) {\n        super(renderer);\n    }\n\n    @Override\n    public void draw() {\n        renderer.render(\"Circle\");\n    }\n}\n\nclass Rectangle extends Shape {\n    public Rectangle(Renderer renderer) {\n        super(renderer);\n    }\n\n    @Override\n    public void draw() {\n        renderer.render(\"Rectangle\");\n    }\n}\n</code></pre> Step-5: Client Code<pre><code>public class BridgePatternDemo {\n    public static void main(String[] args) {\n        Shape circle = new Circle(new VectorRenderer());\n        circle.draw(); // Output: Rendering Circle as vectors.\n\n        Shape rectangle = new Rectangle(new RasterRenderer());\n        rectangle.draw(); // Output: Rendering Rectangle as pixels.\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#notification-system-in-spring-boot","title":"Notification System in Spring Boot","text":"Step-1: Create the Implementor Interface (NotificationSender)<pre><code>public interface NotificationSender {\n    void send(String message);\n}\n</code></pre> Step-2. Implement Concrete Implementors (Email and SMS)<pre><code>@Component\npublic class EmailSender implements NotificationSender {\n    @Override\n    public void send(String message) {\n        System.out.println(\"Sending Email: \" + message);\n    }\n}\n\n@Component\npublic class SmsSender implements NotificationSender {\n    @Override\n    public void send(String message) {\n        System.out.println(\"Sending SMS: \" + message);\n    }\n}\n</code></pre> Step-3. Create the Abstraction (Notification)<pre><code>public abstract class Notification {\n    protected NotificationSender sender;\n\n    public Notification(NotificationSender sender) {\n        this.sender = sender;\n    }\n\n    public abstract void notify(String message);\n}\n</code></pre> Step-4. Create Refined Abstraction (UrgentNotification)<pre><code>@Component\npublic class UrgentNotification extends Notification {\n\n    @Autowired\n    public UrgentNotification(NotificationSender sender) {\n        super(sender);\n    }\n\n    @Override\n    public void notify(String message) {\n        System.out.println(\"Urgent Notification:\");\n        sender.send(message);\n    }\n}\n</code></pre> Step-5. Use the Bridge Pattern in a Controller<pre><code>@RestController\n@RequestMapping(\"/notifications\")\npublic class NotificationController {\n\n    private final UrgentNotification notification;\n\n    @Autowired\n    public NotificationController(UrgentNotification notification) {\n        this.notification = notification;\n    }\n\n    @PostMapping(\"/send\")\n    public String sendNotification(@RequestBody String message) {\n        notification.notify(message);\n        return \"Notification sent!\";\n    }\n}\n</code></pre> <p>In this example, the Bridge Pattern allows you to switch between different ways of sending notifications (email or SMS) without changing the client code (the <code>NotificationController</code>).</p>"},{"location":"fundamentaldives/DesignPatterns/Bridge/#summary","title":"Summary","text":"<p>The Bridge Pattern is an essential design pattern to consider when your class hierarchy is growing unmanageable due to multiple dimensions of variations. Use this pattern when you need to decouple abstraction from implementation and allow them to evolve independently, but avoid it when simpler solutions can suffice.</p>"},{"location":"fundamentaldives/DesignPatterns/Builder/","title":"Builder Design","text":""},{"location":"fundamentaldives/DesignPatterns/Builder/#what","title":"What ?","text":"<p>The Builder Pattern is a creational design pattern that allows the construction of complex objects step by step. It separates the construction process from the actual object, giving more control over the construction process.</p> <p>This Pattern simplifies the creation of complex objects with many optional fields by enabling incremental construction through method chaining, avoiding constructors with numerous parameters. It's ideal for objects requiring various configurations or optional parameters.</p>"},{"location":"fundamentaldives/DesignPatterns/Builder/#when-to-use","title":"When to Use ?","text":"<ul> <li>When the class has many fields (especially optional ones).</li> <li>When you want to avoid telescoping constructors (having constructors with increasing numbers of parameters).</li> <li>When an object must be immutable but needs complex construction logic.</li> <li>When you want to ensure a clear, readable way to build an object, rather than calling constructors directly.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Builder/#why-use","title":"Why Use ?","text":"<ul> <li>Improves Code Readability by avoiding large constructors by using chained methods.</li> <li>Enforces Immutability after construction, the built object can remain immutable.</li> <li>Increases Flexibility by supporting different configurations while keeping the same building logic.</li> <li>Clear Separation of Logic Like The construction logic stays in the builder, while the object remains a simple data container.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Builder/#where-not-to-use","title":"Where Not to Use ?","text":"<ul> <li>If the object is simple with only a few attributes, using a builder can overcomplicate things.</li> <li>When performance is critical\u2014since creating the builder involves some extra overhead (though minimal).</li> <li>If immutability is not necessary, simpler setter methods might suffice.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Builder/#advantages","title":"Advantages","text":"<ul> <li>Clear and readable object construction.</li> <li>Immutable Objects once built, the object cannot be modified.</li> <li>Flexible Object Creation supports optional parameters without overloading constructors.</li> <li>Easier Maintenance with new fields can be easily added without modifying existing constructors.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Builder/#how-to-implement","title":"How to Implement ?","text":"Simple Example <p>Below is a basic Java example demonstrating the pattern. Assume we need to build a <code>Car</code> object with several optional fields.</p> Simple Builder Implementation<pre><code>public class Car {\n    // Required fields\n    private final String make;\n    private final String model;\n\n    // Optional fields\n    private final String color;\n    private final int year;\n    private final boolean automatic;\n\n    // Private constructor accessible only through Builder\n    private Car(Builder builder) {\n        this.make = builder.make;\n        this.model = builder.model;\n        this.color = builder.color;\n        this.year = builder.year;\n        this.automatic = builder.automatic;\n    }\n\n    // Getters (optional, based on your needs)\n    public String getMake() { return make; }\n    public String getModel() { return model; }\n    public String getColor() { return color; }\n    public int getYear() { return year; }\n    public boolean isAutomatic() { return automatic; }\n\n    // Static inner Builder class\n    public static class Builder {\n        // Required fields\n        private final String make;\n        private final String model;\n\n        // Optional fields initialized to default values\n        private String color = \"White\";\n        private int year = 2020;\n        private boolean automatic = true;\n\n        // Builder constructor with required fields\n        public Builder(String make, String model) {\n            this.make = make;\n            this.model = model;\n        }\n\n        // Setter-like methods for optional fields, returning the builder object\n        public Builder color(String color) {\n            this.color = color;\n            return this;\n        }\n\n        public Builder year(int year) {\n            this.year = year;\n            return this;\n        }\n\n        public Builder automatic(boolean automatic) {\n            this.automatic = automatic;\n            return this;\n        }\n\n        // Build method to create the final Car object\n        public Car build() {\n            return new Car(this);\n        }\n    }\n\n    @Override\n    public String toString() {\n        return \"Car [make=\" + make + \", model=\" + model + \n            \", color=\" + color + \", year=\" + year + \n            \", automatic=\" + automatic + \"]\";\n    }\n}\n</code></pre> Usage of the Builder Pattern<pre><code>public class Main {\n    public static void main(String[] args) {\n        // Using the builder to create a Car object\n        Car car = new Car.Builder(\"Tesla\", \"Model S\")\n                            .color(\"Red\")\n                            .year(2023)\n                            .automatic(true)\n                            .build();\n\n        System.out.println(car);\n    }\n}\n</code></pre> <p>Output: <pre><code>Car [make=Tesla, model=Model S, color=Red, year=2023, automatic=true]\n</code></pre></p> Spring Boot Example <p>In Spring Boot, you often need to build objects like DTOs, configurations, or entities with complex structures. Using the Builder Pattern can make object construction more manageable, especially when working with REST APIs.</p> Using Builder Pattern for DTOs in Spring Boot<pre><code>// Let's assume a UserDTO object for API responses.\npublic class UserDTO {\n    private final String username;\n    private final String email;\n    private final String role;\n\n    private UserDTO(Builder builder) {\n        this.username = builder.username;\n        this.email = builder.email;\n        this.role = builder.role;\n    }\n\n    public static class Builder {\n        private String username;\n        private String email;\n        private String role;\n\n        public Builder username(String username) {\n            this.username = username;\n            return this;\n        }\n\n        public Builder email(String email) {\n            this.email = email;\n            return this;\n        }\n\n        public Builder role(String role) {\n            this.role = role;\n            return this;\n        }\n\n        public UserDTO build() {\n            return new UserDTO(this);\n        }\n    }\n}\n</code></pre> Controller Example with Builder Pattern in Spring Boot<pre><code>@RestController\n@RequestMapping(\"/api/users\")\npublic class UserController {\n\n    @GetMapping(\"/{id}\")\n    public UserDTO getUserById(@PathVariable Long id) {\n        // Simulate fetching user details from a database\n        return new UserDTO.Builder()\n                .username(\"johndoe\")\n                .email(\"john.doe@example.com\")\n                .role(\"ADMIN\")\n                .build();\n    }\n}\n</code></pre> <p>This approach ensures that the object returned from the API is constructed cleanly with only the necessary fields set.</p> Alternative Ways <p>Telescoping Constructors Multiple overloaded constructors for different parameter combinations but Not ideal for readability and maintainability.</p> <pre><code>public Car(String make, String model) { ... }\npublic Car(String make, String model, String color) { ... }\npublic Car(String make, String model, String color, int year) { ... }\n</code></pre> <p>Setter Methods Useful for mutable objects but doesn\u2019t guarantee immutability but less readable when constructing objects with many attributes.</p> <pre><code>Car car = new Car();\ncar.setMake(\"Tesla\");\ncar.setModel(\"Model S\");\ncar.setColor(\"Red\");\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/Builder/#summary","title":"Summary","text":"<p>The Builder Pattern is an elegant way to handle object creation, especially when dealing with many fields or optional parameters. It ensures code readability, immutability, and flexibility while avoiding the need for numerous constructors. However, it should be used only when necessary, as simple objects may not benefit from it.</p> <p>Note</p> <p>In Spring Boot, the Builder Pattern can be effectively used for creating DTOs and other complex objects, improving both code readability and maintenance. This pattern fits well when dealing with REST API responses or configuration settings, ensuring your objects are built in a clear, consistent manner.</p>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/","title":"Circuit Breakers","text":""},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#what","title":"What ?","text":"<p>A circuit breaker is a design pattern used to prevent cascading failures and manage service availability. If a service call repeatedly fails, the circuit breaker \"trips\" and prevents further attempts, allowing the system to recover gracefully. This pattern mimics the behavior of electrical circuit breakers.</p>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#why-is-it-needed","title":"Why is it Needed ?","text":"<ul> <li>Fault tolerance: Preventing cascading failures in microservices.</li> <li>Graceful degradation: Avoiding overloading failing services.</li> <li>Latency reduction: Avoid waiting indefinitely on unresponsive services.</li> <li>Network management: Protects against service exhaustion from too many retries.</li> </ul> <p>Real-world scenario</p> <p>If Service A depends on Service B but Service B becomes unavailable, Service A will receive failures continuously. A circuit breaker prevents Service A from overloading itself and Service B by failing fast.</p>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#types-of-circuit-breakers","title":"Types of Circuit Breakers","text":"<p>There are multiple models of circuit breakers to choose from depending on use case:</p> <p>Count-based Circuit Breaker     - Trips if a predefined number of failures occur, eg: If there are 3 consecutive failed requests, the breaker opens.</p> <p>Time-based Circuit Breaker     - Monitors failures within a window of time and trips if the failure threshold is met, eg: If 5 requests out of 10 fail within 1 minute, it opens.</p> <p>Sliding Window Circuit Breaker     - A rolling window of requests over time determines if the circuit trips, Useful when failure patterns are sporadic.</p>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#how-does-it-work","title":"How Does it Work?","text":"<p>The basic mechanics of a circuit breaker involve three states:</p> <p>Closed State </p> <ul> <li>All requests are passed through.</li> <li>If failures exceed the threshold, it trips to the Open state.</li> </ul> <p>Open State</p> <ul> <li>No requests are forwarded to the target service.</li> <li>Calls return a fallback response or error immediately.</li> </ul> <p>Half-Open State</p> <ul> <li>The breaker allows limited requests to check if the service has recovered.</li> <li>If requests succeed, it switches back to Closed. If not, it returns to Open.</li> </ul> <p>State Transition Flow</p> <pre><code>Closed -&gt; (failure threshold reached) -&gt; Open -&gt; (timeout) -&gt; Half-Open -&gt; (success) -&gt; Closed\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#use-cases","title":"Use Cases","text":"<ul> <li>E-commerce: Payment gateways failing temporarily switch to fallback payment options.</li> <li>Microservices: A microservice becomes unresponsive breaker prevents excessive load.</li> <li>API Gateways: Protect external APIs from crashing under heavy traffic.</li> <li>Circuit Breakers in UI: Stop retrying user requests that target a failing backend.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#implementation","title":"Implementation","text":"<p>Several popular libraries and frameworks make circuit breaker implementations simple. Below are code examples in Java and Python.</p> Java with Resilience4jPython with PyBreaker <pre><code>// Resilience4j is a library providing circuit breaker implementations.\nimport io.github.resilience4j.circuitbreaker.CircuitBreaker;\nimport io.github.resilience4j.circuitbreaker.CircuitBreakerConfig;\nimport io.github.resilience4j.circuitbreaker.CircuitBreakerRegistry;\n\nimport java.time.Duration;\n\npublic class Example {\n    public static void main(String[] args) {\n        // Configuration\n        CircuitBreakerConfig config = CircuitBreakerConfig.custom()\n            .failureRateThreshold(50)  // Open if 50% of requests fail\n            .waitDurationInOpenState(Duration.ofSeconds(5))  // Wait 5 seconds before Half-Open\n            .build();\n\n        CircuitBreakerRegistry registry = CircuitBreakerRegistry.of(config);\n        CircuitBreaker circuitBreaker = registry.circuitBreaker(\"myService\");\n\n        // Wrap a call in the circuit breaker\n        String response = circuitBreaker.executeSupplier(() -&gt; makeHttpRequest());\n\n        System.out.println(response);\n    }\n\n    private static String makeHttpRequest() {\n        // Simulate an HTTP request here\n        return \"Success!\";\n    }\n}\n</code></pre> <pre><code># PyBreaker is a library implementing the Circuit Breaker pattern for Python applications.\n\nfrom pybreaker import CircuitBreaker, CircuitBreakerError\nimport requests\n\n# Define a circuit breaker\nbreaker = CircuitBreaker(fail_max=3, reset_timeout=5)\n\n@breaker\ndef fetch_data(url):\n    response = requests.get(url)\n    if response.status_code != 200:\n        raise Exception(\"Service unavailable\")\n    return response.json()\n\ntry:\n    data = fetch_data('https://api.example.com/data')\n    print(data)\nexcept CircuitBreakerError:\n    print(\"Circuit is open. Service unavailable.\")\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#advanced-topics","title":"Advanced Topics","text":""},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#monitoring-and-metrics","title":"Monitoring and Metrics","text":"<p>Circuit breakers need to be monitored to ensure they perform correctly. You can integrate them with monitoring tools like Prometheus or Grafana. Many libraries offer hooks to capture metrics such as</p> <ul> <li>Failure rate</li> <li>Open/closed/half-open state transitions</li> <li>Request success/failure ratios</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#tuning-the-circuit-breaker","title":"Tuning the Circuit Breaker","text":"<ul> <li>Failure Threshold Set based on your service\u2019s tolerance.</li> <li>Open Timeout Define how long to wait before reattempting.</li> <li>Sliding Window Size Determines sensitivity to spikes in failures.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#testing-circuit-breakers","title":"Testing Circuit Breakers","text":"<ul> <li>Chaos Engineering tools like Gremlin or Simian Army.</li> <li>Manually disconnect network connections to force failures.</li> <li>Use mock services to test the transition between breaker states.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/CircuitBreakers/#summary","title":"Summary","text":"<p>Circuit breakers are crucial in modern, distributed systems, preventing unnecessary retries and protecting systems from cascading failures. As systems grow in complexity, using the circuit breaker pattern helps maintain high availability and resilience.</p>"},{"location":"fundamentaldives/DesignPatterns/Composite/","title":"Composite","text":""},{"location":"fundamentaldives/DesignPatterns/Composite/#what","title":"What ?","text":"<p>The Composite Pattern is a structural design pattern used in software design to represent part whole hierarchies. It enables you to build complex object structures by treating both individual objects and compositions of objects uniformly.</p> <p>This pattern allows you to treat a group of objects in the same way as a single object. This is especially useful when building tree structures (like directories or UI components). </p> <p>Key Concepts</p> <p>The idea is to define a common interface for all the objects, whether simple or complex, so they can be treated uniformly.</p> <ul> <li>Component: A base interface for both leaf objects and composite objects.</li> <li>Leaf: An individual object that doesn't contain other objects.</li> <li>Composite: A container of other <code>Component</code> objects. It may contain both Leafs and other Composites.</li> </ul> <p>Basic Structure UML</p> <pre><code>Component (Interface or Abstract class)\n\u251c\u2500\u2500 Leaf (Concrete class)\n\u2514\u2500\u2500 Composite (Concrete class containing Components)\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/Composite/#when","title":"When ?","text":"<ul> <li>When you have a tree structure. eg: Filesystem, organizational hierarchies, UI components (panels, buttons, etc.).</li> <li>When you need to treat individual and composite objects uniformly. eg: A method like <code>draw()</code> should work for both individual shapes and a group of shapes.</li> <li>When you want to avoid if-else checks to determine if an object is an individual or a container.</li> <li>When you want objects to dynamically add children.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Composite/#where-not-to-use","title":"Where Not to Use ?","text":"<ul> <li>If your object structure is flat without any hierarchy.</li> <li>If objects have no relation to one another, there\u2019s no need for such complexity.</li> <li>If performance is critical and deep hierarchies could result in expensive recursive calls.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Composite/#why-use","title":"Why Use ?","text":"<ul> <li>Perfect for hierarchical data like organizations, UI components, or filesystems.</li> <li>Unified API Makes it easy to handle both individual and composite objects using the same operations.</li> <li>You can add new types of components without modifying existing code (Open-Closed Principle).</li> <li>Reduces Conditional Logic Avoids if-else statements by treating all objects uniformly.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Composite/#ways-to-create","title":"Ways to Create ?","text":"<ul> <li>With Interfaces or Abstract Classes.</li> <li>With Generics, allowing better type-safety.</li> <li>With Builders Use a Builder pattern to assemble the composite structure dynamically.</li> <li>Immutable Composites Create composite objects where elements are added only through constructor injection to prevent accidental changes.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Composite/#how-to-use-effectively","title":"How to Use Effectively?","text":"<ul> <li>Design around hierarchies Use it when your model naturally fits a tree structure.</li> <li>Leverage abstraction Ensure you design a robust <code>Component</code> interface for both Leafs and Composites.</li> <li>Avoid unnecessary depth Keep your object hierarchy shallow to prevent performance issues with recursive calls.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Composite/#how-to-apply","title":"How to Apply ?","text":"Simple Example <pre><code>// 1. Component Interface\ninterface Component {\n    void showDetails();  // Common operation for both Leaf and Composite\n}\n\n// 2. Leaf Class (Single object)\nclass Employee implements Component {\n    private String name;\n    private String position;\n\n    public Employee(String name, String position) {\n        this.name = name;\n        this.position = position;\n    }\n\n    @Override\n    public void showDetails() {\n        System.out.println(name + \" works as \" + position);\n    }\n}\n\n// 3. Composite Class (Composite of Components)\nclass Department implements Component {\n    private List&lt;Component&gt; employees = new ArrayList&lt;&gt;();\n\n    public void addEmployee(Component employee) {\n        employees.add(employee);\n    }\n\n    public void removeEmployee(Component employee) {\n        employees.remove(employee);\n    }\n\n    @Override\n    public void showDetails() {\n        for (Component employee : employees) {\n            employee.showDetails();\n        }\n    }\n}\n\n// 4. Client Code\npublic class CompositePatternDemo {\n    public static void main(String[] args) {\n        // Create individual employees\n        Component emp1 = new Employee(\"John\", \"Developer\");\n        Component emp2 = new Employee(\"Doe\", \"Tester\");\n\n        // Create a department and add employees to it\n        Department department = new Department();\n        department.addEmployee(emp1);\n        department.addEmployee(emp2);\n\n        // Show details\n        System.out.println(\"Department Details:\");\n        department.showDetails();\n    }\n}\n</code></pre> Output<pre><code>Department Details:\nJohn works as Developer\nDoe works as Tester\n</code></pre> Spring Boot Example <p>In Spring Boot, the Composite pattern can fit into cases where you model tree-based structures in your business logic, such as:</p> <ol> <li>Entity Relationships in JPA: Modeling nested categories, departments, or menus.</li> <li>Business Service Layer: Creating a unified API to handle both individual and composite objects.</li> </ol>"},{"location":"fundamentaldives/DesignPatterns/Composite/#product-category-service-in-spring-boot","title":"Product Category Service in Spring Boot","text":"<pre><code>// 1. Component Interface\npublic interface ProductCategory {\n    String getName();\n    void showCategoryDetails();\n}\n\n// 2. Leaf Class\npublic class Product implements ProductCategory {\n    private String name;\n\n    public Product(String name) {\n        this.name = name;\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void showCategoryDetails() {\n        System.out.println(\"Product: \" + name);\n    }\n}\n\n// 3. Composite Class\npublic class Category implements ProductCategory {\n    private String name;\n    private List&lt;ProductCategory&gt; children = new ArrayList&lt;&gt;();\n\n    public Category(String name) {\n        this.name = name;\n    }\n\n    public void add(ProductCategory category) {\n        children.add(category);\n    }\n\n    public void remove(ProductCategory category) {\n        children.remove(category);\n    }\n\n    @Override\n    public String getName() {\n        return name;\n    }\n\n    @Override\n    public void showCategoryDetails() {\n        System.out.println(\"Category: \" + name);\n        for (ProductCategory child : children) {\n            child.showCategoryDetails();\n        }\n    }\n}\n\n// 4. Controller in Spring Boot\n@RestController\n@RequestMapping(\"/categories\")\npublic class CategoryController {\n\n    @GetMapping(\"/example\")\n    public void example() {\n        // Creating products\n        ProductCategory p1 = new Product(\"Laptop\");\n        ProductCategory p2 = new Product(\"Phone\");\n\n        // Creating a category and adding products\n        Category electronics = new Category(\"Electronics\");\n        electronics.add(p1);\n        electronics.add(p2);\n\n        // Display details\n        electronics.showCategoryDetails();\n    }\n}\n</code></pre> Sample Output when calling /categories/example<pre><code>Category: Electronics\nProduct: Laptop\nProduct: Phone\n</code></pre> Spring Boot Considerations <ul> <li>Use in Controllers: You can use the composite pattern to model responses from REST endpoints.</li> <li>Use in Services: Combine multiple services (leaf and composite) in a unified API.</li> <li>Use with JPA Entities: If your entities are hierarchical, you can apply the Composite pattern with relationships (e.g., <code>@OneToMany</code>).</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Composite/#summary","title":"Summary","text":"<p>The Composite Pattern is a powerful structural pattern for managing hierarchical, tree-like structures. It allows uniform handling of individual and composite objects, making it ideal for UI elements, filesystems, or business domains with nested elements. When integrating with Spring Boot, it works well in controllers, services, or JPA entities for modeling hierarchical data. However, avoid using it when there\u2019s no hierarchy or when performance is critical (deep recursion). Use it wisely, and it can help you reduce complexity and simplify your code.</p>"},{"location":"fundamentaldives/DesignPatterns/Decorator/","title":"Decorator","text":""},{"location":"fundamentaldives/DesignPatterns/Decorator/#what","title":"What ?","text":"<p>The Decorator Pattern is a structural design pattern that allows behavior to be added to individual objects, either statically or dynamically, without affecting the behavior of other objects from the same class. This pattern is particularly useful when you need to add functionality to objects without subclassing and in scenarios where multiple combinations of behaviors are required.</p> <p>This pattern is used to attach additional responsibilities or behaviors to an object dynamically. It wraps the original object, adding new behavior while keeping the object\u2019s interface intact. A decorator class has a reference to the original object and implements the same interface.</p> <p>Key Concepts</p> <ul> <li>Component: The interface or abstract class that defines the original object.</li> <li>ConcreteComponent: The actual object that implements the <code>Component</code> interface.</li> <li>Decorator: An abstract class that implements the <code>Component</code> interface and holds a reference to a <code>Component</code> object.</li> <li>Concrete Decorators: Subclasses of the <code>Decorator</code> that add specific functionalities.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Decorator/#when-to-use","title":"When to Use ?","text":"<ul> <li>When you need to add responsibilities to individual objects dynamically and without altering their structure.</li> <li>When you want to extend the functionality of an object at runtime, without changing the class.</li> <li>When multiple combinations of responsibilities are needed, and subclassing would result in too many subclasses.</li> <li>When you want to keep the original class unchanged but extend its behavior transparently.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Decorator/#where-not-to-use","title":"Where Not to Use ?","text":"<ul> <li>If too many layers of decorators are required, it can make code complex and difficult to debug.</li> <li>When performance is a concern, as the decorator adds overhead with each layer.</li> <li>If the object\u2019s behavior doesn\u2019t need to change dynamically, then simpler design patterns like inheritance or composition might suffice.</li> <li>In cases where direct modification to the existing class is possible, decorators might be overkill.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Decorator/#advantages","title":"Advantages","text":"<ul> <li>Open for extension, closed for modification New functionalities can be added without altering existing code.</li> <li>More flexible than inheritance. It allows the combination of behaviors at runtime.</li> <li>Helps achieve single responsibility principle since each decorator adds only one type of behavior.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Decorator/#disadvantages","title":"Disadvantages","text":"<ul> <li>Complexity increases with a large number of decorators.</li> <li>Debugging can be challenging because you need to trace through multiple layers of decorators.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Decorator/#how-to-apply","title":"How to Apply ?","text":"Simple Example <p>Let's consider an example where we are building a coffee shop. Different types of coffees can be enhanced with add-ons like milk, sugar, etc. Using the decorator pattern, we can apply these add-ons dynamically without subclassing.</p> <pre><code>// Step 1: Component Interface\npublic interface Coffee {\n    String getDescription();\n    double getCost();\n}\n\n// Step 2: ConcreteComponent (Basic Coffee)\npublic class BasicCoffee implements Coffee {\n    @Override\n    public String getDescription() {\n        return \"Basic Coffee\";\n    }\n\n    @Override\n    public double getCost() {\n        return 2.0;\n    }\n}\n\n// Step 3: Decorator (Abstract)\npublic abstract class CoffeeDecorator implements Coffee {\n    protected Coffee coffee; // The object being decorated\n\n    public CoffeeDecorator(Coffee coffee) {\n        this.coffee = coffee;\n    }\n\n    public String getDescription() {\n        return coffee.getDescription();\n    }\n\n    public double getCost() {\n        return coffee.getCost();\n    }\n}\n\n// Step 4: Concrete Decorators (e.g., Milk, Sugar)\npublic class MilkDecorator extends CoffeeDecorator {\n    public MilkDecorator(Coffee coffee) {\n        super(coffee);\n    }\n\n    @Override\n    public String getDescription() {\n        return coffee.getDescription() + \", Milk\";\n    }\n\n    @Override\n    public double getCost() {\n        return coffee.getCost() + 0.5;\n    }\n}\n\npublic class SugarDecorator extends CoffeeDecorator {\n    public SugarDecorator(Coffee coffee) {\n        super(coffee);\n    }\n\n    @Override\n    public String getDescription() {\n        return coffee.getDescription() + \", Sugar\";\n    }\n\n    @Override\n    public double getCost() {\n        return coffee.getCost() + 0.2;\n    }\n}\n\n// Step 5: Usage\npublic class CoffeeShop {\n    public static void main(String[] args) {\n        Coffee coffee = new BasicCoffee();\n        System.out.println(coffee.getDescription() + \" $\" + coffee.getCost());\n\n        coffee = new MilkDecorator(coffee);\n        System.out.println(coffee.getDescription() + \" $\" + coffee.getCost());\n\n        coffee = new SugarDecorator(coffee);\n        System.out.println(coffee.getDescription() + \" $\" + coffee.getCost());\n    }\n}\n</code></pre> Output<pre><code>Basic Coffee $2.0\nBasic Coffee, Milk $2.5\nBasic Coffee, Milk, Sugar $2.7\n</code></pre> Spring Boot Example <p>In Spring Boot, the decorator pattern can be used in scenarios such as logging, monitoring, or security checks. You can implement a decorator pattern to enhance service classes without changing their core logic. Here's an example where we decorate a service class to add logging functionality.</p> Component Interface (Service Layer)<pre><code>public interface UserService {\n    String getUserDetails(String userId);\n}\n</code></pre> Concrete Component<pre><code>@Service\npublic class UserServiceImpl implements UserService {\n    @Override\n    public String getUserDetails(String userId) {\n        return \"User details for \" + userId;\n    }\n}\n</code></pre> Decorator<pre><code>@Service\npublic class LoggingUserService implements UserService {\n\n    private final UserService userService;\n\n    public LoggingUserService(UserService userService) {\n        this.userService = userService;\n    }\n\n    @Override\n    public String getUserDetails(String userId) {\n        System.out.println(\"Fetching details for user: \" + userId);\n        return userService.getUserDetails(userId);\n    }\n}\n</code></pre> Configuration to Use Decorator<pre><code>@Configuration\npublic class ServiceConfig {\n\n    @Bean\n    public UserService userService(UserServiceImpl userServiceImpl) {\n        return new LoggingUserService(userServiceImpl);\n    }\n}\n</code></pre> How it Works in Spring Boot <ul> <li><code>UserServiceImpl</code> provides the basic functionality.</li> <li><code>LoggingUserService</code> acts as a decorator, adding logging before calling the original method.</li> <li>Spring\u2019s DI (Dependency Injection) ensures that the decorated service is injected wherever needed.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Decorator/#summary","title":"Summary","text":"<p>The Decorator Pattern is a powerful and flexible way to enhance objects with additional behaviors dynamically without altering their structure. It shines in scenarios requiring combinations of behaviors and helps maintain clean, modular code. </p> <p>In Spring Boot, it can be used for decorating services with additional features like logging, security, or metrics, allowing these aspects to remain separate from the core business logic.</p> <p>This pattern should be used thoughtfully since excessive use can introduce complexity and make debugging difficult. However, when applied correctly, it ensures that code remains extensible and adheres to the Single Responsibility Principle and Open Closed Principle.</p>"},{"location":"fundamentaldives/DesignPatterns/Facade/","title":"Facade","text":"<p>The Facade Pattern is a structural design pattern commonly used to provide a simple, unified interface to a complex subsystem of classes, libraries, or frameworks. This pattern makes a complex library or system easier to use by hiding the underlying complexities and exposing only the functionality that is relevant for the client.</p>"},{"location":"fundamentaldives/DesignPatterns/Facade/#what","title":"What ?","text":"<ul> <li>The Facade Pattern defines a higher-level interface that makes a system easier to use by hiding its complexity.</li> <li>It provides a single interface or entry point to a group of related classes or modules.</li> <li>It simplifies interactions between the client and complex subsystems.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Facade/#how-to-create","title":"How to Create ?","text":"<ul> <li>Identify a complex subsystem that needs simplification.</li> <li>Design a Facade class to serve as the entry point for interacting with the subsystem.</li> <li>Expose only the essential methods in the Facade class that clients need.</li> <li>Delegate requests from the Facade class to the appropriate subsystem components.</li> <li>Hide the internal complexity of subsystems from the client.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Facade/#when-to-use","title":"When to Use ?","text":"<ul> <li>When you need to provide a simpler interface to a complex subsystem.</li> <li>When you want to minimize the dependency of your client code on the inner details of your system.</li> <li>When you make changes to the subsystems won\u2019t impact the client code since the facade hides those details.</li> <li>When you have multiple clients that need to interact with a system in a unified way.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Facade/#where-not-to-use","title":"Where Not to Use ?","text":"<ul> <li>If the system is already simple No need to add an extra abstraction layer.</li> <li>When full access to the subsystem is required If clients need to use the complete functionality of the subsystem, a facade might limit access.</li> <li>When high performance is critical If adding the facade introduces unnecessary overhead.</li> <li>Too many Facades can be anti-pattern overusing facades may cause code to become harder to maintain by hiding too much behind layers of abstraction.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Facade/#advantages","title":"Advantages","text":"<ul> <li>Simplifies code usage Reduces the number of classes exposed to the client.</li> <li>Encapsulates complexity Hides the intricacies of the subsystems.</li> <li>Improves maintainability Changes in subsystems don\u2019t affect the client directly.</li> <li>Reduces dependencies Decouples the client from internal subsystems.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Facade/#disadvantages","title":"Disadvantages","text":"<ul> <li>Over-abstraction Might hide too much, making it hard to access specific functionality.</li> <li>Performance overhead If not designed well, adding a facade might introduce latency.</li> <li>Risk of becoming an anti-pattern Overuse can lead to poorly maintainable code due to excessive abstraction layers.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Facade/#how-to-apply","title":"How to Apply ?","text":"Simple Example <p>Let's go through a simple Java example demonstrating a Facade pattern for a Home Theater System:</p> <pre><code>// Subsystem classes\nclass Amplifier {\n    public void on() { System.out.println(\"Amplifier is ON.\"); }\n    public void off() { System.out.println(\"Amplifier is OFF.\"); }\n}\n\nclass DVDPlayer {\n    public void play() { System.out.println(\"Playing movie.\"); }\n    public void stop() { System.out.println(\"Stopping movie.\"); }\n}\n\nclass Projector {\n    public void on() { System.out.println(\"Projector is ON.\"); }\n    public void off() { System.out.println(\"Projector is OFF.\"); }\n}\n\n// Facade class\nclass HomeTheaterFacade {\n    private Amplifier amplifier;\n    private DVDPlayer dvdPlayer;\n    private Projector projector;\n\n    public HomeTheaterFacade(Amplifier amp, DVDPlayer dvd, Projector proj) {\n        this.amplifier = amp;\n        this.dvdPlayer = dvd;\n        this.projector = proj;\n    }\n\n    public void watchMovie() {\n        System.out.println(\"Setting up movie...\");\n        amplifier.on();\n        projector.on();\n        dvdPlayer.play();\n    }\n\n    public void endMovie() {\n        System.out.println(\"Shutting down movie...\");\n        dvdPlayer.stop();\n        projector.off();\n        amplifier.off();\n    }\n}\n\n// Client code\npublic class FacadePatternDemo {\n    public static void main(String[] args) {\n        Amplifier amp = new Amplifier();\n        DVDPlayer dvd = new DVDPlayer();\n        Projector proj = new Projector();\n\n        HomeTheaterFacade homeTheater = new HomeTheaterFacade(amp, dvd, proj);\n\n        homeTheater.watchMovie();\n        homeTheater.endMovie();\n    }\n}\n</code></pre> Output<pre><code>Setting up movie...\nAmplifier is ON.\nProjector is ON.\nPlaying movie.\nShutting down movie...\nStopping movie.\nProjector is OFF.\nAmplifier is OFF.\n</code></pre> Explanation: <ul> <li>Subsystem classes (Amplifier, DVDPlayer, Projector) have their own logic.</li> <li>Facade class (HomeTheaterFacade) abstracts the interactions between these subsystems and provides a simple interface for the client.</li> <li>The client only needs to call the watchMovie() and endMovie() methods without worrying about the complex setup logic.</li> </ul> Spring Boot Example <p>In Spring Boot, the Facade pattern can be applied to services or controllers to hide the complexity of business logic or external systems. For example, a facade class can wrap multiple service calls or integrate external APIs to provide a simplified interface to the client (like a REST controller).</p> <p>Let's go through a example of how to apply the Facade pattern in a Spring Boot application.</p> <p>Example Scenario: A Payment System interacts with several services (like PaymentGatewayService, NotificationService, and OrderService). We create a PaymentFacade to simplify the interaction.</p> Step-1: Subsystem Services<pre><code>@Service\npublic class PaymentGatewayService {\n    public void processPayment(String orderId) {\n        System.out.println(\"Processing payment for order: \" + orderId);\n    }\n}\n\n@Service\npublic class NotificationService {\n    public void sendNotification(String message) {\n        System.out.println(\"Sending notification: \" + message);\n    }\n}\n\n@Service\npublic class OrderService {\n    public void completeOrder(String orderId) {\n        System.out.println(\"Completing order: \" + orderId);\n    }\n}\n</code></pre> Step-2: Facade Class<pre><code>@Service\npublic class PaymentFacade {\n\n    private final PaymentGatewayService paymentGatewayService;\n    private final NotificationService notificationService;\n    private final OrderService orderService;\n\n    @Autowired\n    public PaymentFacade(PaymentGatewayService paymentGatewayService,\n                        NotificationService notificationService,\n                        OrderService orderService) {\n        this.paymentGatewayService = paymentGatewayService;\n        this.notificationService = notificationService;\n        this.orderService = orderService;\n    }\n\n    public void makePayment(String orderId) {\n        System.out.println(\"Initiating payment process...\");\n        paymentGatewayService.processPayment(orderId);\n        orderService.completeOrder(orderId);\n        notificationService.sendNotification(\"Payment completed for order: \" + orderId);\n    }\n}\n</code></pre> Step-3: Controller<pre><code>@RestController\n@RequestMapping(\"/api/payment\")\npublic class PaymentController {\n\n    private final PaymentFacade paymentFacade;\n\n    @Autowired\n    public PaymentController(PaymentFacade paymentFacade) {\n        this.paymentFacade = paymentFacade;\n    }\n\n    @PostMapping(\"/pay/{orderId}\")\n    public ResponseEntity&lt;String&gt; pay(@PathVariable String orderId) {\n        paymentFacade.makePayment(orderId);\n        return ResponseEntity.ok(\"Payment successful for order: \" + orderId);\n    }\n}\n</code></pre> Explanation <ul> <li>PaymentFacade: Acts as the Facade, simplifying the interactions between <code>PaymentGatewayService</code>, <code>OrderService</code>, and <code>NotificationService</code>.</li> <li>Controller: Uses the <code>PaymentFacade</code> to expose a single endpoint for making payments.</li> <li>This ensures that the controller does not need to handle complex business logic and can focus only on handling HTTP requests.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Facade/#summary","title":"Summary","text":"<p>The Facade Pattern is a powerful tool for simplifying interactions with complex systems. It is especially useful when working with large subsystems or external APIs, as it encapsulates the internal workings and provides a simple interface to clients. In a Spring Boot application, you can use it to manage complex business logic or interactions with multiple services within a single, cohesive facade. However, it should be used judiciously to avoid over-abstraction or unnecessary complexity.</p> <p>Note</p> <p>This makes the Facade pattern a valuable asset in both object-oriented design and modern frameworks like Spring Boot.</p>"},{"location":"fundamentaldives/DesignPatterns/Facade/#this-pattern-is-best-used-when","title":"This pattern is best used when:","text":"<pre><code>- You need to simplify client interactions.\n- You want to decouple the client from a complex subsystem.\n- You aim to improve maintainability and reduce dependencies.\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/Facade/#avoid-using-it-when","title":"Avoid using it when:","text":"<pre><code>- The system is already simple.\n- Performance is a key concern.\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/","title":"Factory Method","text":""},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#what","title":"What ?","text":"<p>Factory Method is a creational design pattern that provides an interface for creating objects in a superclass, but allows subclasses to alter the type of objects that will be created (decide which class to instantiate). This pattern delegates the responsibility of object creation to subclasses rather than using a direct constructor call, It is one of the most widely used creational design patterns, It helps in the creation of objects without specifying the exact class of the object that will be created.</p> <p>You provide a \"factory\" method that the client code calls to get the object, but the actual object that gets created is determined at runtime (based on some logic).</p>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#when-to-use","title":"When to Use ?","text":"<ul> <li>When you don't know in advance which class to instantiate (i.e., you want the logic to determine the object type dynamically).</li> <li>When you need flexibility in creating objects but want to avoid tight coupling.</li> <li>When new types of objects might be introduced in the future without breaking code.</li> <li>When working with complex object creation logic (e.g., when object creation requires conditional logic).</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#when-not-to-use","title":"When Not to Use ?","text":"<ul> <li>When only a single type of object needs to be created (Factory adds unnecessary complexity).</li> <li>If object creation does not require polymorphism or dynamism, and the same class instantiation works fine.</li> <li>When performance is critical, as Factory Method can introduce overhead by adding extra layers of abstraction.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#where-it-shines","title":"Where it Shines ?","text":"<ul> <li>Many frameworks (like JDBC, Hibernate, etc.) rely on Factory Method to return specific instances without the client needing to know the class type.</li> <li>When there are multiple subclasses of a product and only one of them needs to be instantiated at runtime.</li> <li>If new product types might be introduced in the future, the pattern provides an easy way to extend.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#advantages","title":"Advantages","text":"<ul> <li>Loose coupling, The controller doesn't need to know exact type of object being created.</li> <li>Flexibility, You can add new types of notifications without modifying the controller logic.</li> <li>Testability, The factory can be easily mocked or stubbed during unit tests.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#structure","title":"Structure","text":"<ol> <li>Product Interface: Defines the interface for the object being created.</li> <li>Concrete Product: Implements the product interface.</li> <li>Creator: Declares the factory method which returns an object of type Product.</li> <li>Concrete Creator: Overrides the factory method to return a specific product instance.</li> </ol>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#how-to-implement","title":"How To Implement ?","text":"Structured Example Step-1: Define a Product Interface<pre><code>public interface Notification {\n    void notifyUser();\n}\n</code></pre> Step-2: Create Concrete Implementations of the Product<pre><code>public class SMSNotification implements Notification {\n    @Override\n    public void notifyUser() {\n        System.out.println(\"Sending an SMS notification.\");\n    }\n}\n\npublic class EmailNotification implements Notification {\n    @Override\n    public void notifyUser() {\n        System.out.println(\"Sending an Email notification.\");\n    }\n}\n</code></pre> Step-3: Create an Abstract Factory Class<pre><code>public abstract class NotificationFactory {\n    public abstract Notification createNotification();\n}\n</code></pre> Step-4: Implement Concrete Factory Classes<pre><code>public class SMSNotificationFactory extends NotificationFactory {\n    @Override\n    public Notification createNotification() {\n        return new SMSNotification();\n    }\n}\n\npublic class EmailNotificationFactory extends NotificationFactory {\n    @Override\n    public Notification createNotification() {\n        return new EmailNotification();\n    }\n}\n</code></pre> Step-5: Usage in Client Code<pre><code>public class Client {\n    public static void main(String[] args) {\n        NotificationFactory factory = new SMSNotificationFactory();\n        Notification notification = factory.createNotification();\n        notification.notifyUser();\n\n        factory = new EmailNotificationFactory();\n        notification = factory.createNotification();\n        notification.notifyUser();\n    }\n}\n</code></pre> Spring Boot Example <p>Spring Boot relies heavily on dependency injection (DI) and Inversion of Control (IoC), which means Spring beans can act as factory classes to produce the desired objects.</p>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#example-notification-factory-with-spring-boot","title":"Example: Notification Factory with Spring Boot","text":"Define the Product Interface and Implementations (Same as Before)<pre><code>public interface Notification {\n    void notifyUser();\n}\n\npublic class SMSNotification implements Notification {\n    @Override\n    public void notifyUser() {\n        System.out.println(\"Sending an SMS notification.\");\n    }\n}\n\npublic class EmailNotification implements Notification {\n    @Override\n    public void notifyUser() {\n        System.out.println(\"Sending an Email notification.\");\n    }\n}\n</code></pre> Create a Spring Factory Class<pre><code>import org.springframework.stereotype.Service;\n// This class will act as the **Factory**. You can make it a Spring **`@Service` or `@Component`** bean, so Spring manages it.\n@Service\npublic class NotificationFactory {\n    public Notification createNotification(String type) {\n        if (type.equalsIgnoreCase(\"SMS\")) {\n            return new SMSNotification();\n        } else if (type.equalsIgnoreCase(\"Email\")) {\n            return new EmailNotification();\n        }\n        throw new IllegalArgumentException(\"Unknown notification type: \" + type);\n    }\n}\n</code></pre> Use the Factory Class in a Spring Controller<pre><code>import org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class NotificationController {\n\n    @Autowired\n    private NotificationFactory notificationFactory;\n\n    @GetMapping(\"/notify/{type}\")\n    public String sendNotification(@PathVariable String type) {\n        Notification notification = notificationFactory.createNotification(type);\n        notification.notifyUser();\n        return \"Notification sent: \" + type;\n    }\n}\n</code></pre> <p>When you access <code>/notify/SMS</code> or <code>/notify/Email</code>, it will dynamically create and send the corresponding notification after running the spring boot application.</p>"},{"location":"fundamentaldives/DesignPatterns/FactoryMethod/#summary","title":"Summary","text":"<p>The Factory Pattern enables dynamic object creation without specifying exact classes, reducing coupling and improving maintainability. It uses a factory method to determine which class to instantiate. In Spring Boot, this pattern integrates seamlessly through factory beans and dependency injection, providing flexible and condition-based object creation.</p> <p>Note</p> <p>Factory Method is especially helpful in modular systems where new functionalities might be added frequently, and we want to minimize the impact of changes to existing code.</p>"},{"location":"fundamentaldives/DesignPatterns/Iterator/","title":"Iterator","text":"<p>The Iterator pattern is a behavioral design pattern that allows sequential access to elements of a collection without exposing its underlying structure. The goal is to provide a way to access the elements of an aggregate object (such as an array, list, or set) one by one, without needing to understand how the collection is implemented.</p>"},{"location":"fundamentaldives/DesignPatterns/Iterator/#what","title":"What ?","text":"<p>Iterator is a behavioral design pattern that lets you traverse elements of a collection without exposing its underlying representation (list, stack, tree, etc.).</p> <p>Key Components</p> <ul> <li>Iterator: An interface that defines methods for traversing elements (e.g., <code>hasNext()</code>, <code>next()</code>).</li> <li>Concrete Iterator: A class implementing the <code>Iterator</code> interface for specific collections.</li> <li>Aggregate: An interface that defines a method to return an iterator (e.g., <code>iterator()</code>).</li> <li>Concrete Aggregate: A collection (like List, Set, or Custom Collection) that returns a concrete iterator for traversal.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Iterator/#when-to-use","title":"When to Use ?","text":"<ul> <li>When you need to traverse a collection without exposing its internal structure.</li> <li>When the collection might be complex (e.g., trees, graphs) or needs to be accessed in multiple ways.</li> <li>When you want to ensure uniform traversal logic regardless of the type of collection (array, list, set, etc.).</li> <li>Helpful when designing read-only views over complex collections.</li> <li>If you need multiple ways to traverse the collection (e.g., forward, reverse, or filtered).</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Iterator/#when-not-to-use","title":"When Not to Use ?","text":"<ul> <li>If the collection is small and performance is critical, an iterator might introduce overhead.</li> <li>When direct access to elements is more efficient or easier (e.g., in simple arrays or lists).</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Iterator/#advantages","title":"Advantages","text":"<ul> <li>Separation of concerns the client doesn\u2019t need to know the internal structure of the collection.</li> <li>Multiple traversal strategies can implement different types of iterators (e.g., reverse iterator).</li> <li>Simplifies collections makes it easier to work with complex structures like trees or graphs.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Iterator/#disadvantages","title":"DisAdvantages","text":"<ul> <li>Performance overhead if not managed properly, iterators can add unnecessary overhead.</li> <li>Limited control over collection Iterators typically provide read-only access.</li> <li>Concurrency issues Modifying a collection while iterating over it may throw <code>ConcurrentModificationException</code>.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Iterator/#how-to-implement","title":"How to Implement ?","text":"Sample Example <p>Let's go through with a simple Java example of a custom iterator for a list of strings.</p> Defining the Iterator Interface<pre><code>interface Iterator&lt;T&gt; {\n    boolean hasNext();\n    T next();\n}\n</code></pre> Creating a Concrete Iterator<pre><code>class NameIterator implements Iterator&lt;String&gt; {\n    private String[] names;\n    private int index;\n\n    public NameIterator(String[] names) {\n        this.names = names;\n    }\n\n    @Override\n    public boolean hasNext() {\n        return index &lt; names.length;\n    }\n\n    @Override\n    public String next() {\n        if (this.hasNext()) {\n            return names[index++];\n        }\n        return null;\n    }\n}\n</code></pre> Defining the Aggregate (Collection) Interface<pre><code>interface NameCollection {\n    Iterator&lt;String&gt; getIterator();\n}\n</code></pre> Implementing the Concrete Aggregate (Collection)<pre><code>class NameRepository implements NameCollection {\n    private String[] names = {\"John\", \"Alice\", \"Robert\", \"Michael\"};\n\n    @Override\n    public Iterator&lt;String&gt; getIterator() {\n        return new NameIterator(names);\n    }\n}\n</code></pre> Usage Example in Java<pre><code>public class IteratorPatternDemo {\n    public static void main(String[] args) {\n        NameRepository namesRepository = new NameRepository();\n        Iterator&lt;String&gt; iterator = namesRepository.getIterator();\n\n        while (iterator.hasNext()) {\n            String name = iterator.next();\n            System.out.println(\"Name: \" + name);\n        }\n    }\n}\n</code></pre> Using Java\u2019s Built-in Iterators <p>Java already provides built-in iterators for its collection framework (<code>Iterator</code>, <code>ListIterator</code>, and <code>Spliterator</code>).</p> Example with Java\u2019s Built-in Iterator<pre><code>import java.util.ArrayList;\nimport java.util.Iterator;\nimport java.util.List;\n\npublic class BuiltInIteratorExample {\n    public static void main(String[] args) {\n        List&lt;String&gt; names = new ArrayList&lt;&gt;();\n        names.add(\"John\");\n        names.add(\"Alice\");\n        names.add(\"Robert\");\n\n        Iterator&lt;String&gt; iterator = names.iterator();\n        while (iterator.hasNext()) {\n            System.out.println(\"Name: \" + iterator.next());\n        }\n    }\n}\n</code></pre> Spring Boot Example <p>Spring Boot doesn\u2019t explicitly use the Iterator pattern as part of its core framework, but it does utilize Iterators internally (e.g., when dealing with <code>ApplicationContext</code> beans or data access layers). You can integrate the Iterator pattern within Spring Boot to handle collections of objects such as configurations, database entities, or APIs.</p> Create a Model Class<pre><code>public class Book {\n    private String title;\n\n    public Book(String title) {\n        this.title = title;\n    }\n\n    public String getTitle() {\n        return title;\n    }\n}\n</code></pre> Create a Repository to Hold Books<pre><code>import java.util.ArrayList;\nimport java.util.List;\n\npublic class BookRepository {\n    private List&lt;Book&gt; books = new ArrayList&lt;&gt;();\n\n    public BookRepository() {\n        books.add(new Book(\"Spring in Action\"));\n        books.add(new Book(\"Java 8 in Action\"));\n        books.add(new Book(\"Microservices Patterns\"));\n    }\n\n    public Iterator&lt;Book&gt; getIterator() {\n        return books.iterator();\n    }\n}\n</code></pre> Service to Fetch Books Using Iterator<pre><code>import org.springframework.stereotype.Service;\nimport java.util.Iterator;\n\n@Service\npublic class BookService {\n    private final BookRepository bookRepository = new BookRepository();\n\n    public void printBooks() {\n        Iterator&lt;Book&gt; iterator = bookRepository.getIterator();\n        while (iterator.hasNext()) {\n            Book book = iterator.next();\n            System.out.println(\"Book: \" + book.getTitle());\n        }\n    }\n}\n</code></pre> Controller to Trigger the Book Listing<pre><code>import org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\n@RequestMapping(\"/books\")\npublic class BookController {\n\n    @Autowired\n    private BookService bookService;\n\n    @GetMapping\n    public void listBooks() {\n        bookService.printBooks();\n    }\n}\n</code></pre> <p>When you access <code>http://localhost:8080/books</code>, it will print the list of books using the iterator after running the application</p>"},{"location":"fundamentaldives/DesignPatterns/Iterator/#summary","title":"Summary","text":"<p>The Iterator pattern is a powerful way to decouple iteration logic from collections, ensuring a clean separation of concerns. It\u2019s useful in Java projects where complex or multiple ways of traversal are required. When integrated into Spring Boot, the pattern can be applied to iterate over configurations, data models, or APIs efficiently.</p>"},{"location":"fundamentaldives/DesignPatterns/Prototype/","title":"Prototype","text":""},{"location":"fundamentaldives/DesignPatterns/Prototype/#what","title":"What ?","text":"<p>The Prototype Pattern is a creational design pattern used when the cost of creating a new object is expensive or complicated. Instead of creating new instances from scratch, this pattern suggests cloning existing objects to produce new ones.</p> <p>The pattern allows cloning or copying existing instances to create new ones, ensuring that new objects are created without going through the expensive or complex instantiation process repeatedly.</p> <p>Key Characteristics</p> <ul> <li>Objects are created by copying or cloning an existing prototype object.</li> <li>Each prototype maintains its state, and the cloned objects are independent copies.</li> <li>Useful when the creation of an object is resource-intensive (e.g., large data loads, configurations, etc.).</li> <li>Shallow Copy: Only the references of the fields are copied, not the objects themselves.</li> <li>Deep Copy: A full independent copy of all nested objects is created.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Prototype/#when-to-use","title":"When to Use ?","text":"<ul> <li>When creating an object is expensive e.g., reading a database, complex object initialization, or network-intensive setup.</li> <li>When you want to avoid creating new instances and prefer copying existing objects.</li> <li>When your code requires many objects of a similar type, where only slight modifications are made to the original object.</li> <li>When the class structure or object creation is complex and involves multiple configurations (e.g., with builders, factories, etc.).</li> <li>When you need stateless beans that are short-lived and used temporarily.</li> <li>When objects need to be created dynamically (e.g., user session-based objects).</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Prototype/#where-not-to-use","title":"Where Not to Use ?","text":"<ul> <li>When creating a new instance is inexpensive and straightforward.</li> <li>When object state changes frequently, as the cloned object may quickly become stale or out-of-sync with the original.</li> <li>If immutable objects are required, as the whole point of this pattern is to create modifiable, independent copies.</li> <li>For singleton beans or objects that must be shared across the application.</li> <li>When object creation is cheap, and cloning provides no significant benefit.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Prototype/#how-to-implement","title":"How to Implement ?","text":"Simple Example <p>In Java, the Prototype Pattern is implemented by making the class implement the <code>Cloneable</code> interface and overriding the <code>clone()</code> method from the <code>Object</code> class.</p> Example of Prototype in Java<pre><code>class Address {\n    String street;\n    String city;\n\n    public Address(String street, String city) {\n        this.street = street;\n        this.city = city;\n    }\n\n    // Deep Copy\n    public Address(Address address) {\n        this.street = address.street;\n        this.city = address.city;\n    }\n\n    @Override\n    public String toString() {\n        return street + \", \" + city;\n    }\n}\n\nclass Employee implements Cloneable {\n    String name;\n    Address address;\n\n    public Employee(String name, Address address) {\n        this.name = name;\n        this.address = address;\n    }\n\n    // Shallow Copy\n    @Override\n    protected Object clone() throws CloneNotSupportedException {\n        return super.clone();\n    }\n\n    // Deep Copy\n    public Employee deepClone() {\n        return new Employee(this.name, new Address(this.address));\n    }\n\n    @Override\n    public String toString() {\n        return \"Employee: \" + name + \", Address: \" + address;\n    }\n}\n\npublic class PrototypeExample {\n    public static void main(String[] args) throws CloneNotSupportedException {\n        Employee emp1 = new Employee(\"Alice\", new Address(\"123 Street\", \"New York\"));\n\n        // Shallow Clone\n        Employee emp2 = (Employee) emp1.clone();\n\n        // Deep Clone\n        Employee emp3 = emp1.deepClone();\n\n        System.out.println(\"Original: \" + emp1);\n        System.out.println(\"Shallow Copy: \" + emp2);\n        System.out.println(\"Deep Copy: \" + emp3);\n\n        // Modify the original object to see the effect on shallow vs deep copy\n        emp1.address.street = \"456 Avenue\";\n\n        System.out.println(\"After modifying the original object:\");\n        System.out.println(\"Original: \" + emp1);\n        System.out.println(\"Shallow Copy: \" + emp2);\n        System.out.println(\"Deep Copy: \" + emp3);\n    }\n}\n</code></pre> Output <pre><code>Original: Employee: Alice, Address: 123 Street, New York\nShallow Copy: Employee: Alice, Address: 123 Street, New York\nDeep Copy: Employee: Alice, Address: 123 Street, New York\n\nAfter modifying the original object:\nOriginal: Employee: Alice, Address: 456 Avenue, New York\nShallow Copy: Employee: Alice, Address: 456 Avenue, New York\nDeep Copy: Employee: Alice, Address: 123 Street, New York\n</code></pre> Explanation <ul> <li>Shallow Copy (<code>clone()</code>): Modifying the original affects the copy (since both reference the same <code>Address</code> object).</li> <li>Deep Copy (<code>deepClone()</code>): The copy remains unaffected because it contains a completely new <code>Address</code> object.</li> </ul> Spring Boot Example <p>Spring Framework allows defining prototype-scoped beans. Each time you request a bean with the prototype scope, Spring returns a new instance, effectively following the Prototype Pattern.</p>"},{"location":"fundamentaldives/DesignPatterns/Prototype/#how-to-use-prototype-scope-in-spring-boot","title":"How to Use Prototype Scope in Spring Boot","text":"<ol> <li>Add <code>@Scope</code> annotation to the bean definition.</li> <li>Use <code>prototype</code> scope to ensure each request gets a new object.</li> </ol>"},{"location":"fundamentaldives/DesignPatterns/Prototype/#simple-prototype-scope-example-in-spring-boot","title":"Simple Prototype Scope Example in Spring Boot","text":"Bean Definition<pre><code>import org.springframework.context.annotation.Scope;\nimport org.springframework.stereotype.Component;\n\n@Component\n@Scope(\"prototype\")\npublic class Employee {\n    public Employee() {\n        System.out.println(\"New Employee instance created.\");\n    }\n}\n</code></pre> Controller<pre><code>import org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class EmployeeController {\n\n    @Autowired\n    private Employee employee1;\n\n    @Autowired\n    private Employee employee2;\n\n    @GetMapping(\"/employees\")\n    public String getEmployees() {\n        return \"Employee 1: \" + employee1 + \" | Employee 2: \" + employee2;\n    }\n}\n</code></pre> Output <p>When you run this application and hit the <code>/employees</code> endpoint, you will see: <pre><code>New Employee instance created.\nNew Employee instance created.\n</code></pre></p> <p>This shows that a new instance is created each time a prototype-scoped bean is injected.</p>"},{"location":"fundamentaldives/DesignPatterns/Prototype/#summary","title":"Summary","text":"<p>The Prototype Pattern offers an elegant way to clone existing objects, saving the overhead of complex object creation. It fits well when objects are expensive to create or share the same initial configuration. With Java's cloning mechanisms and Spring Boot's prototype scope, it is easy to implement. However, care must be taken when handling deep versus shallow copies, and the pattern should be avoided when objects are inexpensive to create.</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/","title":"Singleton","text":""},{"location":"fundamentaldives/DesignPatterns/Singleton/#what","title":"What ?","text":"<p>The Singleton Pattern is a creational design pattern that ensures a class has only one instance and provides a global access point to that instance. </p> <ul> <li>Single instance: Only one object of the class is created.</li> <li>Global access: Provides a global point of access to that instance.</li> </ul> <p>Singleton is useful when exactly one instance of a class is needed across the system, like for logging, configuration, database connection pools, etc.</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#when-to-use","title":"When to Use ?","text":"<ul> <li>When an object holds configuration settings for the application.</li> <li>When only one connection pool should be active throughout the system.</li> <li>Needed to Ensure that all parts of the application use the same logging instance.</li> <li>When a cache should be available throughout the application.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#when-not-to-use","title":"When Not to Use ?","text":"<ul> <li>Singleton is limited to the JVM instance, so it won't work across multiple servers such as distributed systems.</li> <li>If the singleton object holds state, it can lead to thread contention in cases like High concurrency applications.</li> <li>Singleton classes are difficult to test because their state is shared across tests, leading to unpredictable behavior.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#why-use","title":"Why Use ?","text":"<ul> <li>As Only one instance is created, reducing memory overhead so memory efficiency </li> <li>Ensures a consistent state throughout the application since all code accesses the same instance.</li> <li>Provides a way to access a shared resource or service from anywhere in the code.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#how-to-implement","title":"How to Implement ?","text":""},{"location":"fundamentaldives/DesignPatterns/Singleton/#eager-initialization","title":"Eager Initialization","text":"<p>The instance is created when the class is loaded. This is the simplest way, but it doesn\u2019t support lazy loading.</p> Eager Initialization Implementation <pre><code>public class EagerSingleton {\n    private static final EagerSingleton INSTANCE = new EagerSingleton();\n\n    // Private constructor to prevent instantiation\n    private EagerSingleton() {}\n\n    public static EagerSingleton getInstance() {\n        return INSTANCE;\n    }\n}\n</code></pre> <p>When to Use Eager</p> <p>When the instance is required throughout the application, and we are okay with it being created at startup.</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#lazy-initialization","title":"Lazy Initialization","text":"<p>The instance is created only when needed (on first access). But this version is not thread-safe.</p> Lazy Initialization Implementation <pre><code>public class LazySingleton {\n    private static LazySingleton instance;\n\n    private LazySingleton() {}\n\n    public static LazySingleton getInstance() {\n        if (instance == null) {\n            instance = new LazySingleton();\n        }\n        return instance;\n    }\n}\n</code></pre> <p>Issue with Lazy</p> <p>Lazy Initialization is not suitable for multithreaded environments.</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#using-synchronized","title":"Using Synchronized","text":"<p>This solves the issue of thread safety by synchronizing the access method.</p> Synchronized Implementation <pre><code>public class ThreadSafeSingleton {\n    private static ThreadSafeSingleton instance;\n\n    private ThreadSafeSingleton() {}\n\n    public static synchronized ThreadSafeSingleton getInstance() {\n        if (instance == null) {\n            instance = new ThreadSafeSingleton();\n        }\n        return instance;\n    }\n}\n</code></pre> <p>Issue with Synchronized</p> <p>Performance overhead due to synchronization.</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#double-checked-locking","title":"Double-Checked Locking","text":"<p>This improves the performance by reducing the overhead of synchronized block.</p> Double-Checked Locking Implementation <pre><code>public class DoubleCheckedLockingSingleton {\n    private static volatile DoubleCheckedLockingSingleton instance;\n\n    private DoubleCheckedLockingSingleton() {}\n\n    public static DoubleCheckedLockingSingleton getInstance() {\n        if (instance == null) {\n            synchronized (DoubleCheckedLockingSingleton.class) {\n                if (instance == null) {\n                    instance = new DoubleCheckedLockingSingleton();\n                }\n            }\n        }\n        return instance;\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#bill-pugh-singleton","title":"Bill Pugh Singleton","text":"<p>This approach leverages static inner classes, which ensures thread safety and lazy loading without synchronization overhead.</p> Bill Pugh Singleton Implementation <pre><code>public class BillPughSingleton {\n    private BillPughSingleton() {}\n\n    // Static inner class responsible for holding the instance\n    private static class SingletonHelper {\n        private static final BillPughSingleton INSTANCE = new BillPughSingleton();\n    }\n\n    public static BillPughSingleton getInstance() {\n        return SingletonHelper.INSTANCE;\n    }\n}\n</code></pre> <p>Best Practice</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#enum-singleton","title":"Enum Singleton","text":"<p>This approach is the most concise and prevents issues with serialization and reflection attacks.</p> Enum Singleton Implementation <pre><code>public enum EnumSingleton {\n    INSTANCE;\n\n    public void someMethod() {\n        System.out.println(\"Enum Singleton Instance\");\n    }\n}\n</code></pre> <p>Recommended</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#in-spring-boot","title":"In Spring Boot","text":"<p>In Spring Boot, Spring\u2019s IoC container (Inversion of Control) makes singleton beans by default. Each bean in Spring is, by default, a singleton. So, you don\u2019t need to explicitly implement the Singleton pattern. Instead, you annotate the class with <code>@Component</code> or <code>@Service</code>, and Spring ensures that only one instance is created and managed.</p> Spring Boot Example How to init in a Spring Boot application<pre><code>import org.springframework.stereotype.Component;\n\n@Component\npublic class MySingletonService {\n    public void doSomething() {\n        System.out.println(\"Singleton service is working\");\n    }\n}\n</code></pre> How to use in a Spring Boot application<pre><code>import org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class MyController {\n\n    private final MySingletonService singletonService;\n\n    @Autowired\n    public MyController(MySingletonService singletonService) {\n        this.singletonService = singletonService;\n    }\n\n    @GetMapping(\"/test\")\n    public String test() {\n        singletonService.doSomething();\n        return \"Check logs for Singleton Service\";\n    }\n}\n</code></pre> <p>Note</p> <p>Spring manages lifecycle and thread safety for you, ensuring it behaves like a Singleton without extra code.</p>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#comparison","title":"Comparison","text":"Implementation Thread Safety Lazy Initialization Serialization Safe Ease of Implementation Eager Initialization Yes No No Easy Lazy Initialization No Yes No Easy Thread-safe Singleton (Synchronized) Yes Yes No Moderate Double-Checked Locking Singleton Yes Yes No Moderate Bill Pugh Singleton Yes Yes No Best Practice Enum Singleton Yes Yes Yes Recommended"},{"location":"fundamentaldives/DesignPatterns/Singleton/#potential-issues","title":"Potential Issues","text":"<ul> <li>If not implemented correctly, it can lead to thread synchronization issues.</li> <li>Normal singletons can break if the instance is serialized and deserialized.</li> <li>Code becomes tightly coupled to the singleton instance, reducing flexibility.</li> <li>It\u2019s harder to mock or replace singletons in unit tests, leading to less modular code.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Singleton/#summary","title":"Summary","text":"<p>The Singleton Pattern is a powerful tool when used appropriately. However, misuse can lead to tightly coupled code, concurrency issues, and testing difficulties. </p> <p>Note</p> <p>If you are working with Spring Boot, rely on Spring\u2019s built-in singleton beans instead of implementing your own singleton logic. Where thread safety, serialization, or distributed behavior is required, choose the appropriate Singleton implementation like Enum Singleton or Bill Pugh Singleton. </p> <p>By default, a single instance of the bean is created and shared across the entire application (singleton scope). If two or more components use the same bean, they will refer to the same instance. However, if you need a new instance every time a bean is requested, you can change the scope to <code>prototype</code>. But be mindful Spring\u2019s singleton scope simplifies things like caching and state consistency, while prototype beans may introduce complexity.</p>"},{"location":"fundamentaldives/DesignPatterns/Strategy/","title":"Strategy","text":""},{"location":"fundamentaldives/DesignPatterns/Strategy/#what","title":"What ?","text":"<p>The Strategy Pattern is a behavioral design pattern that allows you to define a family of algorithms, encapsulate each one, and make them interchangeable. It lets the algorithm vary independently from clients that use it, promoting flexibility, scalability, and separation of concerns. </p> <p>In simpler terms, It enables selecting a specific algorithm at runtime based on the context, without modifying the client code. </p>"},{"location":"fundamentaldives/DesignPatterns/Strategy/#when-to-use","title":"When to Use?","text":"<ul> <li>When you have multiple algorithms or behaviors that can be applied to an object and want to switch between them dynamically.</li> <li>When you need to avoid conditional logic (like many <code>if-else</code> or <code>switch</code> statements).</li> <li>When you want to decouple the code that uses the algorithm from the actual implementation of the algorithm.</li> <li>When a class has multiple related behaviors, and you want to configure them at runtime.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Strategy/#why-to-use","title":"Why to Use ?","text":"<ul> <li>Avoids code duplication by eliminating repeated conditional logic.</li> <li>Adheres to the Open/Closed principle (open for extension, closed for modification).</li> <li>Promotes modularity and testability since algorithms are in separate classes.</li> <li>Simplifies maintenance by isolating algorithms from the business logic.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Strategy/#when-not-to-use","title":"When Not to Use?","text":"<ul> <li>If the algorithms are not likely to change or only one behavior is needed, adding this pattern would add unnecessary complexity.</li> <li>When performance is critical, and switching algorithms frequently incurs overhead.</li> <li>If the algorithms are trivial and simple, the extra classes and abstractions may not be worth the effort.</li> </ul>"},{"location":"fundamentaldives/DesignPatterns/Strategy/#how-to-implement","title":"How to Implement ?","text":"Simple Example <p>Let\u2019s implement a payment system that allows different payment methods using the Strategy Pattern. We will define multiple payment strategies (like Credit Card and PayPal) and switch between them dynamically.</p> Step-1: Create the Strategy Interface<pre><code>// PaymentStrategy.java\npublic interface PaymentStrategy {\n    void pay(int amount);\n}\n</code></pre> Step-2: Implement Concrete Strategies<pre><code>// CreditCardStrategy.java\npublic class CreditCardStrategy implements PaymentStrategy {\n    private String cardNumber;\n    private String name;\n\n    public CreditCardStrategy(String cardNumber, String name) {\n        this.cardNumber = cardNumber;\n        this.name = name;\n    }\n\n    @Override\n    public void pay(int amount) {\n        System.out.println(amount + \" paid with credit card.\");\n    }\n}\n\n// PayPalStrategy.java\npublic class PayPalStrategy implements PaymentStrategy {\n    private String email;\n\n    public PayPalStrategy(String email) {\n        this.email = email;\n    }\n\n    @Override\n    public void pay(int amount) {\n        System.out.println(amount + \" paid using PayPal.\");\n    }\n}\n</code></pre> Step-3: Create a Context Class<pre><code>// PaymentContext.java\npublic class PaymentContext {\n    private PaymentStrategy strategy;\n\n    public PaymentContext(PaymentStrategy strategy) {\n        this.strategy = strategy;\n    }\n\n    public void setPaymentStrategy(PaymentStrategy strategy) {\n        this.strategy = strategy;\n    }\n\n    public void pay(int amount) {\n        strategy.pay(amount);\n    }\n}\n</code></pre> Step-4: Test the Strategy Pattern<pre><code>public class StrategyPatternDemo {\n    public static void main(String[] args) {\n        PaymentContext context = new PaymentContext(new CreditCardStrategy(\"1234-5678-9012\", \"John Doe\"));\n        context.pay(100);\n\n        // Switch strategy at runtime\n        context.setPaymentStrategy(new PayPalStrategy(\"john.doe@example.com\"));\n        context.pay(200);\n    }\n}\n</code></pre> Spring Boot Example <p>In a Spring Boot application, the Strategy Pattern can be applied by injecting different strategy implementations using Spring\u2019s dependency injection.</p> <p>Let's build a simple notification service where the user can choose between sending notifications via Email or SMS.</p> Create the Strategy Interface<pre><code>// NotificationStrategy.java\npublic interface NotificationStrategy {\n    void sendNotification(String message);\n}\n</code></pre> Implement the Concrete Strategies<pre><code>// EmailNotification.java\nimport org.springframework.stereotype.Service;\n\n@Service(\"email\")\npublic class EmailNotification implements NotificationStrategy {\n    @Override\n    public void sendNotification(String message) {\n        System.out.println(\"Sending Email: \" + message);\n    }\n}\n\n// SMSNotification.java\nimport org.springframework.stereotype.Service;\n\n@Service(\"sms\")\npublic class SMSNotification implements NotificationStrategy {\n    @Override\n    public void sendNotification(String message) {\n        System.out.println(\"Sending SMS: \" + message);\n    }\n}\n</code></pre> Create a Context Class to Use the Strategy<pre><code>// NotificationContext.java\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class NotificationContext {\n\n    private final Map&lt;String, NotificationStrategy&gt; strategies;\n\n    public NotificationContext(Map&lt;String, NotificationStrategy&gt; strategies) {\n        this.strategies = strategies;\n    }\n\n    public void send(String type, String message) {\n        NotificationStrategy strategy = strategies.get(type);\n        if (strategy == null) {\n            throw new IllegalArgumentException(\"No such notification type\");\n        }\n        strategy.sendNotification(message);\n    }\n}\n</code></pre> Create the Controller to Use the Notification Service<pre><code>// NotificationController.java\nimport org.springframework.web.bind.annotation.*;\n\n@RestController\n@RequestMapping(\"/notify\")\npublic class NotificationController {\n\n    private final NotificationContext context;\n\n    public NotificationController(NotificationContext context) {\n        this.context = context;\n    }\n\n    @PostMapping(\"/{type}\")\n    public void sendNotification(@PathVariable String type, @RequestBody String message) {\n        context.send(type, message);\n    }\n}\n</code></pre> Application Configuration and Running<pre><code>// Application.java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class Application {\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n}\n</code></pre> How It Works <ul> <li>NotificationContext uses a Map of NotificationStrategy beans, where the key is the bean name (like <code>email</code> or <code>sms</code>).</li> <li>Spring Boot automatically injects the strategies with the <code>@Service</code> annotation.</li> <li>In the **controller, the appropriate strategy is selected based on the URL path (<code>/notify/email</code> or <code>/notify/sms</code>).</li> </ul> Alternative Ways <p>Using Enum-based Strategies:  If the algorithms are simple and limited, you can use an <code>enum</code> with methods for strategy logic.</p> <pre><code>public enum Operation {\n    ADD {\n        @Override\n        public int execute(int a, int b) {\n            return a + b;\n        }\n    },\n    SUBTRACT {\n        @Override\n        public int execute(int a, int b) {\n            return a - b;\n        }\n    };\n\n    public abstract int execute(int a, int b);\n}\n</code></pre> <p>Using Java 8 Lambdas:  Since Java 8, you can use lambdas to avoid creating multiple strategy classes.</p> <pre><code>import java.util.function.Consumer;\n\npublic class LambdaStrategyDemo {\n    public static void main(String[] args) {\n        Consumer&lt;String&gt; emailStrategy = message -&gt; System.out.println(\"Email: \" + message);\n        Consumer&lt;String&gt; smsStrategy = message -&gt; System.out.println(\"SMS: \" + message);\n\n        emailStrategy.accept(\"Hello via Email!\");\n        smsStrategy.accept(\"Hello via SMS!\");\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/DesignPatterns/Strategy/#summary","title":"Summary","text":"<p>The Strategy Pattern is a powerful way to manage dynamic behavior selection in a clean and decoupled way. In a Spring Boot application, you can easily integrate it by using dependency injection. However, it\u2019s essential to use the pattern wisely to avoid unnecessary complexity or overhead. Use it when multiple behaviors or algorithms need to vary independently without modifying client code. Avoid using it if the added complexity is not justified.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/","title":"Concurrency and Parallelism","text":"<p>Both concurrency and parallelism refer to ways a computer performs multiple tasks, but they differ in how the tasks are executed. Let's go through them, along with related concepts like threads, processes, and programs in this article.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#what-is-process","title":"What is Process ?","text":"<p>A process is an instance of a running program (an executable code). Each process runs in isolation and gets its own memory space. eg: Opening a browser or text editor creates a process.</p> <p>Characteristics</p> <ul> <li>Processes do not share memory by default.</li> <li>Each process has its own address space, file handles, and system resources.</li> <li>Communication between processes is more expensive (requires Inter-Process Communication, like pipes or sockets).</li> </ul>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#what-is-thread","title":"What is Thread ?","text":"<p>A thread is the smallest unit of execution within a process. Threads run within a process and share the same memory space. eg: A web browser might use multiple threads one for rendering pages, one for handling user input, and another for downloading files.</p> <p>Characteristics</p> <ul> <li>Multiple threads within the same process can access the same memory.</li> <li>Lighter than processes since they don\u2019t require their own memory.</li> <li>Threads are managed and scheduled by the operating system or a thread pool.</li> </ul>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#threads-vs-processes","title":"Threads vs Processes","text":"Aspect Threads Processes Memory Space Shared within the same process Separate for each process Overhead Low (lightweight) High (needs its own resources) Communication Easy (shared memory) Complex (requires IPC) Execution Within a single process Each process runs independently Parallelism Can run on multiple cores Can run on multiple cores"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#what-is-concurrency","title":"What is Concurrency ?","text":"<p>Concurrency is when multiple tasks make progress within the same time frame, but not necessarily at the same exact moment. Tasks switch back and forth, sharing resources like CPU time.</p> <p>Analogy</p> <p>It\u2019s like a chef preparing multiple dishes, working on one dish for a few minutes, switching to another, and then returning to the previous dish.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#concurrency-with-threads","title":"Concurrency with Threads","text":"<ul> <li>Multiple threads are interleaved by the operating system to make progress.</li> <li>On a single-core CPU, threads take turns using the CPU, creating the illusion of multitasking.</li> <li>Example: A text editor might have one thread handling keystrokes and another saving your work in the background.</li> </ul>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#concurrency-with-processes","title":"Concurrency with Processes","text":"<ul> <li>Multiple processes can run concurrently by switching between them.</li> <li>Context switching between processes is more expensive since the OS needs to switch memory spaces and system resources.</li> </ul> <p>Note</p> <p>Concurrency focuses on dealing with multiple tasks by time-sharing resources.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#issues-in-concurrency","title":"Issues in Concurrency","text":"<p>Below are key issues associated with concurrency.</p> Race Conditions <p>When two or more threads/processes try to access and modify shared data simultaneously, the final result may depend on the sequence of execution, leading to unpredictable outcomes.  </p> <p>Example: Two bank transactions updating the same account balance at the same time might result in lost updates.</p> <p>How to Mitigate</p> <p>Use synchronization mechanisms like locks or mutexes to control access to shared resources.</p> Deadlocks <p>Occurs when two or more threads/processes block each other by holding resources and waiting for resources held by the other. Example: Process A holds Resource 1 and waits for Resource 2, which is held by Process B, and vice versa.</p> <p>How to Mitigate</p> <p>Use techniques like resource ordering, deadlock detection, or timeouts to avoid deadlocks.</p> Livelock <p>In livelock, threads are constantly changing states to respond to each other but never make actual progress. It\u2019s similar to two people trying to step aside but always stepping in each other\u2019s way. Example: Two threads repeatedly yield control to avoid conflict, but neither progresses.</p> <p>How to Mitigate</p> <p>Add randomness or back-off mechanisms to break the cycle.</p> Starvation <p>A thread or process may be blocked indefinitely because other higher-priority tasks consume all the resources. Example: A low-priority thread never gets CPU time because high-priority threads always take precedence.</p> <p>How to Mitigate</p> <p>Use fair scheduling algorithms to ensure all tasks eventually get a chance to execute.</p> Context Switching Overhead <p>Switching between multiple threads or processes incurs a cost, as the CPU saves and restores the state of each thread. Excessive context switching can reduce performance. Example: An overloaded web server with too many threads may spend more time switching contexts than doing actual work.</p> <p>How to Mitigate</p> <p>Minimize the number of threads and optimize the task scheduling.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#what-is-parallelism","title":"What is Parallelism ?","text":"<p>Parallelism is when multiple tasks are executed simultaneously, usually on different processors or cores.</p> <p>Analogy</p> <p>It\u2019s like having multiple chefs, each cooking one dish at the same time.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#parallelism-with-threads","title":"Parallelism with Threads","text":"<ul> <li>On a multi-core CPU, multiple threads can run truly in parallel, each on a different core.</li> <li>Example: A parallelized program (like video rendering software) might divide the task across multiple threads running on different cores.</li> </ul>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#parallelism-with-processes","title":"Parallelism with Processes","text":"<ul> <li>Similarly, multiple processes can run on multiple cores, each doing different work simultaneously.</li> <li>Example: Running multiple instances of a program like Python interpreters on different cores.</li> </ul> <p>Note</p> <p>Parallelism requires multiple CPUs or cores for real simultaneous execution.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#issues-in-parallelism","title":"Issues in Parallelism","text":"<p>Below are key issues associated with parallelism.</p> Load Imbalance <p>If the workload is not evenly distributed across threads or processes, some cores might remain underutilized while others are overloaded. Example: In a matrix multiplication task, if one thread processes a large chunk and another a small chunk, the first thread might take longer, slowing down the whole task.</p> <p>How to Mitigate</p> <p>Use dynamic load balancing or work stealing techniques to distribute the workload effectively.</p> Scalability Bottlenecks <p>As more threads or processes are added, the overhead of synchronization and communication increases, limiting performance improvements. Example: A program may scale well with 4 threads but show diminishing returns with 16 threads due to synchronization overhead.</p> <p>How to Mitigate</p> <p>Optimize algorithms for scalability and minimize shared resources to reduce synchronization costs.</p> False Sharing <p>Occurs when multiple threads on different cores modify variables that are close in memory, leading to unnecessary cache invalidations and reduced performance. Example: Two threads updating variables in the same cache line can cause frequent cache synchronization, slowing execution.</p> <p>How to Mitigate</p> <p>Align data properly in memory to avoid false sharing.</p> Communication Overhead <p>In parallel systems, threads or processes may need to communicate with each other, which adds overhead. Example: In distributed computing, passing messages between nodes can slow down the computation.</p> <p>How to Mitigate</p> <p>Reduce communication frequency or use message batching techniques to minimize overhead.</p> Debugging and Testing Complexity <p>Debugging concurrent or parallel programs is harder because issues like race conditions or deadlocks may only appear under specific conditions, making them difficult to reproduce. Example: A race condition might only occur when threads execute in a specific order, which is hard to detect in testing.</p> <p>How to Mitigate</p> <p>Use debugging tools like thread analyzers and log events to trace execution paths.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#example-scenarios","title":"Example Scenarios","text":"<p>Concurrent Programming (e.g., in Java, Python)</p> <ul> <li>Threads are used for non-blocking I/O operations, like downloading files while continuing to run the program\u2019s main logic.</li> <li>In asynchronous programming (like with <code>async/await</code> in Python), tasks switch between each other, sharing the same thread.</li> </ul> <p>Parallel Programming (e.g., using Python's multiprocessing or CUDA for GPU computation)</p> <ul> <li>Tasks are divided into multiple processes or threads, each of which executes on a different core for faster performance.</li> <li>Used in tasks like matrix multiplications or large-scale simulations that benefit from simultaneous execution.</li> </ul>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#when-to-use","title":"When to Use ?","text":"<ul> <li>Concurrency: Useful when you need to deal with many tasks at once, like handling user inputs, network requests, or database queries.</li> <li>Parallelism: Ideal for computationally intensive tasks, such as scientific simulations, video processing, or machine learning models.</li> </ul>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#common-issues","title":"Common Issues","text":"Data Consistency and Synchronization <p>Ensuring that shared data remains consistent when accessed by multiple threads or processes is challenging. Example: If multiple threads increment the same counter, the final result may be incorrect without proper synchronization.</p> <p>How to Mitigate</p> <p>Use locks, semaphores, or atomic operations to ensure data consistency.</p> Performance Trade-offs <p>Parallel or concurrent execution does not always lead to better performance. In some cases, overhead from synchronization, communication, and context switching can negate performance gains. Example: A parallel algorithm may run slower on a small dataset due to the overhead of managing multiple threads.</p> <p>How to Mitigate</p> <p>Assess whether the overhead is justified and use profiling tools to analyze performance.</p> Non-Deterministic Behavior <p>In concurrent and parallel systems, the order of execution is not guaranteed, leading to non-deterministic results. Example: Running the same multi-threaded program twice may produce different outcomes, making testing and debugging difficult.</p> <p>How to Mitigate</p> <p>Use locks and barriers carefully, and design programs to tolerate or avoid non-determinism where possible.</p> Resource Contention <p>Threads and processes compete for shared resources, such as memory, I/O, and network bandwidth, leading to bottlenecks. Example: Multiple processes writing to the same disk simultaneously may degrade performance.</p> <p>How to Mitigate</p> <p>Optimize resource usage and avoid unnecessary contention by reducing shared resources.</p>"},{"location":"fundamentaldives/FundamentalConcepts/ConcurrencyParallelism/#summary","title":"Summary","text":"<p>Concurrency deals with multiple tasks making progress within the same period (may or may not be simultaneous) whereas Parallelism deals with tasks running simultaneously on different cores or processors.</p> <p>Processes and threads are core to both concurrency and parallelism, with threads sharing memory within a process and processes running independently with isolated memory.</p> <p>While concurrency and parallelism offer significant benefits, they also come with substantial challenges. Managing issues such as race conditions, deadlocks, false sharing, and debugging complexity requires thoughtful design and appropriate use of synchronization techniques. Additionally, scalability bottlenecks and communication overhead can limit the effectiveness of parallel systems. </p> <p>To mitigate these issues, some fixes are:</p> <ul> <li>Choose appropriate synchronization mechanisms.</li> <li>Use profiling tools (VisualVM for Java) to identify bottlenecks.</li> <li>Balance the trade-offs between concurrency/parallelism and overhead.</li> <li>Test thoroughly under various conditions to catch non-deterministic issues. </li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/DRY/","title":"DRY Principle","text":""},{"location":"fundamentaldives/FundamentalPrinciples/DRY/#what","title":"What ?","text":"<p>The DRY Principle stands for Don\u2019t Repeat Yourself. It is a fundamental software development principle aimed at reducing repetition of code and logic. The main idea is that duplication introduces potential risks, if you need to update logic in multiple places, you might forget some, leading to bugs and inconsistencies. When applied well, it improves maintainability, scalability, and clarity, yupp something that lot of codebases misses.</p> <p>\"Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.\"</p> <p>In other words, the DRY principle encourages developers to write modular, reusable code and avoid duplicating the same functionality in multiple places. It encourages us to minimize redundancy and write code that does one thing well, making our lives (and the lives of those who maintain our code) much easier.</p>"},{"location":"fundamentaldives/FundamentalPrinciples/DRY/#when-to-use","title":"When to Use ?","text":"<ul> <li>When similar code is being reused across multiple places.</li> <li>When there is duplication of logic (same logic split across functions, classes, or layers).</li> <li>When code updates require changing multiple parts of the program at once.</li> <li>In design patterns or utility classes Extract common behavior to avoid redundancy.</li> <li>Database queries, APIs, and validations Avoid repeated queries or repeated validation code.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/DRY/#why-to-use","title":"Why to Use ?","text":"<ul> <li>Improved Maintainability with no duplication, you only need to update code in one place, reducing the risk of errors.</li> <li>Reduced Bug Risks When code is repeated, a bug in one place may go unnoticed in others. DRY ensures consistent logic across the codebase.</li> <li>Better Code Readability as redundant code makes it hard to focus on the real logic. Extracting common behavior enhances clarity.</li> <li>Easier Refactoring as DRY simplifies the process of changing logic. Code is modular and avoids unnecessary redundancy.</li> <li>Encourages Reusability using DRY often leads to utility classes, helper methods, or shared components that can be reused across projects.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/DRY/#when-not-to-use","title":"When Not to Use ?","text":"<ul> <li>Over-abstracting can lead to tightly coupled code. If two pieces of code look similar but serve different purposes, it might not be a good idea to merge them.</li> <li>Don't in micro-optimizations, If extracting code results in decreased performance or introduces complexity, it\u2019s better to keep things simple.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/DRY/#how-to-use-example","title":"How to Use Example ?","text":"<p>Let's cover an example where we apply DRY principle to refactor duplicated logic into reusable.</p> Without DRY (Code Duplication) Example <pre><code>public class OrderService {\n\n    public void placeOrder(int productId, int quantity) {\n        if (quantity &lt;= 0) {\n            throw new IllegalArgumentException(\"Quantity must be greater than zero.\");\n        }\n        // Logic to place order\n        System.out.println(\"Order placed for product: \" + productId);\n    }\n\n    public void cancelOrder(int orderId) {\n        if (orderId &lt;= 0) {\n            throw new IllegalArgumentException(\"Order ID must be greater than zero.\");\n        }\n        // Logic to cancel order\n        System.out.println(\"Order cancelled: \" + orderId);\n    }\n\n    public void updateOrder(int orderId, int quantity) {\n        if (orderId &lt;= 0) {\n            throw new IllegalArgumentException(\"Order ID must be greater than zero.\");\n        }\n        if (quantity &lt;= 0) {\n            throw new IllegalArgumentException(\"Quantity must be greater than zero.\");\n        }\n        // Logic to update order\n        System.out.println(\"Order updated with new quantity: \" + quantity);\n    }\n}\n</code></pre> Explanation <ul> <li>The validation logic is duplicated across multiple methods (<code>placeOrder</code>, <code>cancelOrder</code>, and <code>updateOrder</code>).</li> <li>If we want to change the validation rule, we need to update all the occurrences.</li> <li>This is a maintenance burden and prone to bugs.</li> </ul> <p>We can extract the common logic into a reusable private method to apply the DRY principle.</p> With DRY (Refactored Code) Example <pre><code>public class OrderService {\n\n    public void placeOrder(int productId, int quantity) {\n        validateQuantity(quantity);\n        // Logic to place order\n        System.out.println(\"Order placed for product: \" + productId);\n    }\n\n    public void cancelOrder(int orderId) {\n        validateOrderId(orderId);\n        // Logic to cancel order\n        System.out.println(\"Order cancelled: \" + orderId);\n    }\n\n    public void updateOrder(int orderId, int quantity) {\n        validateOrderId(orderId);\n        validateQuantity(quantity);\n        // Logic to update order\n        System.out.println(\"Order updated with new quantity: \" + quantity);\n    }\n\n    // Reusable validation methods\n    private void validateOrderId(int orderId) {\n        if (orderId &lt;= 0) {\n            throw new IllegalArgumentException(\"Order ID must be greater than zero.\");\n        }\n    }\n\n    private void validateQuantity(int quantity) {\n        if (quantity &lt;= 0) {\n            throw new IllegalArgumentException(\"Quantity must be greater than zero.\");\n        }\n    }\n}\n</code></pre> Explanation <ul> <li>We removed the duplicated validation code and moved it into dedicated reusable methods (<code>validateOrderId</code> and <code>validateQuantity</code>).</li> <li>Now, if we need to change the validation logic, we only have to update it in one place.</li> <li>The code is easier to read, maintain, and extend.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/DRY/#summary","title":"Summary","text":"<p>The DRY principle ensures that code duplication is minimized for easier maintenance and improved consistency. In our example, we extracted common validation logic to private methods, adhering to DRY and making the code more maintainable. However, always be careful to avoid over-abstraction, as not all code repetition is bad. The goal is to achieve a balance between simplicity and reusability.</p>"},{"location":"fundamentaldives/FundamentalPrinciples/KISS/","title":"KISS Principle","text":""},{"location":"fundamentaldives/FundamentalPrinciples/KISS/#what","title":"What ?","text":"<p>The KISS Principle stands for \"Keep It Simple, Stupid\". It\u2019s a design principle that emphasizes simplicity, stating that systems and code work best if they are kept simple rather than made unnecessarily complex. The main idea is to avoid over-engineering and unnecessary complications, which can introduce more bugs, make the code harder to maintain, and increase development time.</p> <p>KISS encourages developers to create code or solutions that are easy to understand, maintain, and modify. The idea is not to use complicated approaches or unnecessary abstractions when a simpler, more straightforward approach will do.</p> <p>\u201cSimple\u201d here doesn\u2019t mean incomplete or simplistic it means clear, focused, and straightforward.</p>"},{"location":"fundamentaldives/FundamentalPrinciples/KISS/#when-to-use","title":"When to Use ?","text":"<ul> <li>When you\u2019re writing code that other developers (or future you) will need to understand.</li> <li>In code that needs to be maintainable over time.</li> <li>For small to medium-sized projects, where simplicity ensures agility.</li> <li>When performance and maintainability are both important.</li> <li>When solving common, straightforward problems (CRUD operations, data validation, etc.).</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/KISS/#why-to-use","title":"Why to Use ?","text":"<ul> <li>Improves code readability as Simple code is easier to read and understand.</li> <li>Reduces bugs as The fewer moving parts, the fewer the chances of introducing errors.</li> <li>Facilitates maintenance as Developers can modify simple code more easily.</li> <li>Encourages reusability as Simple, well-factored code is more likely to be reusable.</li> <li>Reduces development time as Simple code can be implemented and tested faster.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/KISS/#where-not-to-use","title":"Where Not to Use ?","text":"<p>While simplicity is valuable, there are situations where the KISS principle might not apply fully. Over-simplifying can sometimes lead to problems.</p> <ul> <li>Systems like distributed architectures or cryptographic algorithms require a level of complexity. Oversimplifying might compromise functionality or security.</li> <li>In some cases, optimizations (like using caching or multi-threading) introduce complexity but are essential for performance. Blindly following KISS might result in suboptimal code.</li> <li>In large-scale software projects, abstractions (even though they introduce some complexity) are necessary to manage dependencies and maintain modularity.</li> <li>Security systems often require additional layers of checks and validation that might seem complex. Simplifying such code could introduce vulnerabilities.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/KISS/#how-to-use-in-practice","title":"How to Use in Practice ?","text":"<ul> <li>Implement the most straightforward solution to a problem first.</li> <li>If the code grows complex, break it down into smaller, manageable pieces.</li> <li>Don\u2019t use design patterns or abstractions unless they add real value.</li> <li>Use standard, well-known patterns unless there is a strong reason to deviate.</li> <li>Clear names for variables, methods, and classes contribute to simplicity.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/KISS/#how-to-use-example","title":"How to Use Example ?","text":"<p>Let's Consider a example where we want to check if a number is even or odd.</p> Non-KISS Complex Code <pre><code>public class NumberUtils {\n    public static boolean isEven(int number) {\n        return isDivisibleByTwo(number);\n    }\n\n    private static boolean isDivisibleByTwo(int number) {\n        if (number % 2 == 0) {\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n    public static void main(String[] args) {\n        System.out.println(\"Is 4 even? \" + isEven(4));\n    }\n}\n</code></pre> Explanation <ul> <li>This version introduces unnecessary complexity by creating a separate method <code>isDivisibleByTwo</code>.</li> <li>It complicates the readability without adding value.</li> <li>While technically correct, the design violates the KISS principle because the same functionality could have been achieved more simply.</li> </ul> KISS Simpler Code <pre><code>public class NumberUtils {\n    public static boolean isEven(int number) {\n        return number % 2 == 0;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(\"Is 4 even? \" + isEven(4));\n    }\n}\n</code></pre> Explanation <ul> <li>This version keeps things simple and easy to understand. </li> <li>The code is self-explanatory without unnecessary indirection.</li> <li>It follows the KISS principle by doing the task in the simplest way possible while still being clear and functional.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/KISS/#summary","title":"Summary","text":"<p>The KISS principle encourages developers to create simple, maintainable, and readable code, it means avoiding unnecessary complexity. However, KISS must be balanced some projects or scenarios require complexity to meet performance, modularity, or security needs. In the end, applying KISS is about striking the right balance making the solution as simple as possible, but not simpler than necessary.</p>"},{"location":"fundamentaldives/FundamentalPrinciples/SOLID/","title":"SOLID Principles","text":""},{"location":"fundamentaldives/FundamentalPrinciples/SOLID/#single-responsibility-principle","title":"Single Responsibility Principle","text":"<p>A class should have only one reason to change. This means that each class should focus on a single responsibility or feature.</p> Violation Example <pre><code>// Violates SRP: User class has multiple responsibilities.\npublic class User {\n    private String name;\n    private String email;\n\n    public void sendEmail(String message) {\n        // Sending email logic here...\n        System.out.println(\"Email sent to \" + email);\n    }\n\n    public void saveUser() {\n        // Save user to the database\n        System.out.println(\"User saved to DB\");\n    }\n}\n</code></pre> Fixed Example <pre><code>// Separate responsibilities into different classes.\npublic class User {\n    private String name;\n    private String email;\n\n    // Getters and setters...\n}\n\npublic class UserRepository {\n    public void save(User user) {\n        System.out.println(\"User saved to DB\");\n    }\n}\n\npublic class EmailService {\n    public void sendEmail(User user, String message) {\n        System.out.println(\"Email sent to \" + user.getEmail());\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/FundamentalPrinciples/SOLID/#open-closed-principle","title":"Open Closed Principle","text":"<p>Software components (classes, functions, etc.) should be open for extension but closed for modification. You shouldn\u2019t modify existing code to add new behavior instead, extend it.</p> Violation Example <pre><code>// Violates OCP: PaymentProcessor needs to be modified for new payment types.\npublic class PaymentProcessor {\n    public void pay(String type) {\n        if (type.equals(\"credit\")) {\n            System.out.println(\"Processing credit card payment...\");\n        } else if (type.equals(\"paypal\")) {\n            System.out.println(\"Processing PayPal payment...\");\n        }\n    }\n}\n</code></pre> Fixed Example <pre><code>// Use an interface for extensibility.\ninterface PaymentMethod {\n    void pay();\n}\n\npublic class CreditCardPayment implements PaymentMethod {\n    public void pay() {\n        System.out.println(\"Processing credit card payment...\");\n    }\n}\n\npublic class PayPalPayment implements PaymentMethod {\n    public void pay() {\n        System.out.println(\"Processing PayPal payment...\");\n    }\n}\n\npublic class PaymentProcessor {\n    public void processPayment(PaymentMethod paymentMethod) {\n        paymentMethod.pay();\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/FundamentalPrinciples/SOLID/#liskov-substitution-principle","title":"Liskov Substitution Principle","text":"<p>Subclasses should be substitutable for their base class without altering the correctness of the program.</p> Violation Example <pre><code>// Violates LSP: Square changes the behavior of Rectangle.\nclass Rectangle {\n    protected int width, height;\n\n    public void setWidth(int width) {\n        this.width = width;\n    }\n\n    public void setHeight(int height) {\n        this.height = height;\n    }\n\n    public int getArea() {\n        return width * height;\n    }\n}\n\nclass Square extends Rectangle {\n    @Override\n    public void setWidth(int width) {\n        this.width = width;\n        this.height = width;  // Violates LSP: Unexpected behavior.\n    }\n\n    @Override\n    public void setHeight(int height) {\n        this.width = height;\n        this.height = height;\n    }\n}\n</code></pre> Fixed Example <pre><code>// Use separate classes to maintain correct behavior.\nclass Shape {\n    public int getArea() {\n        return 0;\n    }\n}\n\nclass Rectangle extends Shape {\n    protected int width, height;\n\n    public Rectangle(int width, int height) {\n        this.width = width;\n        this.height = height;\n    }\n\n    @Override\n    public int getArea() {\n        return width * height;\n    }\n}\n\nclass Square extends Shape {\n    private int side;\n\n    public Square(int side) {\n        this.side = side;\n    }\n\n    @Override\n    public int getArea() {\n        return side * side;\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/FundamentalPrinciples/SOLID/#interface-segregation-principle","title":"Interface Segregation Principle","text":"<p>A client should not be forced to implement interfaces that it does not use. Instead, smaller, more specific interfaces should be preferred.</p> Violation Example <pre><code>// Violates ISP: Cat(r) needs to implement unnecessary methods.\ninterface Vehicle {\n    void drive();\n    void fly();\n}\n\nclass Car implements Vehicle {\n    @Override\n    public void drive() {\n        System.out.println(\"Car is driving...\");\n    }\n\n    @Override\n    public void fly() {\n        // Car can't fly! This method is unnecessary.\n        throw new UnsupportedOperationException(\"Car can't fly\");\n    }\n}\n</code></pre> Fixed Example <pre><code>// Use separate interfaces for each capability.\ninterface Drivable {\n    void drive();\n}\n\ninterface Flyable {\n    void fly();\n}\n\nclass Car implements Drivable {\n    @Override\n    public void drive() {\n        System.out.println(\"Car is driving...\");\n    }\n}\n\nclass Plane implements Drivable, Flyable {\n    @Override\n    public void drive() {\n        System.out.println(\"Plane is taxiing...\");\n    }\n\n    @Override\n    public void fly() {\n        System.out.println(\"Plane is flying...\");\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/FundamentalPrinciples/SOLID/#dependency-inversion-principle","title":"Dependency Inversion Principle","text":"<p>High-level modules should not depend on low-level modules. Both should depend on abstractions.</p> Violation Example <pre><code>// Violates DIP: High-level class depends on a specific implementation.\nclass SQLDatabase {\n    public void connect() {\n        System.out.println(\"Connected to SQL Database\");\n    }\n}\n\nclass Application {\n    private SQLDatabase database;\n\n    public Application() {\n        database = new SQLDatabase();  // Tight coupling to SQLDatabase.\n    }\n\n    public void start() {\n        database.connect();\n    }\n}\n</code></pre> Fixed Example <pre><code>// Depend on an abstraction instead of a specific implementation.\ninterface Database {\n    void connect();\n}\n\nclass SQLDatabase implements Database {\n    public void connect() {\n        System.out.println(\"Connected to SQL Database\");\n    }\n}\n\nclass NoSQLDatabase implements Database {\n    public void connect() {\n        System.out.println(\"Connected to NoSQL Database\");\n    }\n}\n\nclass Application {\n    private Database database;\n\n    public Application(Database database) {\n        this.database = database;\n    }\n\n    public void start() {\n        database.connect();\n    }\n}\n</code></pre>"},{"location":"fundamentaldives/FundamentalPrinciples/SOLID/#summary","title":"Summary","text":"Principle Definition Violation Example Fixed Example Single Responsibility A class should have only one reason to change. User class manages both data and emails. Separate <code>User</code>, <code>EmailService</code>, <code>UserRepository</code>. Open Closed Open for extension, closed for modification. Modify <code>PaymentProcessor</code> for new methods. Use <code>PaymentMethod</code> interface and extend classes. Liskov Substitution Subtypes should behave like their base type. <code>Square</code> modifies behavior of <code>Rectangle</code>. Separate <code>Square</code> and <code>Rectangle</code> classes. Interface Segregation Use small, specific interfaces. Car implements unnecessary <code>fly()</code> method. Split into <code>Drivable</code> and <code>Flyable</code> interfaces. Dependency Inversion Depend on abstractions, not implementations. App depends on <code>SQLDatabase</code> directly. Use <code>Database</code> interface for loose coupling."},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/","title":"YAGNI Principle","text":""},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#what","title":"What ?","text":"<p>YAGNI stands for \"You Aren\u2019t Gonna Need It.\" It is one of the core principles of Extreme Programming (XP) and Agile development. The principle advises developers not to add any functionality or code until it is truly needed. Essentially, YAGNI promotes simplicity and avoids speculative development.</p> <p>Always implement things when you actually need them, never when you just foresee you might need them.</p>"},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#why-use","title":"Why Use ?","text":"<ul> <li>Reduces Complexity as unused code can make the codebase harder to maintain.</li> <li>Saves Time as developers avoid spending time on features that might never be used.</li> <li>Reduces Maintenance Costs as Every piece of code adds maintenance overhead.</li> <li>Improves Focus as Teams stay focused on current requirements.</li> <li>Prevents Waste as You avoid wasting resources on unused or unnecessary functionality.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#when-to-use","title":"When to Use ?","text":"<ul> <li>During the early stages of software development when requirements are still evolving.</li> <li>In Agile or lean development methodologies, where the focus is on delivering working software quickly and iteratively.</li> <li>When planning features or writing code always ask, \u201cDo we need this now?\u201d If not, avoid implementing it.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#when-not-to-use","title":"When Not to Use ?","text":"<ul> <li>When designing core architecture You still need some foresight to design scalable systems. For example, if your product will likely need scalability soon, adding some basic support might be necessary. A good architecture sometimes requires forward-thinking to avoid technical debt.</li> <li>When working with security, compliance, or performance In certain domains, adding some safeguards or optimizations upfront is critical.</li> <li>In libraries or frameworks Sometimes, developers of reusable components need to anticipate needs of others.</li> <li>In infrastructure planning Systems like databases and message queues need to be built for the scale they might soon reach.</li> <li>In performance-critical applications, you might need to optimize upfront rather than waiting for problems to arise.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#how-to-apply","title":"How to Apply ?","text":"<ul> <li>Focus on immediate requirements Write only the code needed to solve the problem at hand.</li> <li>Iterate frequently in Agile environments, deliver small but functional increments.</li> <li>Review code regularly ensures developers are not adding speculative code.</li> <li>Practice Test Driven Development (TDD).</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#advantages","title":"Advantages","text":"<ul> <li>Faster Development By focusing only on what is necessary, development cycles are shorter.</li> <li>Easier Maintenance Less code means fewer bugs and easier updates.</li> <li>Lower Costs, Saves time, resources, and effort.</li> <li>Improved Team Efficiency Developers stay focused on real requirements.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#how-to-use-example","title":"How to Use Example ?","text":"<p>Lets go through a simple example to illustrate YAGNI in practice.</p> Without YAGNI Example Adding Unnecessary Functionality<pre><code>public class UserService {\n\n    // Current functionality: Retrieve a user by ID\n    public User getUserById(int id) {\n        // Logic to retrieve user\n        return new User(id, \"John Doe\");\n    }\n\n    // Unnecessary feature: Speculating that we may need a \"deleteUser\" method in the future\n    public void deleteUser(int id) {\n        // Logic to delete user (unimplemented)\n        System.out.println(\"User deleted: \" + id);\n    }\n\n    // Another unnecessary feature: Thinking we might need email notifications\n    public void sendEmailNotification(User user) {\n        // Logic to send email (unimplemented)\n        System.out.println(\"Email sent to: \" + user.getEmail());\n    }\n}\n\nclass User {\n    private int id;\n    private String name;\n\n    public User(int id, String name) {\n        this.id = id;\n        this.name = name;\n    }\n\n    public String getEmail() {\n        return name.toLowerCase() + \"@example.com\";\n    }\n}\n</code></pre> Explanation <ul> <li>A <code>deleteUser()</code> method.</li> <li>A <code>sendEmailNotification()</code> method.</li> <li>These methods were added prematurely, based on an assumption that they might be needed. This is a violation of the YAGNI principle. </li> </ul> Applying YAGNI Only Implement What is Needed Now<pre><code>public class UserService {\n\n    // Only add the necessary method for now\n    public User getUserById(int id) {\n        // Logic to retrieve user\n        return new User(id, \"John Doe\");\n    }\n}\n\nclass User {\n    private int id;\n    private String name;\n\n    public User(int id, String name) {\n        this.id = id;\n        this.name = name;\n    }\n}\n</code></pre> Explanation <ul> <li>We only implement the necessary functionality retrieving a user by ID.</li> <li>We avoid premature code like <code>deleteUser()</code> or <code>sendEmailNotification()</code>.</li> <li>If, in the future, we do need a <code>deleteUser()</code> or notification feature, we can implement it when it becomes necessary.</li> </ul>"},{"location":"fundamentaldives/FundamentalPrinciples/YAGNI/#summary","title":"Summary","text":"<p>The YAGNI principle encourages developers to focus on delivering only the required features at a given point in time, avoiding speculative development that may never be used. This approach fosters simplicity, maintainability, and efficiency in the codebase. However, it should be applied carefully there are scenarios (like architecture or security) where anticipating needs is necessary, When used properly, YAGNI helps teams build better software, faster, and with fewer headaches down the line.</p>"},{"location":"langdives/Java/4Pillars/","title":"4 Pillars - What, How, and Why ?","text":""},{"location":"langdives/Java/4Pillars/#encapsulation","title":"Encapsulation","text":"<p>What: Hiding the internal details of an object and only exposing necessary parts through public methods.</p> <p>Why: It helps in data hiding and ensures controlled access to variables.</p> <p>How: Use private variables to restrict direct access and provide getters and setters to access and modify the data.</p> Encapsulation Example <pre><code>public class Person {\n    private String name; // Encapsulated field\n\n    // Getter\n    public String getName() {\n        return name;\n    }\n\n    // Setter\n    public void setName(String name) {\n        this.name = name;\n    }\n}\n</code></pre>"},{"location":"langdives/Java/4Pillars/#inheritance","title":"Inheritance","text":"<p>What: Allows a class (child/subclass) to acquire the properties and behaviors of another class (parent/superclass).</p> <p>How: Use the <code>extends</code> keyword.</p> <p>Why: Promotes code reusability and establishes a parent-child relationship.</p> Inheritance Example <pre><code>class Animal {\n    public void sound() {\n        System.out.println(\"Animals make sound\");\n    }\n}\n\nclass Dog extends Animal {\n    @Override\n    public void sound() {\n        System.out.println(\"Dog barks\");\n    }\n}\n</code></pre>"},{"location":"langdives/Java/4Pillars/#polymorphism","title":"Polymorphism","text":"<p>What: Ability to process objects differently based on their data type or class.</p> <ul> <li>Compile-time polymorphism: Method overloading (same method name, different parameters).</li> <li>Runtime polymorphism: Method overriding (subclass redefines a method of the superclass).</li> </ul> <p>Why: Increases flexibility and supports dynamic method invocation.</p> Polymorphism Example Method Overloading<pre><code>class Calculator {\n    public int add(int a, int b) {\n        return a + b;\n    }\n\n    public double add(double a, double b) {\n        return a + b;\n    }\n}\n</code></pre> Method Overriding<pre><code>class Animal {\n    public void sound() {\n        System.out.println(\"Animal makes sound\");\n    }\n}\n\nclass Cat extends Animal {\n    @Override\n    public void sound() {\n        System.out.println(\"Cat meows\");\n    }\n}\n</code></pre>"},{"location":"langdives/Java/4Pillars/#abstraction","title":"Abstraction","text":"<p>What: Hiding the complex implementation details and only exposing the essential features.</p> <p>Why: Helps in achieving modularity and loose coupling between components.</p> <p>How: Use abstract classes and interfaces.</p> Abstraction Example Abstract Class Example<pre><code>abstract class Vehicle {\n    abstract void start();\n}\n\nclass Car extends Vehicle {\n    @Override\n    void start() {\n        System.out.println(\"Car starts with a key\");\n    }\n}\n</code></pre> Interface Example<pre><code>interface Animal {\n    void eat();\n}\n\nclass Dog implements Animal {\n    @Override\n    public void eat() {\n        System.out.println(\"Dog eats bones\");\n    }\n}\n</code></pre>"},{"location":"langdives/Java/4Pillars/#summary","title":"Summary","text":"Aspect Encapsulation Inheritance Polymorphism Abstraction Definition Bundling data and methods together and restricting access to data. Mechanism for a subclass to acquire properties of a parent class. Allowing methods to take different forms (overloading/overriding). Hiding implementation details while showing only essential features. Focus Protecting data and providing controlled access. Code reuse and establishing a parent-child hierarchy. Dynamic behavior based on object type. Simplifying complex systems by exposing only key details. Achieved Through Using private fields, and public getters/setters. Using the <code>extends</code> keyword to derive subclasses. Overloading (compile-time) and overriding (runtime). Using <code>abstract</code> classes or <code>interfaces</code>. Key Benefit Data hiding and modular code. Reduces redundancy and promotes code reuse. Flexibility and extensibility of behavior. Promotes loose coupling and modularity. Access Modifiers Requires <code>private</code>, <code>protected</code>, or <code>public</code>. Involves all inheritance-accessible modifiers. Leverages method visibility across class hierarchies. Abstract methods can be <code>protected</code> or <code>public</code> (not private). Real-World Analogy A capsule with medicine inside it hides the internal components. A child inheriting traits from their parents. A shape object behaving differently as circle/square. A remote control exposing buttons without showing internal circuits. Code Dependency Independent within the class. Dependent on parent-child relationship. Involves multiple forms of a single method/class. Can work with unrelated classes sharing common behavior."},{"location":"langdives/Java/AccessModifPPPPP/","title":"Access modifiers","text":""},{"location":"langdives/Java/AccessModifPPPPP/#public","title":"Public","text":"<p>Keyword: <code>public</code> Access: Accessible from anywhere (inside/outside the class, package, or project). Usage: Typically used for classes, methods, and variables that need global access.  </p> Public Example <pre><code>public class MyClass {\n    public int value = 10;\n    public void display() {\n        System.out.println(\"Public method\");\n    }\n}\n</code></pre>"},{"location":"langdives/Java/AccessModifPPPPP/#private","title":"Private","text":"<p>Keyword: <code>private</code> Access: Accessible only within the same class. Usage: Used to hide class fields or methods, following the principle of encapsulation.  </p> Private Example <pre><code>public class MyClass {\n    private int value = 10; // Not accessible outside this class\n\n    private void display() {\n        System.out.println(\"Private method\");\n    }\n}\n</code></pre>"},{"location":"langdives/Java/AccessModifPPPPP/#protected","title":"Protected","text":"<p>Keyword: <code>protected</code> Access: Accessible within the same package and by subclasses (even if outside the package). Usage: Useful when extending classes across packages.  </p> Protected Example <pre><code>public class MyClass {\n    protected int value = 10;\n\n    protected void display() {\n        System.out.println(\"Protected method\");\n    }\n}\n</code></pre> <p>Note</p> <p>If accessed by a subclass in a different package, it must be through inheritance (not directly via an instance).</p>"},{"location":"langdives/Java/AccessModifPPPPP/#package-private","title":"Package-Private","text":"<p>Keyword: No keyword  (Default Access) Access: Accessible only within the same package. Usage: Used for classes and members that don\u2019t need to be accessed outside their package.  </p> Package-Private Example <pre><code>class MyClass { // No access modifier, so it's package-private\n    int value = 10;\n\n    void display() {\n        System.out.println(\"Package-private method\");\n    }\n}\n</code></pre> <p>Note</p> <p>Package-private is the default if no modifier is specified.</p>"},{"location":"langdives/Java/AccessModifPPPPP/#access-summary","title":"Access Summary","text":"Modifier Same Class Same Package Subclass (Different Package) Other Packages <code>public</code> \u2705 \u2705 \u2705 \u2705 <code>protected</code> \u2705 \u2705 \u2705 (via inheritance) \u274c (default) \u2705 \u2705 \u274c \u274c <code>private</code> \u2705 \u274c \u274c \u274c"},{"location":"langdives/Java/Collections-JCF/","title":"Java Collections Framework","text":""},{"location":"langdives/Java/Collections-JCF/#categories-of-collections","title":"Categories of Collections","text":"<ul> <li>List: Ordered, allows duplicates.</li> <li>Set: Unordered, no duplicates.</li> <li>Queue/Deque: FIFO or LIFO order.</li> <li>Map: Stores key-value pairs.</li> <li>Utility Collections: Collections with special behavior, eg: <code>Collections.synchronizedList()</code>.</li> </ul>"},{"location":"langdives/Java/Collections-JCF/#list","title":"List","text":""},{"location":"langdives/Java/Collections-JCF/#arraylist","title":"ArrayList","text":"<p>A resizable array, fast random access. It's backed by Array, When random access is needed and insertions are rare you can use this.</p> <p>Operations &amp; Complexities</p> <ul> <li>Access by Index: <code>O(1)</code> </li> <li>Insertion (end): <code>O(1)</code> (amortized)  </li> <li>Insertion (middle): <code>O(n)</code> </li> <li>Space Complexity: <code>O(n)</code> </li> </ul> <p>Thread Safety:  Not synchronized, use <code>Collections.synchronizedList()</code> for thread safety.</p> ArrayList Example <pre><code>List&lt;String&gt; list = new ArrayList&lt;&gt;();\nlist.add(\"Apple\");\nlist.get(0);  // Fast access\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#linkedlist","title":"LinkedList","text":"<p>A Doubly linked list, better at frequent insertions and deletions. It's backed by Doubly Linked List, When insertion/deletion in the middle is frequent you can use this.</p> <p>Operations &amp; Complexities</p> <ul> <li>Access by Index: <code>O(n)</code> </li> <li>Insertion/Deletion: <code>O(1)</code> (at head or tail)  </li> <li>Space Complexity: <code>O(n)</code></li> </ul> <p>Thread Safety: Not synchronized.</p> LinkedList Example <pre><code>List&lt;String&gt; list = new LinkedList&lt;&gt;();\nlist.add(\"Banana\");\nlist.addFirst(\"Apple\");  // O(1) insertion at head\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#set","title":"Set","text":""},{"location":"langdives/Java/Collections-JCF/#hashset","title":"HashSet","text":"<p>It's Unordered, no duplicates, backed by Hash Table. You can use this When you need fast lookups and no duplicates.</p> <p>Operations &amp; Complexities</p> <ul> <li>Add/Remove/Contains: <code>O(1)</code> (on average)  </li> <li>Space Complexity: <code>O(n)</code></li> </ul> <p>Thread Safety: Not synchronized, use <code>Collections.synchronizedSet()</code>.</p> HashSet Example <pre><code>Set&lt;String&gt; set = new HashSet&lt;&gt;();\nset.add(\"Cat\");\nset.add(\"Dog\");\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#linkedhashset","title":"LinkedHashSet","text":"<p>This maintains insertion order, backed by a Hash Table + Linked List. You can use this when you need order-preserving behavior.</p> <p>Operations &amp; Complexities: Same as HashSet (<code>O(1)</code> operations) but with slightly higher overhead due to linked list maintenance.</p> LinkedHashSet Example <pre><code>Set&lt;String&gt; set = new LinkedHashSet&lt;&gt;();\nset.add(\"Apple\");\nset.add(\"Banana\");\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#treeset","title":"TreeSet","text":"<p>A Sorted set, backed by Red-Black Tree, When you need sorted data.</p> <p>Operations &amp; Complexities</p> <ul> <li>Add/Remove/Contains: <code>O(log n)</code> </li> <li>Space Complexity: <code>O(n)</code></li> </ul> <p>Thread Safety: Not synchronized.</p> TreeSet Example <pre><code>Set&lt;Integer&gt; set = new TreeSet&lt;&gt;();\nset.add(5);\nset.add(1);  // Sorted automatically\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#queuedeque","title":"Queue/Deque","text":""},{"location":"langdives/Java/Collections-JCF/#priorityqueue","title":"PriorityQueue","text":"<p>Elements are ordered based on their natural order or a custom comparator. It's backed by Binary Heap, When priority-based retrieval is needed.</p> <p>Operations &amp; Complexities</p> <ul> <li>Insertion: <code>O(log n)</code> </li> <li>Access (peek): <code>O(1)</code> </li> <li>Remove (poll): <code>O(log n)</code> </li> </ul> PriorityQueue Example <pre><code>Queue&lt;Integer&gt; queue = new PriorityQueue&lt;&gt;();\nqueue.add(10);\nqueue.add(5);  // 5 will be at the top\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#arraydeque","title":"ArrayDeque","text":"<p>Resizable-array-backed deque, allows adding/removing from both ends, When you need both stack and queue operations.</p> <p>Operations &amp; Complexities</p> <ul> <li>Add/Remove (head/tail): <code>O(1)</code> </li> <li>Space Complexity: <code>O(n)</code></li> </ul> ArrayDeque Example <pre><code>Deque&lt;String&gt; deque = new ArrayDeque&lt;&gt;();\ndeque.addFirst(\"First\");\ndeque.addLast(\"Last\");\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#map","title":"Map","text":""},{"location":"langdives/Java/Collections-JCF/#hashmap","title":"HashMap","text":"<p>Stores key-value pairs, backed by Hash Table, Fast lookups for key-value pairs.</p> <p>Operations &amp; Complexities</p> <ul> <li>Get/Put/Remove: <code>O(1)</code> (average)  </li> <li>Space Complexity: <code>O(n)</code></li> </ul> <p>Thread Safety: Not synchronized, use <code>ConcurrentHashMap</code> for thread-safe operations.</p> HashMap Example <pre><code>Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();\nmap.put(\"Apple\", 1);\nmap.put(\"Banana\", 2);\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#linkedhashmap","title":"LinkedHashMap","text":"<p>Maintains insertion order, backed by Hash Table + Linked List, When ordering of entries matters.</p> LinkedHashMap Example <pre><code>Map&lt;String, Integer&gt; map = new LinkedHashMap&lt;&gt;();\nmap.put(\"Apple\", 1);\nmap.put(\"Banana\", 2);  // Maintains insertion order\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#treemap","title":"TreeMap","text":"<p>Sorted map, backed by Red-Black Tree, When you need a sorted key-value store.</p> <p>Operations &amp; Complexities: Get/Put/Remove: <code>O(log n)</code> </p> TreeMap Example <pre><code>Map&lt;Integer, String&gt; map = new TreeMap&lt;&gt;();\nmap.put(3, \"Three\");\nmap.put(1, \"One\");  // Sorted by key\n</code></pre>"},{"location":"langdives/Java/Collections-JCF/#synchronized-collections","title":"Synchronized Collections","text":"<p>Synchronized Wrappers: Use <code>Collections.synchronizedList()</code> or <code>Collections.synchronizedSet()</code> to make collections thread-safe.</p> Collections Synchronized Wrapper Example <pre><code>List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;());\n</code></pre> <p>Concurrent Collections: Use <code>ConcurrentHashMap</code>, <code>CopyOnWriteArrayList</code>, or <code>BlockingQueue</code> for better thread-safe alternatives.</p>"},{"location":"langdives/Java/Collections-JCF/#summary","title":"Summary","text":"Collection Type Backed By Access Time Insertion Time Deletion Time Thread Safety Use Case ArrayList List Resizable Array O(1) O(1) (amortized) O(n) No Fast random access LinkedList List Doubly Linked List O(n) O(1) O(1) No Frequent insertions/deletions HashSet Set Hash Table - O(1) O(1) No Unique elements LinkedHashSet Set Hash Table + Linked List - O(1) O(1) No Unique elements with insertion order TreeSet Set Red-Black Tree - O(log n) O(log n) No Sorted elements PriorityQueue Queue Binary Heap - O(log n) O(log n) No Priority-based retrieval ArrayDeque Deque Resizable Array - O(1) O(1) No Both stack and queue operations HashMap Map Hash Table - O(1) O(1) No Fast key-value lookups LinkedHashMap Map Hash Table + Linked List - O(1) O(1) No Key-value lookups with insertion order TreeMap Map Red-Black Tree - O(log n) O(log n) No Sorted key-value pairs ConcurrentHashMap Concurrent Map Segmented Hash Table O(1) O(1) O(1) Yes Thread-safe map CopyOnWriteArrayList Concurrent List Array O(n) O(1) O(1) Yes Thread-safe list BlockingQueue Concurrent Queue Queue/Linked Nodes Depends on impl. O(1) O(1) Yes Thread-safe queue"},{"location":"langdives/Java/GarbageCollection/","title":"Garbage Collection","text":"<p>Garbage collection (GC) in Java is essential to automatic memory management, ensuring that objects no longer needed by an application are reclaimed, and the memory they occupied is freed. This allows Java developers to avoid memory leaks and other resource-management issues.</p>"},{"location":"langdives/Java/GarbageCollection/#basics","title":"Basics","text":"<p>Heap Memory is divided into several areas, mainly</p> <ul> <li>Young Generation: Where new objects are created.</li> <li>Old Generation (Tenured): Stores objects that survived multiple GC cycles.</li> <li>Metaspace: Stores class metadata (since Java 8, replaces the old PermGen).</li> </ul> <p>How GC Works ? Simply GC works by going through phases </p> <ul> <li>GC identifies objects that are no longer reachable from the program.</li> <li>References from the roots (like static variables, thread-local variables, or stack variables) determine reachability.</li> <li>If an object is not reachable by any live references, it becomes eligible for collection.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#phases","title":"Phases","text":"<ul> <li>Mark Phase: The GC algorithm starts by marking all reachable objects from the GC roots.</li> <li>Sweep Phase: All unmarked objects are cleared, and their memory is reclaimed.</li> <li>Compact Phase (optional): Some collectors perform heap compaction to defragment memory and avoid fragmentation issues.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#types-of-collectors","title":"Types of Collectors","text":""},{"location":"langdives/Java/GarbageCollection/#serial-garbage-collector","title":"Serial Garbage Collector","text":"<ul> <li>Use case: Single-threaded environments (small applications).</li> <li>Working: It uses a single thread for both young and old generations, freezing all application threads during collection (stop-the-world).</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#parallel-garbage-collector","title":"Parallel Garbage Collector","text":"<ul> <li>Use case: Multi-threaded environments requiring high throughput.</li> <li>Working: Uses multiple threads to perform GC in the young generation; can freeze the application threads briefly.</li> <li>its a Throughput Collector</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#cms-collector","title":"CMS Collector","text":"<ul> <li>CMS menas for Concurrent Mark-Sweep</li> <li>Deprecated since JDK 9</li> <li>Use case: Low-latency applications.</li> <li>Working: Performs marking and sweeping concurrently with application threads, reducing pause times but susceptible to fragmentation.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#g1-garbage-collector","title":"G1 Garbage Collector","text":"<ul> <li>Garbage-First Collector</li> <li>Use case: Replaces CMS in JDK 9+. Suitable for large heaps.</li> <li>Working: Divides the heap into regions, focusing on areas with the most garbage first. Offers predictable pause times.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#z-garbage-collector-zgc","title":"Z Garbage Collector (ZGC)","text":"<ul> <li>Use case: Ultra-low pause times for very large heaps (multi-TB).</li> <li>Working: Uses region-based collection and performs almost all work concurrently. Pause times remain in the low millisecond range (independent of heap size).</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#shenandoah-gc","title":"Shenandoah GC","text":"<ul> <li>Use case: Large heap, low-latency applications.</li> <li>Working: Similar to ZGC but with even more aggressive concurrent operations to minimize stop-the-world pauses.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#comparing-collectors","title":"Comparing Collectors","text":"Collector Use Case Pause Time Heap Size Parallelism Serial Small apps, single-threaded High Small (&lt;1 GB) Single-threaded Parallel Throughput-heavy apps Moderate Medium to large Multi-threaded CMS Low-latency (deprecated) Low Medium to large Concurrent G1 Balanced throughput &amp; latency Predictable Large Mixed ZGC Ultra-low latency, huge heaps Sub-millisecond Multi-TB Highly concurrent Shenandoah Latency-sensitive, large heaps Sub-millisecond Multi-TB Highly concurrent <p>Note</p> <p>ZGC and Shenandoah use advanced algorithms that perform incremental marking, remapping, and concurrent sweeping. They avoid long pauses by offloading most GC work to concurrent threads.</p>"},{"location":"langdives/Java/GarbageCollection/#garbage-collection-concepts","title":"Garbage Collection Concepts","text":""},{"location":"langdives/Java/GarbageCollection/#generational-collection","title":"Generational Collection","text":"<p>Java heap is divided into:</p> <ul> <li> <p>Young Generation: Divided into Eden Space and Survivor Spaces (S0, S1), New objects are created in Eden. After surviving a GC cycle, they move to a survivor space, and after multiple cycles, to the Old Generation.</p> </li> <li> <p>Old Generation (Tenured): Contains long-lived objects.</p> </li> </ul> <p>Garbage collection types:</p> <ul> <li>Minor GC: Cleans the young generation.</li> <li>Major GC: Cleans the old generation.</li> <li>Full GC: Cleans both generations and compacts the heap.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#advanced-memory-layout","title":"Advanced Memory Layout","text":"<ul> <li>Heap Structure and Region-Based Management (G1/ZGC):</li> <li>G1 GC divides the heap into multiple equal-sized regions. These regions are not contiguous but logically organized into young/old regions.</li> <li>In ZGC and Shenandoah, these regions are even smaller to improve parallelism and reduce pause times.</li> </ul> <p>Dynamic Region Management:  </p> <ul> <li>G1 GC dynamically adjusts the size and number of regions based on application memory behavior.</li> <li> <p>ZGC uses regions independently to ensure ultra-low pause times, as each GC thread works on separate regions without blocking others.</p> </li> <li> <p>Compressed Oops (Ordinary Object Pointers):</p> </li> <li>Java uses compressed pointers (32-bit references) for heaps smaller than 32GB to optimize memory. Without this, object references would take 64 bits.      Enabled with<pre><code>-XX:+UseCompressedOops\n</code></pre></li> </ul>"},{"location":"langdives/Java/GarbageCollection/#safepoints","title":"Safepoints","text":"<p>Java threads stop only at specific safepoints for GC (or other JVM activities). A safepoint is a checkpoint where all threads must reach before GC can start for eg Executing bytecode that triggers allocation failure, method calls, or back branches in loops.</p> <p>The JVM injects safepoint polls within running code to ensure threads hit these safepoints regularly, Too many safepoint pauses indicate GC tuning issues or excessive thread blocking.</p> <p>JVM may delay triggering GC due to waiting for all threads to reach a safepoint, which introduces unpredictable latency. This is critical in low-latency systems like trading applications.</p>"},{"location":"langdives/Java/GarbageCollection/#stop-the-world-stw","title":"Stop the World (STW)","text":"<p>A Stop-The-World (STW) event occurs when the garbage collector (GC) halts all application threads to perform critical tasks like marking live objects, reclaiming memory, and compacting the heap. These pauses, necessary to prevent heap inconsistencies, impact application performance, especially in latency-sensitive environments. </p> <p>The duration of STW events depends on heap size, the number of live objects, and the GC algorithm. Traditional collectors like Serial GC and Parallel GC have longer STW pauses, while CMS reduces them with concurrent marking but still requires short pauses for initial and final marking. Modern GCs like G1 GC, ZGC, and Shenandoah GC minimize pauses by performing most work concurrently with application threads, achieving millisecond-range STW durations.</p> <p>Optimizations include using low-latency collectors, tuning GC settings, reducing allocation pressure, and monitoring GC behavior with tools like JFR or VisualVM. For latency-critical applications, advanced collectors and careful memory management are essential to mitigate the impact of STW events.</p>"},{"location":"langdives/Java/GarbageCollection/#barriers-tables-fences","title":"Barriers, Tables &amp; Fences","text":""},{"location":"langdives/Java/GarbageCollection/#write-barriers","title":"Write Barriers","text":"<ul> <li>Write barriers are small pieces of code inserted into memory writes to track references between young and old generations.</li> <li>These ensure that changes to references are correctly accounted for during GC (especially relevant for concurrent collectors).</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#card-tables","title":"Card Tables","text":"<ul> <li>Java divides heap memory into \"cards\" small blocks of 512 bytes. If an old object references a young object, the corresponding card is marked dirty.</li> <li>During GC, only dirty cards are scanned instead of the entire heap, improving GC performance. This is especially relevant for CMS and G1GC.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#memory-fences","title":"Memory Fences","text":"<ul> <li>Concurrent collectors use memory fences to ensure visibility across threads.</li> <li>ZGC leverages colored pointers to track object states (marked, remapped) without blocking threads.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#hierarchy","title":"Hierarchy","text":""},{"location":"langdives/Java/GarbageCollection/#allocation","title":"Allocation","text":"<p>New Object Creation</p> <ul> <li>Objects are first allocated in the Eden Space of the Young Generation.</li> <li>If there\u2019s no space in Eden, a Minor GC is triggered.</li> </ul> <p>Minor GC (Young Generation Collection)</p> <ul> <li>Scans Eden and Survivor Spaces to collect dead objects.</li> <li>Live objects are moved to Survivor Space S1.</li> <li>If objects survive several Minor GCs, they are promoted to the Old Generation.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#thresholds-promotions","title":"Thresholds &amp; Promotions","text":"<p>Max Tenuring Threshold</p> <ul> <li>Controls how many GC cycles an object must survive in the young generation to be promoted to the old generation.</li> </ul> <p>Promotion Failures</p> <ul> <li>If the Old Generation is full or unable to accommodate promoted objects, a Full GC (stop-the-world) may occur.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#major-gc-old-generation","title":"Major GC &amp; Old Generation","text":"<p>When Old Generation Fills Up</p> <ul> <li>Major GC (or Old Generation Collection) occurs.</li> <li>If old generation runs out of space, it may trigger a Full GC or throw an OutOfMemoryError (OOM).</li> </ul> <p>Concurrent Collectors (CMS, G1, ZGC, Shenandoah)</p> <ul> <li>These collectors minimize the impact of major GC by concurrently marking and sweeping objects with application threads running.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#full-gc-stop-the-world-event","title":"Full GC (Stop-the-World Event)","text":"<p>What Causes Full GC?</p> <ul> <li>Heap fragmentation (in CMS) or promotions failing from young to old generation.</li> <li>Metaspace OutOfMemoryError (if class metadata fills the Metaspace).</li> </ul> <p>What Happens During Full GC</p> <ul> <li>JVM pauses all application threads (STW).</li> <li>Performs marking, sweeping, and compacting on both young and old generations.</li> <li>Heap is defragmented to ensure that future allocations don't face fragmentation.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#safepoints-write-barriers","title":"Safepoints &amp; Write Barriers","text":"<p>Safepoints</p> <ul> <li>GC waits for all threads to hit a safepoint before starting.</li> <li>The JVM injects polls in code to ensure that all threads eventually reach a safepoint.</li> </ul> <p>Write Barriers</p> <ul> <li>Used to track reference changes between objects in the young and old generations.</li> <li>Ensures correct behavior when marking reachable objects during concurrent collections.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#finalization-reference-types","title":"Finalization &amp; Reference Types","text":"<p>Soft, Weak, and Phantom References</p> <ul> <li>Java handles objects with special reference types differently during GC.</li> <li>Soft References: Collected when memory is low.</li> <li>Weak References: Always collected during GC if not strongly reachable.</li> <li>Phantom References: Used to schedule cleanup tasks for objects.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#gc-flow-structure","title":"GC Flow Structure","text":"<p>GC Flow</p> <ol> <li> <p>Object Creation</p> <ul> <li>Allocated in Eden Space (Young Gen).</li> </ul> </li> <li> <p>Eden Full \u2192 Trigger Minor GC</p> <ul> <li>Mark live objects and move them to Survivor Spaces.</li> <li>Objects surviving multiple cycles move to the Old Generation.</li> </ul> </li> <li> <p>Old Gen Full \u2192 Trigger Major GC</p> <ul> <li>Mark and sweep objects in the Old Gen.</li> <li>If heap is fragmented, trigger Full GC.</li> </ul> </li> <li> <p>Concurrent Collections (G1, ZGC)</p> <ul> <li>Perform marking and sweeping concurrently without stopping the world.</li> </ul> </li> <li> <p>Full GC (Stop-the-World)</p> <ul> <li>When all else fails, Full GC freezes all threads, marks, sweeps, and compacts memory.</li> </ul> </li> </ol>"},{"location":"langdives/Java/GarbageCollection/#fragmentation","title":"Fragmentation","text":"<p>Fragmentation refers to the inefficient use of memory that occurs when free memory is split into small, non-contiguous blocks, making it difficult to allocate larger contiguous blocks even if the total free memory is sufficient. In Java, fragmentation can occur in both the young and old generations of the heap.</p>"},{"location":"langdives/Java/GarbageCollection/#types","title":"Types","text":"<p>Internal Fragmentation: Occurs when a block of memory is larger than what is actually needed. For example, if an object requires 10 bytes but is allocated a 16-byte block, the remaining 6 bytes are wasted.</p> <p>External Fragmentation: Happens when free memory is scattered in small chunks across the heap. This can lead to a situation where there isn\u2019t enough contiguous space available to fulfill a large allocation request, even if the total free memory is sufficient.</p>"},{"location":"langdives/Java/GarbageCollection/#causes","title":"Causes","text":"<p>Object Lifetimes: Short-lived objects are frequently allocated and deallocated, especially in the young generation. This can create gaps in memory as these objects are collected, leading to external fragmentation.</p> <p>Promotion of Objects: When objects in the young generation are promoted to the old generation, if the old generation is already fragmented, it may become difficult to allocate new objects.</p> <p>Full GCs: In collectors like CMS (Concurrent Mark-Sweep), memory is reclaimed but not compacted, leaving fragmented free spaces.</p>"},{"location":"langdives/Java/GarbageCollection/#effects","title":"Effects","text":"<p>OutOfMemoryError: Fragmentation can cause allocation failures, leading to <code>OutOfMemoryError</code> if there isn\u2019t enough contiguous memory available for new object allocations.</p> <p>Increased GC Overhead: The JVM may spend more time during GC cycles trying to find suitable spaces for object allocation, which can degrade performance.</p> <p>Heap Fragmentation: Some collectors (like CMS) suffer from heap fragmentation since they don\u2019t compact memory after reclaiming space.</p> <ul> <li>Symptoms: Increased GC frequency or Full GCs despite available heap space.</li> <li>Solution: Use G1GC or ZGC which support region-based compaction.</li> </ul> <p>Pinned Objects:  Sometimes, objects cannot be moved during GC (e.g., JNI references or thread-local objects). This can lead to fragmentation.</p>"},{"location":"langdives/Java/GarbageCollection/#mitigating","title":"Mitigating","text":"<p>Using G1 GC or ZGC: These collectors are designed to handle fragmentation better than older collectors. They manage memory in regions and perform compaction as part of their regular operations.</p> <p>Heap Size Adjustments: Increasing the size of the old generation can help reduce the frequency of fragmentation issues.</p> <p>Monitoring and Tuning: Regularly monitor memory usage and GC logs to identify fragmentation patterns. Tuning the JVM parameters can help alleviate fragmentation issues.</p> <p>Object Pooling: Reusing objects instead of frequently allocating and deallocating them can help reduce fragmentation.</p>"},{"location":"langdives/Java/GarbageCollection/#configuring-garbage-collection","title":"Configuring garbage collection","text":"<p>Configuring garbage collection and its parameters in Java is primarily done through JVM (Java Virtual Machine) options when starting your application.</p>"},{"location":"langdives/Java/GarbageCollection/#how-to-configure-params","title":"How to Configure Params","text":"<p>Command-Line Options: You can specify GC options when you start your Java application using the <code>java</code> command.</p> Example <pre><code>java -Xms512m -Xmx4g -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -jar my-application.jar\n</code></pre> <ul> <li><code>-Xms512m</code>: Sets the initial heap size to 512 MB.</li> <li><code>-Xmx4g</code>: Sets the maximum heap size to 4 GB.</li> <li><code>-XX:+UseG1GC</code>: Uses the G1 Garbage Collector.</li> <li><code>-XX:MaxGCPauseMillis=100</code>: Aims for a maximum pause time of 100 milliseconds.</li> </ul> <p>Environment Variables: For containerized applications (like those running in Docker or Kubernetes), you can set JVM options through environment variables or directly in the configuration file.</p> Example in Docker <pre><code>ENV JAVA_OPTS=\"-Xms512m -Xmx4g -XX:+UseG1GC\"\nCMD java $JAVA_OPTS -jar your-application.jar\n</code></pre> <p>Configuration Files: Some applications allow you to specify JVM options in a configuration file, which can be helpful for managing multiple parameters in one place.</p>"},{"location":"langdives/Java/GarbageCollection/#common-gc-options","title":"Common GC Options","text":"<p>Basic Heap Size Configuration</p> <ul> <li><code>-Xms&lt;size&gt;</code>: Sets the initial heap size.</li> <li><code>-Xmx&lt;size&gt;</code>: Sets the maximum heap size.</li> </ul> <p>Choosing a Garbage Collector</p> G1 GC<pre><code>-XX:+UseG1GC\n</code></pre> Parallel GC<pre><code>-XX:+UseParallelGC\n</code></pre> CMS (Concurrent Mark-Sweep)<pre><code>-XX:+UseConcMarkSweepGC\n</code></pre> ZGC<pre><code>-XX:+UseZGC\n</code></pre> Shenandoah<pre><code>-XX:+UseShenandoahGC\n</code></pre> <p>Tuning G1 GC</p> <ul> <li><code>-XX:MaxGCPauseMillis=&lt;time&gt;</code>: Target maximum pause time.</li> <li><code>-XX:G1HeapRegionSize=&lt;size&gt;</code>: Size of the regions in G1.</li> <li><code>-XX:G1ReservePercent=&lt;percentage&gt;</code>: Percentage of heap reserved for G1 to avoid Full GC.</li> </ul> <p>Tuning Parallel GC</p> <ul> <li><code>-XX:ParallelGCThreads=&lt;number&gt;</code>: Number of threads to use for parallel GC.</li> <li><code>-XX:ConcGCThreads=&lt;number&gt;</code>: Number of concurrent threads during GC.</li> </ul> <p>Monitoring and Logging</p> <ul> <li><code>-Xlog:gc*:file=gc.log</code>: Logs detailed GC information to <code>gc.log</code>.</li> <li><code>-XX:+PrintGCDetails</code>: Outputs detailed information about each GC event.</li> </ul> <p>Controlling Object Promotion</p> <ul> <li><code>-XX:MaxTenuringThreshold=&lt;N&gt;</code>: Number of times an object can be copied in the young generation before being promoted to the old generation.</li> </ul> <p>Metaspace Configuration (for class metadata)</p> <ul> <li><code>-XX:MetaspaceSize=&lt;size&gt;</code>: Initial size of Metaspace.</li> <li><code>-XX:MaxMetaspaceSize=&lt;size&gt;</code>: Maximum size of Metaspace.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#example-configuration","title":"Example Configuration","text":"<p>Here\u2019s an example of a command to start a Java application with G1 GC and some tuning parameters</p> Example <pre><code>java -Xms1g -Xmx8g -XX:+UseG1GC \\\n   -XX:MaxGCPauseMillis=200 \\\n   -XX:G1HeapRegionSize=16m \\\n   -XX:InitiatingHeapOccupancyPercent=30 \\\n   -XX:ConcGCThreads=2 \\\n   -Xlog:gc*:file=gc.log \\\n   -jar my-application.jar\n</code></pre>"},{"location":"langdives/Java/GarbageCollection/#deep-tuning-techniques","title":"Deep Tuning Techniques","text":"<p>Heap Size and GC Frequency</p> <ul> <li>Larger heaps reduce the frequency of GC but increase GC pause times.</li> <li>Too small a heap size leads to frequent GC, causing poor performance.</li> </ul> <p>GC Latency and Response Times</p> <ul> <li>GC pauses affect 99<sup>th</sup> percentile latencies, especially in real-time systems.</li> <li>ZGC and Shenandoah are designed to keep pause times sub-millisecond by performing most operations concurrently.</li> </ul> <p>Application Throughput vs Latency</p> <ul> <li>Throughput-oriented collectors (like Parallel GC) achieve high throughput but at the cost of longer pauses.</li> <li>G1GC offers a compromise between throughput and latency.</li> </ul> <p>Survivor Space Tuning</p> <ul> <li>A higher ratio gives more space to Eden, and smaller Survivor spaces.   Adjust with<pre><code>-XX:SurvivorRatio=&lt;N&gt;\n</code></pre></li> <li>A higher threshold means more objects are kept in the young generation, but it may increase Minor GC times.    Adjust how long with<pre><code>-XX:MaxTenuringThreshold=&lt;N&gt;\n</code></pre></li> <li>Promotion Failures: When young generation cannot fit objects into old generation (usually during high allocation bursts), GC falls back to Full GC. To reduce this Increase old generation size or set higher SurvivorRatio.</li> </ul> <p>Tuning G1 GC</p> <ul> <li>Focus on pause times   <pre><code>-XX:MaxGCPauseMillis=100\n-XX:G1ReservePercent=10  // Extra heap reserved to avoid Full GC\n</code></pre></li> <li>Analyze G1 Humongous Objects: Objects larger than half the region size are treated as \"humongous\" and allocated directly in the old generation.   <pre><code>-XX:G1HeapRegionSize=&lt;N&gt;  // Larger region size helps handle humongous objects efficiently\n</code></pre></li> </ul> <p>Young GC Tuning</p> <ul> <li>Monitor Minor GC behavior using:   <pre><code>-Xlog:gc*:file=gc.log\n</code></pre></li> <li>Frequent Minor GC indicates<ul> <li>Too small Eden space.</li> <li>Objects are prematurely promoted to old generation, leading to promotion failures.</li> </ul> </li> </ul> <p>Tuning Java GC for High Performance</p> <ul> <li> <p>Choose the Right GC:  </p> <ul> <li>Use ZGC or Shenandoah for low-latency, large-memory applications.</li> <li>Stick with G1GC for general-purpose applications needing a balance between throughput and latency.</li> </ul> </li> <li> <p>Analyze and Tune:  </p> <ul> <li>Regularly monitor GC logs and fine-tune heap settings.</li> <li>Avoid unnecessary Full GCs by managing object lifetimes and heap fragmentation.</li> </ul> </li> </ul> <p>Handling Multi-Terabyte Heaps</p> <ul> <li>ZGC and Shenandoah are designed to handle multi-TB heaps with minimal latency impact.</li> <li>Even with multi-GB objects, pause times remain low by processing in parallel regions.</li> </ul> <p>GC in Cloud and Microservices</p> <ul> <li>In Kubernetes environments, GC settings must align with container limits:   <pre><code>-XX:MaxRAMPercentage=75.0\n</code></pre></li> <li>Use G1GC for microservices to ensure predictable pauses.</li> </ul> <p>Latency Monitoring</p> <ul> <li>Monitor GC pause impact on response times using:   <pre><code>-Xlog:gc*:file=gc.log\n</code></pre></li> <li>Look for long Minor GC pauses and tune accordingly.</li> </ul>"},{"location":"langdives/Java/GarbageCollection/#tools-for-analysis","title":"Tools for Analysis","text":"<p>GC Logs: Capture GC details by adding <code>-Xlog:gc*</code> or <code>-XX:+PrintGCDetails</code> JVM options.</p> Sample GC Log <pre><code>[GC (Allocation Failure) [PSYoungGen: 2048K-&gt;512K(2560K)] 4096K-&gt;2048K(8192K), 0.0103451 secs]\n</code></pre> <ul> <li>[GC (Allocation Failure)]: Reason for GC.</li> <li>[PSYoungGen: 2048K-&gt;512K(2560K)]: Young generation usage before and after GC.</li> <li>4096K-&gt;2048K(8192K): Heap usage before and after GC.</li> <li>0.0103451 secs: GC pause duration.</li> </ul> <p>VisualVM: A monitoring tool bundled with the JDK for real-time JVM performance monitoring.</p> <p>Java Flight Recorder (JFR): An advanced profiling tool that collects detailed JVM metrics, including GC data.</p> <p>JConsole: Visualize JVM statistics and monitor heap usage.</p>"},{"location":"langdives/Java/GarbageCollection/#diagnosing-troubleshooting","title":"Diagnosing &amp; Troubleshooting","text":"<p>OutOfMemoryError (OOM): Common causes</p> <ul> <li>Memory leak due to uncollected objects.</li> <li>Survivor space overflow or promotion failures.</li> <li>JNI leaks or unmanaged native memory usage.</li> </ul> <p>Heap Dump Analysis:</p> <ul> <li>Use tools like jmap to capture heap dumps:    <pre><code>jmap -dump:format=b,file=heapdump.hprof &lt;pid&gt;\n</code></pre></li> <li>Analyze with Eclipse MAT (Memory Analyzer Tool) or VisualVM.</li> </ul> <p>Detecting Leaks: Look for large, unreachable objects with static references or growing collections (e.g., large <code>HashMap</code> or <code>ArrayList</code>).</p> <p>Java Flight Recorder (JFR): JFR provides detailed memory profiling without heavy overhead. Collect a recording and analyze it for object lifetimes, GC events, and thread behavior.</p>"},{"location":"langdives/Java/GarbageCollection/#summary","title":"Summary","text":"<p>Choose the Right GC Collector</p> <ul> <li>Use G1GC for most applications by default.</li> <li>ZGC/Shenandoah for low-latency needs.</li> <li>Parallel GC for batch processing jobs.</li> </ul> <p>Monitor and Analyze</p> <ul> <li>Analyze GC logs regularly to detect bottlenecks.</li> <li>Adjust heap size based on application workload and memory usage patterns.</li> </ul> <p>Avoid Full GC</p> <ul> <li>Tune heap size and object lifetimes to avoid triggering frequent Full GCs.</li> <li>Use G1GC or other region-based collectors to reduce compaction overhead.</li> </ul> <p>Pre-tuning Advice</p> <ul> <li>Avoid over-tuning; start with default GC settings and only tweak after analyzing performance issues.</li> </ul>"},{"location":"langdives/Java/Gradle/","title":"Gradle","text":""},{"location":"langdives/Java/Gradle/#what-is-gradle","title":"What is Gradle ?","text":"<p>Gradle is a modern, powerful build automation tool used for building, testing, and deploying applications. It is particularly popular in Java and Android projects due to its flexibility and performance. Gradle uses a <code>Groovy/Kotlin-based DSL</code> to configure and manage builds, allowing for easy customization.</p>"},{"location":"langdives/Java/Gradle/#how-gradle-works","title":"How Gradle Works ?","text":"<p>Gradle organizes builds using a Directed Acyclic Graph (DAG) of tasks, ensuring that tasks are executed only when necessary.</p> <p>The Build process has Three phases</p> <p>Initialization Phase</p> <ul> <li>Identifies the participating projects (useful for multi-project builds).</li> <li>Creates the build environment (root project and sub-projects).</li> </ul> <p>Configuration Phase</p> <ul> <li>Configures all tasks in the project(s).</li> <li>Resolves dependencies, configures plugins, and defines task order.</li> </ul> <p>Execution Phase</p> <ul> <li>Executes the required tasks in the correct sequence according to the task dependencies.</li> </ul>"},{"location":"langdives/Java/Gradle/#gradle-build","title":"Gradle Build","text":"<p>Gradle build configuration is done in the <code>build.gradle</code> file. This file uses Groovy or Kotlin DSL to describe:</p> <ul> <li>Dependencies required for the project.</li> <li>Repositories where the dependencies will be fetched from.</li> <li>Plugins to extend functionality.</li> <li>Custom tasks to automate various steps.</li> </ul> <p><code>build.gradle</code> Example</p> <pre><code>plugins {\n    id 'java'        // Apply Java plugin\n    id 'application' // Allow running the app from CLI\n}\n\nrepositories {\n    mavenCentral() // Use Maven Central for dependencies\n}\n\ndependencies {\n    implementation 'org.apache.commons:commons-lang3:3.12.0'  // Runtime dependency\n    testImplementation 'junit:junit:4.13.2'  // Test dependency\n}\n\napplication {\n    mainClass = 'com.example.UnderTheHood'  // Entry point of the app\n}\n</code></pre>"},{"location":"langdives/Java/Gradle/#understanding-buildgradle","title":"Understanding <code>build.gradle</code>","text":"<p>Plugins Section</p> <pre><code>plugins {\n    id 'java'\n    id 'application'\n}\n</code></pre> <ul> <li>This section applies Gradle plugins. </li> <li>Gradle provides an ecosystem of plugins to extend functionality</li> <li><code>java</code>: Adds support for Java projects.</li> <li><code>application</code>: Allows running applications directly from Gradle with <code>gradle run</code>.</li> <li><code>maven-publish</code>: Publishes artifacts to Maven repositories.</li> <li><code>android</code>: Used for Android app development.</li> <li>In the example, the <code>java</code> plugin sets up the project to be built as a Java application.</li> </ul> <p>Repositories Section</p> <pre><code>repositories {\n    mavenCentral()\n}\n</code></pre> <ul> <li>This section tells Gradle where to download dependencies from.</li> <li><code>mavenCentral()</code> is a popular repository that hosts many open-source libraries.</li> </ul> <p>Dependencies Section</p> <pre><code>dependencies {\n    implementation 'org.apache.commons:commons-lang3:3.12.0'\n    testImplementation 'junit:junit:4.13.2'\n}\n</code></pre> <ul> <li>Gradle manages external libraries required by your project.</li> <li><code>implementation</code>: Adds a runtime dependency.</li> <li><code>testImplementation</code>: Adds a dependency for testing purposes.</li> </ul> <p>Application Configuration</p> <pre><code>application {\n    mainClass = 'com.example.UnderTheHood'\n}\n</code></pre> <ul> <li>This specifies the main class to be run when using the <code>gradle run</code> command.</li> </ul>"},{"location":"langdives/Java/Gradle/#dependency-management","title":"Dependency Management","text":"<p>Gradle allows automatic dependency management. Dependencies (like libraries and frameworks) are fetched from repositories such as:</p> <ul> <li>Maven Central: A public repository.</li> <li>JCenter: (Now deprecated) Another widely used repository.</li> <li>Custom repositories: Can be local or remote (e.g., Artifactory, Nexus).</li> </ul> <p>Gradle resolves dependencies in the following order:</p> <ul> <li>Local Cache: Located in <code>~/.gradle/caches/</code>.</li> <li>Local Maven Repository: If <code>mavenLocal()</code> is specified (<code>~/.m2/repository/</code>).</li> <li>Remote Repositories: Downloads dependencies from Maven Central or other remote repositories if not found locally.</li> </ul> Offline Mode<pre><code># Forces Gradle to use only the local cache \n# and does not try to access remote repositories.\ngradle build --offline\n</code></pre>"},{"location":"langdives/Java/Gradle/#custom-tasks","title":"Custom Tasks","text":"<p>Gradle allows developers to create custom tasks to automate specific workflows.</p> Custom Tasks Example Create Custom Task<pre><code>task uth {\n    doLast {\n        println 'Hello, UnderTheHood ;)'\n    }\n}\n</code></pre> Run the Custom task<pre><code>gradle uth\n</code></pre> Output<pre><code>Hello, UnderTheHood ;)\n</code></pre> <p>Custom tasks can be chained and made dependent on other tasks:</p> <pre><code>task compileCode {\n    dependsOn clean\n    doLast {\n        println 'Compiling code...'\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Gradle/#publishing-artifacts","title":"Publishing Artifacts","text":"<p>You can publish your project\u2019s artifacts (e.g., JARs) to Maven Local or Remote repositories using the <code>maven-publish</code> plugin.</p> <p>Local Maven Publish Example</p> Apply Maven Publish Plugin<pre><code>plugins {\n    id 'maven-publish'\n}\n</code></pre> Configure Publishing in build.gradle<pre><code>publishing {\n    publications {\n        mavenJava(MavenPublication) {\n            from components.java\n        }\n    }\n    repositories {\n        mavenLocal()  // Publish to local Maven repository (~/.m2/repository)\n    }\n}\n</code></pre> Publish the Artifact<pre><code># This will install the JAR into your local Maven repository.\ngradle publishToMavenLocal\n</code></pre>"},{"location":"langdives/Java/Gradle/#gradle-project-structure","title":"Gradle Project Structure","text":"Gradle recommended standard directory structure<pre><code>/my-project\n\u2502\n\u251c\u2500\u2500 build.gradle          # Build configuration file\n\u251c\u2500\u2500 settings.gradle       # Project settings file\n\u251c\u2500\u2500 src\n\u2502   \u2514\u2500\u2500 main\n\u2502       \u2514\u2500\u2500 java          # Source code\n\u2502   \u2514\u2500\u2500 test\n\u2502       \u2514\u2500\u2500 java          # Unit tests\n\u2514\u2500\u2500 build                 # Output directory (JAR, WAR)\n</code></pre> <ul> <li><code>src/main/java</code>: Contains the application source code.</li> <li><code>src/test/java</code>: Contains unit test code.</li> <li><code>build/</code>: Contains compiled artifacts (like JARs).</li> </ul> <p>Gradle supports multi-module projects where different modules are part of the same build.</p> Example Multi-Project Structure<pre><code>/root-project\n\u2502\n\u251c\u2500\u2500 build.gradle            # Root project configuration\n\u251c\u2500\u2500 settings.gradle         # Lists sub-projects\n\u251c\u2500\u2500 module-1/\n\u2502   \u2514\u2500\u2500 build.gradle        # Configuration for module 1\n\u2514\u2500\u2500 module-2/\n    \u2514\u2500\u2500 build.gradle        # Configuration for module 2\n</code></pre> settings.gradle<pre><code>rootProject.name = 'multi-project-example'\ninclude 'module-1', 'module-2'\n</code></pre> Running the build<pre><code># This will build all modules in the correct order.\ngradle build\n</code></pre>"},{"location":"langdives/Java/Gradle/#gradle-wrapper","title":"Gradle Wrapper","text":"<p>The Gradle Wrapper is a feature that allows a project to include a specific Gradle version along with scripts to execute builds. This ensures that anyone working on the project uses the same Gradle version without requiring a manual installation.</p> <p>The Gradle Wrapper consists of:</p> <ul> <li>A set of shell scripts (Unix: <code>gradlew</code>, Windows: <code>gradlew.bat</code>).</li> <li>A configuration file (<code>gradle/wrapper/gradle-wrapper.properties</code>) that specifies the Gradle version to use.</li> <li>A JAR file (<code>gradle-wrapper.jar</code>) that downloads Gradle if needed.</li> </ul>"},{"location":"langdives/Java/Gradle/#why-use-wrapper","title":"Why Use Wrapper ?","text":"<ul> <li>Ensures that all team members use the same Gradle version.</li> <li>Simplifies onboarding \u2013 contributors do not need to install Gradle manually.</li> <li>Useful for CI/CD pipelines to avoid version mismatches.</li> <li>Works offline after the first download by caching Gradle versions locally.</li> </ul>"},{"location":"langdives/Java/Gradle/#gradle-commands","title":"Gradle Commands","text":"<p>Here are some essential Gradle commands for working with projects:</p> Command Description <code>gradle init</code> Initializes a new Gradle project. <code>gradle build</code> Compiles, tests, and packages the project. <code>gradle run</code> Runs the application (if using the Application plugin). <code>gradle clean</code> Removes the <code>build/</code> directory for a fresh build. <code>gradle tasks</code> Lists all available tasks. <code>gradle test</code> Runs all tests in the project. <code>gradle publish</code> Publishes artifacts to Maven repositories."},{"location":"langdives/Java/Gradle/#performance-benefits","title":"Performance Benefits","text":"<p>Gradle is designed for speed and efficiency</p> <ul> <li>Incremental Builds: Only recompiles changed files, speeding up builds.</li> <li>Build Cache: Gradle reuses outputs of previous builds if nothing has changed.</li> <li>Parallel Execution: Gradle can execute tasks in parallel when there are no dependencies between them.</li> </ul>"},{"location":"langdives/Java/Gradle/#summary","title":"Summary","text":"<p>Gradle provides several advantages for modern projects</p> <ul> <li>Flexibility: Customizable tasks and plugins allow you to tailor builds to your needs.</li> <li>Speed: Incremental builds and build caching reduce build times.</li> <li>Dependency Management: Easy integration with Maven repositories.</li> <li>Scalability: Suitable for multi-project builds and large teams.</li> <li>Extensibility: Works well for Java, Android, and multi-language projects.</li> </ul>"},{"location":"langdives/Java/JDK-JRE-JVM/","title":"Java","text":"<p>Java is a high-level, object-oriented programming language designed for portability, security, and ease of use. It is known for its \"write once, run anywhere\" capability, allowing developers to create software that can run on any device with a Java Virtual Machine (JVM).</p>"},{"location":"langdives/Java/JDK-JRE-JVM/#architecture","title":"Architecture","text":"<p>The Java architecture is composed of three main components:</p>"},{"location":"langdives/Java/JDK-JRE-JVM/#jdk","title":"JDK","text":"<p>The JDK Java Development Kit is a comprehensive development environment for building Java applications. It provides all the tools necessary for Java developers to create, compile, and package Java applications.</p> <p>Components</p> <ul> <li>Java Compiler (<code>javac</code>):  Translates Java source code (<code>.java</code> extension) into bytecode (<code>.class</code> extension).</li> <li>Java Runtime Environment (JRE): A subset of the JDK, required to run Java applications.</li> <li>Development Tools: Tools for debugging, monitoring, and managing Java applications, such as <code>javadoc</code>, <code>jdb</code>, and <code>jar</code>.</li> </ul>"},{"location":"langdives/Java/JDK-JRE-JVM/#jre","title":"JRE","text":"<p>The JRE-Java Runtime Environment provides the libraries, Java Virtual Machine (JVM), and other components necessary for running Java applications. It does not include development tools, making it ideal for end-users who only need to run Java applications.</p> <p>Components</p> <ul> <li>Java Virtual Machine (JVM): The core component that executes Java bytecode.</li> <li>Java Class Libraries: Precompiled libraries containing standard Java classes for various functionalities.</li> </ul>"},{"location":"langdives/Java/JDK-JRE-JVM/#jvm","title":"JVM","text":"<p>The JVM Java Virtual Machine is an abstract computing machine that enables a computer to run Java programs. It is responsible for interpreting and executing the bytecode generated by the Java compiler.</p> <p>Functions</p> <ul> <li>Loading: Loads <code>.class</code> files containing the bytecode into memory.</li> <li>Linking: Combines and prepares the bytecode for execution by resolving references, validating the code.</li> <li>Execution: Translates bytecode into machine code specific to the operating system, allowing the application to run.</li> </ul>"},{"location":"langdives/Java/JDK-JRE-JVM/#hierarchical-structure","title":"Hierarchical Structure","text":"<p>Hierarchical Structure</p> <pre><code>JDK (includes javac, JRE, Tools)\n\u2514\u2500\u2500 JRE (includes JVM and libraries)\n    \u2514\u2500\u2500 JVM (executes bytecode)\n</code></pre>"},{"location":"langdives/Java/JDK-JRE-JVM/#how-java-executes","title":"How Java Executes ?","text":"<p>The execution of Java code involves several steps, transitioning through the JDK, JRE, and JVM before reaching the machine code that the computer's CPU executes.</p> <p>Code Writing: Java developers write source code in plain text files using the <code>.java</code> extension. This code defines classes and methods that make up the Java application.</p> <p>Code Compilation: The developer uses the Java compiler (<code>javac</code>), which is part of the JDK, to compile the <code>.java</code> file. This process translates the human-readable Java code into an intermediate form known as bytecode. The output of this step is a <code>.class</code> file containing the bytecode.</p> <p>Running the Application: To run the Java application, the developer executes a command using the Java runtime environment (e.g., <code>java ClassName</code>), which triggers the JRE, The JRE includes the JVM, which performs the following steps:</p> <ul> <li> <p>Loading: The JVM locates the specified <code>.class</code> file and loads it into memory.</p> </li> <li> <p>Linking: The JVM links the bytecode:</p> <ul> <li>Verification: Ensures the bytecode adheres to the JVM specifications, checking for security and integrity.</li> <li>Preparation: Allocates memory for static variables and prepares the code for execution.</li> <li>Resolution: Resolves symbolic references to classes, methods, and fields.</li> </ul> </li> <li> <p>Execution: The JVM executes the bytecode:</p> <ul> <li>Interpreting: The JVM can interpret the bytecode line-by-line, converting it to machine code as it runs.</li> <li>JIT Compilation: For performance optimization, the JVM employs a Just-In-Time (JIT) compiler, which compiles frequently executed bytecode into native machine code at runtime. This compiled code is stored in memory for future calls, improving execution speed.</li> </ul> </li> </ul> <p>Machine Code Execution: The machine code generated by the JVM is executed by the host operating system's CPU. This process allows Java applications to be platform-independent, as the same bytecode can run on any system that has a compatible JVM.</p>"},{"location":"langdives/Java/Java8vs11vs17vs21/","title":"Java 8 vs 11 vs 17 vs 21","text":"<p>A detailed comparison of Java 8, Java 11, Java 17, and Java 21, summarizing the key differences, improvements, and deprecations introduced across these versions:</p>"},{"location":"langdives/Java/Java8vs11vs17vs21/#java-8-released-march-2014","title":"Java 8 (Released March 2014)","text":"<p>Java 8 is a long-term support (LTS) release, bringing significant new features:</p>"},{"location":"langdives/Java/Java8vs11vs17vs21/#major-features","title":"Major Features","text":"<ul> <li>Lambda Expressions: Enables functional-style programming.</li> <li>Stream API: Helps process collections and data pipelines.</li> <li>Optional Class: Helps avoid <code>NullPointerException</code>.</li> <li>Default Methods in Interfaces: Allows adding new methods to interfaces without breaking existing code.</li> <li>New Date and Time API (<code>java.time</code>): Replaces the old <code>java.util.Date</code>.</li> <li>Nashorn JavaScript Engine: Allows embedding JavaScript in Java applications.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#performance-security","title":"Performance &amp; Security","text":"<ul> <li>PermGen space removed (replaced by Metaspace).</li> <li>Improved Garbage Collection (G1 GC available).</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#drawbacks","title":"Drawbacks","text":"<ul> <li>Older TLS 1.2 implementation.</li> <li>Less modular structure.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#java-11-released-sept-2018","title":"Java 11 (Released Sept 2018)","text":"<p>Java 11 is also LTS and a significant milestone since it removed many outdated APIs and modularized the runtime.</p>"},{"location":"langdives/Java/Java8vs11vs17vs21/#major-features_1","title":"Major Features","text":"<ul> <li>Local-Variable Syntax for Lambda Parameters (<code>var</code> in lambda).</li> <li>HTTP Client API (Standardized): Supports HTTP/2.</li> <li>String Enhancements: <code>lines()</code>, <code>strip()</code>, <code>repeat()</code>, <code>isBlank()</code> methods.</li> <li>Files API Improvements: <code>readString()</code>, <code>writeString()</code>, <code>isSameFile()</code> methods.</li> <li>Nest-Based Access Control: Easier access between nested classes.</li> <li>ZGC (Z Garbage Collector): A scalable low-latency GC.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#removals-deprecations","title":"Removals &amp; Deprecations","text":"<ul> <li>Removal of Java EE and CORBA modules.</li> <li>Nashorn JavaScript Engine deprecated.</li> <li>Applet API deprecated.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#performance-security_1","title":"Performance &amp; Security","text":"<ul> <li>TLS 1.3 support.</li> <li>Better memory management (e.g., with ZGC).</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#java-17-released-sept-2021","title":"Java 17 (Released Sept 2021)","text":"<p>Java 17 is an LTS release, refining many features introduced in Java 9-16 and stabilizing the platform.</p>"},{"location":"langdives/Java/Java8vs11vs17vs21/#major-features_2","title":"Major Features","text":"<ul> <li>Sealed Classes: Restricts which classes can extend or implement a particular class.</li> <li>Pattern Matching for <code>instanceof</code>: Simplifies type casting.</li> <li>Records: Concise way to model immutable data.</li> <li>Text Blocks: Multi-line string literals.</li> <li>Foreign Function and Memory API (Preview): Facilitates interoperation with native libraries.</li> <li>Enhanced Switch (Pattern Matching, Switch Expressions).</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#removals-deprecations_1","title":"Removals &amp; Deprecations","text":"<ul> <li>Deprecated Security Manager.</li> <li>RMI Activation removed.</li> <li>Applet API removed.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#garbage-improvements","title":"Garbage Improvements","text":"<ul> <li>ZGC and Shenandoah GC production-ready.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#performance-security_2","title":"Performance &amp; Security","text":"<ul> <li>Stronger encapsulation in the JDK modules.</li> <li>Better startup, memory, and GC performance.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#java-21-released-sept-2023","title":"Java 21 (Released Sept 2023)","text":"<p>Java 21 is a non-LTS release (though with unofficial support from some vendors). It introduces many experimental and innovative features.</p>"},{"location":"langdives/Java/Java8vs11vs17vs21/#major-features_3","title":"Major Features","text":"<ul> <li>Virtual Threads (Part of Project Loom): Lightweight threads for highly scalable applications.</li> <li>Structured Concurrency (Incubator): Simplifies working with multiple concurrent tasks.</li> <li>Record Patterns (Preview): Extends pattern matching.</li> <li>Unnamed Patterns and Variables: Reduces verbosity when matching.</li> <li>Sequenced Collections: New <code>List</code>, <code>Set</code>, and <code>Map</code> with defined iteration order.</li> <li>String Templates: Simplifies string formatting.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#removals-deprecations_2","title":"Removals &amp; Deprecations:","text":"<ul> <li>Security Manager fully removed.</li> <li>Deprecated APIs cleaned up.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#performance-security_3","title":"Performance &amp; Security:","text":"<ul> <li>Further GC enhancements (ZGC, Shenandoah).</li> <li>Virtual threads allow non-blocking I/O models, improving scalability.</li> </ul>"},{"location":"langdives/Java/Java8vs11vs17vs21/#key-versions-differences","title":"Key Versions Differences","text":"Feature / Change Java 8 Java 11 Java 17 Java 21 LTS Release Yes Yes Yes No Lambda Expressions Yes Yes Yes Yes HTTP Client No Yes (HTTP/2) Yes Yes Modular System (JPMS) No Yes Yes Yes Records No No Yes Yes Sealed Classes No No Yes Yes Text Blocks No No Yes Yes Pattern Matching (<code>instanceof</code>) No No Yes Yes Virtual Threads (Loom) No No No Yes Garbage Collectors G1 GC ZGC ZGC, Shenandoah Improved ZGC, Shenandoah String Enhancements Basic <code>strip()</code>, <code>repeat()</code> Text Blocks String Templates TLS Version 1.2 1.3 1.3 1.3 Security Manager Available Deprecated Deprecated Removed Nashorn JavaScript Engine Yes Deprecated Removed Removed"},{"location":"langdives/Java/Java8vs11vs17vs21/#summary","title":"Summary","text":"<ul> <li>Java 8: Best suited for legacy systems; widely adopted but outdated.</li> <li>Java 11: A stable upgrade for Java 8 users with modern features and TLS 1.3.</li> <li>Java 17: The most recommended LTS version, offering modern features like records, sealed classes, and better performance.</li> <li>Java 21: Introduces bleeding-edge technology such as virtual threads and structured concurrency, but being non-LTS, it\u2019s suitable for developers eager to experiment or early adopters. </li> </ul> <p>For production systems, upgrading to Java 17 is generally recommended unless your project needs experimental features from Java 21.</p>"},{"location":"langdives/Java/JavaPassBy/","title":"Is Java Pass By Value or By Reference ?","text":"<p>Java is stricly pass by value but lets go in depth.</p>"},{"location":"langdives/Java/JavaPassBy/#pass-by-value","title":"Pass by Value","text":"<p>Java uses a mechanism called pass by value for method arguments, but it\u2019s important to know how this applies to primitive and reference types.</p>"},{"location":"langdives/Java/JavaPassBy/#primitive-types","title":"Primitive Types","text":"<p>These are the basic data types in Java (e.g., <code>int</code>, <code>char</code>, <code>boolean</code>), When you pass a primitive type to a method, the method receives a copy of the variable's value. Any changes made to this copy do not affect the original variable.</p> Primitive Types Example <pre><code>public class PassByValueExample {\n    public static void main(String[] args) {\n        int num = 10;\n        modifyValue(num); // Passing primitive\n        System.out.println(num); // Output: 10\n    }\n\n    public static void modifyValue(int value) {\n        value = 20; // Only modifies the copy\n    }\n}\n</code></pre>"},{"location":"langdives/Java/JavaPassBy/#reference-types","title":"Reference Types","text":"<p>These include objects, arrays, and instances of classes, When you pass a reference type to a method, the reference itself is passed by value. This means the method receives a copy of the reference to the object. While you can change the object's properties, you cannot change the reference to point to a different object.</p> Reference Types Example <pre><code>class MyClass {\n    int value;\n\n    MyClass(int value) {\n        this.value = value;\n    }\n}\n\npublic class PassByReferenceExample {\n    public static void main(String[] args) {\n        MyClass obj = new MyClass(10);\n        modifyObject(obj); // Passing reference\n        System.out.println(obj.value); // Output: 20\n    }\n\n    public static void modifyObject(MyClass myObject) {\n        myObject.value = 20; // Modifies the object's property\n        // myObject = new MyClass(30); // This would not affect the original object reference only changes local myObject.\n    }\n}\n</code></pre>"},{"location":"langdives/Java/JavaPassBy/#why","title":"Why?","text":"<p>When a method is called, a new stack frame is created, and local variables (including method parameters) are stored in this stack frame. Objects are stored in the heap, and the reference to these objects is passed to methods. When you modify the object\u2019s state inside the method, it reflects outside the method because both the original reference and the parameter reference point to the same object in memory.</p>"},{"location":"langdives/Java/JavaPassBy/#scope-and-lifetime","title":"Scope and Lifetime","text":"<ul> <li> <p>Scope: Variables defined inside a method (local variables) can only be accessed within that method. Once the method completes, the local variables are destroyed.</p> </li> <li> <p>Lifetime: Objects in the heap remain as long as they are referenced. When no references exist (e.g., after the method execution, and no references are held), they become eligible for garbage collection.</p> </li> </ul>"},{"location":"langdives/Java/JavaPassBy/#summary","title":"Summary","text":"<p>Java is pass-by-value: </p> <ul> <li>Primitive types pass a copy of the value.</li> <li>Reference types pass a copy of the reference to the object.</li> </ul> <p>Changes to the object through the reference affect the original object, but reassignment of the reference does not affect the original reference.</p>"},{"location":"langdives/Java/KeyWordsTerminolgies/","title":"Keywords and Terminolgies","text":""},{"location":"langdives/Java/KeyWordsTerminolgies/#class-object","title":"Class &amp; Object","text":"<ul> <li><code>class</code>: Defines a class.</li> <li><code>interface</code>: Declares an interface (a contract for classes).</li> <li><code>object</code>: An instance of a class.</li> <li><code>new</code>: Instantiates a new object.</li> </ul>"},{"location":"langdives/Java/KeyWordsTerminolgies/#modifiers","title":"Modifiers","text":"<ul> <li><code>public</code> / <code>private</code> / <code>protected</code>: Access control modifiers (already discussed).  </li> <li><code>static</code>: Indicates a field or method belongs to the class rather than instances, is shared across all instances of a class.</li> <li><code>final</code>: Used to declare constants, prevent method overriding, or inheritance, A final method cannot be overridden by subclasses, A final class cannot be inherited.</li> <li><code>abstract</code>: Used to declare incomplete methods or classes that must be extended.  </li> </ul>"},{"location":"langdives/Java/KeyWordsTerminolgies/#inheritance-polymorphism","title":"Inheritance &amp; Polymorphism","text":"<ul> <li><code>extends</code>: A class inherits another class.</li> <li><code>implements</code>: A class implements an interface.</li> <li><code>super</code>: Refers to the parent class\u2019s members.</li> <li><code>this</code>: Refers to the current instance of the class.</li> </ul>"},{"location":"langdives/Java/KeyWordsTerminolgies/#control-flow","title":"Control Flow","text":"<ul> <li><code>if</code> / <code>else</code> / <code>switch</code>: Conditional statements.</li> <li><code>for</code> / <code>while</code> / <code>do-while</code>: Looping constructs.</li> <li><code>break</code> / <code>continue</code>: Control loop execution.</li> <li><code>return</code>: Exits from a method and optionally returns a value.</li> </ul>"},{"location":"langdives/Java/KeyWordsTerminolgies/#exception-handling","title":"Exception Handling","text":"<ul> <li><code>try</code> / <code>catch</code> / <code>finally</code>: Handle exceptions.</li> <li><code>throw</code> / <code>throws</code>: Raise exceptions.</li> <li><code>assert</code>: Check assumptions during development.</li> </ul>"},{"location":"langdives/Java/KeyWordsTerminolgies/#memory-managementthreada","title":"Memory Management/Threada","text":"<ul> <li><code>new</code>: Allocates memory for an object.</li> <li><code>null</code>: A reference that points to no object.</li> <li><code>synchronized</code>: Used to control access to methods or blocks in a multithreaded environment.</li> <li><code>volatile</code>: Ensures visibility of changes to variables across threads.</li> <li><code>transient</code>: Prevents serialization of a field.</li> </ul>"},{"location":"langdives/Java/KeyWordsTerminolgies/#types","title":"Types","text":"<ul> <li><code>void</code>: Specifies that a method does not return a value.</li> <li><code>primitive types</code>: <code>int</code>, <code>float</code>, <code>char</code>, <code>boolean</code>, etc.</li> <li><code>instanceof</code>: Tests if an object is of a particular type.</li> </ul>"},{"location":"langdives/Java/KeyWordsTerminolgies/#others","title":"Others","text":"<ul> <li><code>enum</code>: Declares an enumeration, a special type with predefined constant values.</li> <li><code>package</code>: Defines a package (namespace) for classes.</li> <li><code>import</code>: Brings other classes or packages into the current class.</li> <li><code>default</code>: Provides default implementations in interfaces or switch statements.</li> <li><code>native</code>: Declares methods implemented in native code (outside Java).</li> <li><code>strictfp</code>: Ensures consistent floating-point calculations across platforms.</li> <li><code>const</code> / <code>goto</code>: Reserved keywords (not used in Java).</li> </ul>"},{"location":"langdives/Java/Locking-Intrinsic/","title":"Locking","text":"<p>Locking is an essential concept in multithreaded programming to prevent race conditions and ensure thread safety. When multiple threads access shared resources, locks ensure that only one thread accesses the critical section at a time.</p> <p>This article covers synchronized blocks.</p>"},{"location":"langdives/Java/Locking-Intrinsic/#what-is-locking","title":"What is Locking?","text":"<p>Locking is a way to ensure that only one thread at a time executes a critical section or modifies a shared resource, Without proper locks, multiple threads may interfere with each other, leading to data inconsistency or unexpected behavior (race conditions).</p> <p>Java offers various locking mechanisms, from synchronized blocks to explicit locks like <code>ReentrantLock</code>.</p>"},{"location":"langdives/Java/Locking-Intrinsic/#synchronized-and-intrinsic-locks","title":"Synchronized and Intrinsic Locks","text":"<p>Java\u2019s <code>synchronized</code> key   word is one of the primary ways to control access to shared resources in multithreaded programs. It ensures thread safety by providing mutual exclusion and visibility guarantees. Let's go further into every aspect of <code>synchronized</code>.</p> <p>How <code>synchronized</code> Works ?</p> <p>When a method or block is marked as <code>synchronized</code>, the JVM uses a monitor lock (intrinsic lock) for the associated object or class. The monitor is a synchronization construct provided by the JVM.</p> <p>Two things happen when a thread enters a synchronized block or method:</p> <ul> <li>Mutual Exclusion: No other thread can enter the synchronized block on the same object until the first thread exits.</li> <li>Visibility Guarantee: Changes made by the thread to variables inside the synchronized block are visible to other threads.</li> </ul> <p>Intrinsic Lock: Each Java object has an intrinsic lock (also called monitor lock) associated with it, The thread that enters the synchronized block acquires the intrinsic lock. When it leaves the block, it releases the lock, allowing other threads to acquire it.</p>"},{"location":"langdives/Java/Locking-Intrinsic/#synchronized-methods","title":"Synchronized Methods","text":""},{"location":"langdives/Java/Locking-Intrinsic/#instance-level-locking","title":"Instance-Level Locking","text":"<p>When you synchronize a non-static method, the thread acquires the lock on the instance of the class (the <code>this</code> object).</p> <pre><code>public synchronized void increment() {\n    // Lock acquired on the current instance (this)\n    count++;\n}\n</code></pre> <ul> <li>Impact: If multiple threads try to access <code>increment()</code> on the same object instance, only one thread will execute the method at a time. </li> <li>Different Instances: If threads are working on different instances of the class, they can run synchronized methods simultaneously.</li> </ul> Example with Instance-Level Locking <pre><code>class Counter {\n    private int count = 0;\n\n    public synchronized void increment() {\n        count++;\n    }\n\n    public synchronized int getCount() {\n        return count;\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws InterruptedException {\n        Counter counter = new Counter();\n\n        Thread t1 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) counter.increment();\n        });\n\n        Thread t2 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) counter.increment();\n        });\n\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n\n        System.out.println(\"Final Count: \" + counter.getCount());  // Output: 2000\n    }\n}\n</code></pre> <p>Why does this work ?</p> <p>Since both threads are operating on the same <code>Counter</code> object, only one thread at a time can execute the <code>increment()</code> method due to instance-level locking.</p>"},{"location":"langdives/Java/Locking-Intrinsic/#class-level-locking","title":"Class-Level Locking","text":"<p>A static synchronized method locks on the Class object (i.e., <code>ClassName.class</code>) rather than on an instance. This ensures that all threads calling static methods on the class are synchronized.</p> <pre><code>public synchronized static void staticIncrement() {\n    // Lock acquired on the class object (Counter.class)\n}\n</code></pre> <ul> <li>Impact: If a thread calls a static synchronized method, no other thread can access any other static synchronized method on that class until the lock is released. However, threads can still call non-static synchronized methods, since the instance and class-level locks are different.</li> </ul> Example with Class-Level Locking <pre><code>class Counter {\n    private static int count = 0;\n\n    public synchronized static void increment() {\n        count++;\n    }\n\n    public synchronized static int getCount() {\n        return count;\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws InterruptedException {\n        Thread t1 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) Counter.increment();\n        });\n\n        Thread t2 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) Counter.increment();\n        });\n\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n\n        System.out.println(\"Final Count: \" + Counter.getCount());  // Output: 2000\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Locking-Intrinsic/#synchronized-blocks","title":"Synchronized Blocks","text":"<p>A synchronized block provides more control than a synchronized method. You can choose which object\u2019s intrinsic lock to use, instead of locking the entire method.</p> <pre><code>public void increment() {\n    synchronized (this) {  // Locking on the current instance\n        count++;\n    }\n}\n</code></pre> When to use ? <ul> <li>To improve performance: Instead of synchronizing the entire method, only the critical section needs to be synchronized.</li> <li>To lock on specific objects: You can use any object as the lock, not just the instance or class.</li> </ul> <pre><code>class Counter {\n    private int count = 0;\n    private final Object lock = new Object();\n\n    public void increment() {\n        synchronized (lock) {  // Locking on a custom object\n            count++;\n        }\n    }\n}\n</code></pre> Example: Synchronized Block with Fine-Grained Control <pre><code>public void updateBothCounters(Counter counter1, Counter counter2) {\n    synchronized (counter1) {  // Locking on the first Counter object\n        counter1.increment();\n    }\n    synchronized (counter2) {  // Locking on the second Counter object\n        counter2.increment();\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Locking-Intrinsic/#how-it-work-internally","title":"How it Work Internally","text":"<ul> <li> <p>Entry to the Monitor</p> <ul> <li>When a thread enters a synchronized block or method, it acquires the monitor on the object or class.</li> <li>If another thread tries to enter the same block, it gets blocked until the monitor is released.</li> </ul> </li> <li> <p>Exit from the Monitor</p> <ul> <li>When the thread exits the synchronized block, the monitor is released, and another thread waiting on the monitor can proceed.</li> </ul> </li> <li> <p>Bias Locking and Lightweight Locking</p> <ul> <li>The JVM optimizes locks with biased locking (when only one thread uses the lock most of the time) and lightweight locking (fast path for uncontended locks).</li> <li>If contention occurs, the JVM escalates the lock to a heavyweight lock (blocking other threads).</li> </ul> </li> </ul>"},{"location":"langdives/Java/Locking-Intrinsic/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Synchronizing unnecessary code slows down the application so use when necessary.</p> </li> <li> <p>Minimize the scope of synchronization so use synchronized blocks rather than whole methods to reduce contention.</p> </li> <li> <p>Ensure you synchronize on the same object across threads to avoid incorrect locking behavior.</p> </li> <li> <p>Nested synchronized blocks can lead to deadlock. Use consistent lock ordering.</p> </li> </ul>"},{"location":"langdives/Java/Locking-Intrinsic/#potential-issues","title":"Potential Issues","text":"<ul> <li> <p>Deadlock, occurs if two or more threads are waiting for each other to release locks.</p> </li> <li> <p>Performance Bottlenecks, overusing synchronization can lead to contention, where threads are constantly waiting to acquire locks.</p> </li> <li> <p>Livelock, threads keep responding to each other without making progress (e.g., both threads keep yielding the lock to each other).</p> </li> </ul>"},{"location":"langdives/Java/Locking-Issues-DeadLock/","title":"Issues with Locking - DeadLock","text":"<p>Locking mechanisms in Java, while essential for ensuring thread safety in multithreaded applications, can introduce various issues if not used properly. </p> <p>In this article, we\u2019ll explore how deadlocks occur, how to prevent them, and practical examples of various techniques to detect and resolve deadlocks. A deadlock is a common concurrency issue in multithreaded programs and can severely impact performance.</p>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#what-is-deadlock","title":"What is Deadlock ?","text":"<p>A deadlock occurs when two or more threads are blocked indefinitely, Each thread is waiting for a lock held by the other, and neither can proceed.</p> <p>This results in a circular wait, where no thread can release the locks it holds, leading to a deadlock condition.</p>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#how-deadlock-occurs","title":"How Deadlock Occurs ?","text":"<p>Let\u2019s revisit the classic deadlock example.</p> Deadlock Example <pre><code>class A {\n    public synchronized void methodA(B b) {\n        System.out.println(Thread.currentThread().getName() + \": Locked A, waiting for B...\");\n        try {\n            Thread.sleep(50);  // Simulate some work\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        b.last();  // Waiting for lock on object B\n    }\n\n    public synchronized void last() {\n        System.out.println(Thread.currentThread().getName() + \": Inside A.last()\");\n    }\n}\n\nclass B {\n    public synchronized void methodB(A a) {\n        System.out.println(Thread.currentThread().getName() + \": Locked B, waiting for A...\");\n        try {\n            Thread.sleep(50);  // Simulate some work\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        a.last();  // Waiting for lock on object A\n    }\n\n    public synchronized void last() {\n        System.out.println(Thread.currentThread().getName() + \": Inside B.last()\");\n    }\n}\n\npublic class DeadlockDemo {\n    public static void main(String[] args) {\n        A a = new A();\n        B b = new B();\n\n        Thread t1 = new Thread(() -&gt; a.methodA(b), \"Thread 1\");\n        Thread t2 = new Thread(() -&gt; b.methodB(a), \"Thread 2\");\n\n        t1.start();\n        t2.start();\n    }\n}\n</code></pre> <p>Flow Analysis</p> <ol> <li> <p>Thread 1 starts and calls <code>a.methodA(b)</code>. It acquires the lock on object <code>A</code> and prints: <pre><code>Thread 1: Locked A, waiting for B...\n</code></pre></p> </li> <li> <p>Thread 2 starts and calls <code>b.methodB(a)</code>. It acquires the lock on object <code>B</code> and prints: <pre><code>Thread 2: Locked B, waiting for A...\n</code></pre></p> </li> <li> <p>Now:</p> <ul> <li>Thread 1 holds the lock on <code>A</code> and waits for Thread 2 to release the lock on <code>B</code>.</li> <li>Thread 2 holds the lock on <code>B</code> and waits for Thread 1 to release the lock on <code>A</code>.</li> </ul> </li> </ol> <p>Both threads are waiting indefinitely, resulting in a deadlock.</p>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#how-to-avoid","title":"How to Avoid ?","text":"<ul> <li>Acquiring Locks in a Consistent Order</li> <li>Using <code>tryLock()</code> with Timeout</li> <li>Avoid Nested Locks</li> <li>Using Lock Ordering Techniques</li> </ul>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#acquiring-locks-in-a-order","title":"Acquiring Locks in a Order","text":"<p>If all threads acquire locks in the same order, deadlock can be prevented.</p> Modified Example: Acquiring Locks in the Same Order <pre><code>class A {\n    public void methodA(B b) {\n        synchronized (this) {\n            System.out.println(Thread.currentThread().getName() + \": Locked A, waiting for B...\");\n            synchronized (b) {\n                System.out.println(Thread.currentThread().getName() + \": Acquired lock on B\");\n                b.last();\n            }\n        }\n    }\n\n    public void last() {\n        System.out.println(Thread.currentThread().getName() + \": Inside A.last()\");\n    }\n}\n\nclass B {\n    public void methodB(A a) {\n        synchronized (this) {\n            System.out.println(Thread.currentThread().getName() + \": Locked B, waiting for A...\");\n            synchronized (a) {\n                System.out.println(Thread.currentThread().getName() + \": Acquired lock on A\");\n                a.last();\n            }\n        }\n    }\n\n    public void last() {\n        System.out.println(Thread.currentThread().getName() + \": Inside B.last()\");\n    }\n}\n\npublic class DeadlockResolved {\n    public static void main(String[] args) {\n        A a = new A();\n        B b = new B();\n\n        Thread t1 = new Thread(() -&gt; a.methodA(b), \"Thread 1\");\n        Thread t2 = new Thread(() -&gt; b.methodB(a), \"Thread 2\");\n\n        t1.start();\n        t2.start();\n    }\n}\n</code></pre> <p>Explanation</p> <p>Both threads now acquire locks in the same order (<code>A</code> \u2192 <code>B</code>). This ensures that deadlock cannot occur.</p>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#using-trylock-with-timeout","title":"Using <code>tryLock()</code> with Timeout","text":"<p>The <code>tryLock()</code> method attempts to acquire a lock and fails gracefully if the lock is not available within a specified time.</p> Deadlock Prevention using <code>tryLock()</code> example <pre><code>import java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class TryLockDemo {\n    private final ReentrantLock lockA = new ReentrantLock();\n    private final ReentrantLock lockB = new ReentrantLock();\n\n    public void methodA() {\n        try {\n            if (lockA.tryLock(1, TimeUnit.SECONDS)) {\n                System.out.println(Thread.currentThread().getName() + \": Locked A\");\n                Thread.sleep(50);  // Simulate some work\n\n                if (lockB.tryLock(1, TimeUnit.SECONDS)) {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \": Locked B\");\n                    } finally {\n                        lockB.unlock();\n                    }\n                } else {\n                    System.out.println(Thread.currentThread().getName() + \": Could not acquire lock B, releasing A\");\n                }\n\n                lockA.unlock();\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public void methodB() {\n        try {\n            if (lockB.tryLock(1, TimeUnit.SECONDS)) {\n                System.out.println(Thread.currentThread().getName() + \": Locked B\");\n                Thread.sleep(50);  // Simulate some work\n\n                if (lockA.tryLock(1, TimeUnit.SECONDS)) {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \": Locked A\");\n                    } finally {\n                        lockA.unlock();\n                    }\n                } else {\n                    System.out.println(Thread.currentThread().getName() + \": Could not acquire lock A, releasing B\");\n                }\n\n                lockB.unlock();\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void main(String[] args) {\n        TryLockDemo demo = new TryLockDemo();\n\n        Thread t1 = new Thread(demo::methodA, \"Thread 1\");\n        Thread t2 = new Thread(demo::methodB, \"Thread 2\");\n\n        t1.start();\n        t2.start();\n    }\n}\n</code></pre> <p>Explanation</p> <p>If a thread fails to acquire a lock within the timeout, it releases any locks it holds, avoiding a deadlock.</p>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#detecting-using-monitoring-tools","title":"Detecting Using Monitoring Tools","text":"<p>You can detect deadlocks using tools like:</p> <ul> <li>VisualVM: A monitoring tool bundled with the JDK.</li> <li>JConsole: Also part of the JDK, useful for tracking deadlocks in running applications.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>tryLock()</code> with timeout to avoid indefinite blocking.</li> <li>Minimize nested locks to reduce the chances of deadlock.</li> <li>Acquire locks in a consistent order across all threads.</li> <li>Use lock-free data structures like <code>AtomicInteger</code> or <code>ConcurrentHashMap</code> when possible.</li> <li>Analyze your code for potential deadlock scenarios.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-DeadLock/#summary","title":"Summary","text":"<p>Deadlocks are one of the most common and dangerous issues in multithreaded programming.</p>"},{"location":"langdives/Java/Locking-Issues-LiveLock/","title":"Issues with Locking - LiveLock","text":"<p>Locking mechanisms in Java, while essential for ensuring thread safety in multithreaded applications, can introduce various issues if not used properly. </p> <p>In this article, we\u2019ll explore how livelock occur, how to prevent them, and practical examples of various techniques to detect and resolve livelock.</p>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#what-is-livelock","title":"What is Livelock ?","text":"<p>In a livelock, multiple threads remain active but unable to make progress because they keep responding to each other\u2019s actions. Unlike deadlock, where threads are stuck waiting for locks indefinitely, threads in a livelock keep changing their states in response to each other, but they fail to reach a final state or make useful progress.</p> <p>Key difference from deadlock</p> <p>In deadlock, threads are blocked waiting for each other, while in livelock, threads are not blocked, but they keep releasing and reacquiring locks or changing states in a way that prevents progress.</p>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#example-of-livelock","title":"Example of Livelock","text":"<p>Consider two people trying to pick up a spoon to eat, but they keep yielding to each other in an attempt to be polite. Neither person can make progress because they\u2019re constantly checking and responding to each other\u2019s actions.</p> Livelock Example <pre><code>class Spoon {\n    private boolean isAvailable = true;\n\n    public synchronized boolean pickUp() {\n        if (isAvailable) {\n            isAvailable = false;\n            return true;\n        }\n        return false;\n    }\n\n    public synchronized void putDown() {\n        isAvailable = true;\n    }\n}\n\npublic class LivelockDemo {\n    public static void main(String[] args) {\n        Spoon spoon = new Spoon();\n\n        Thread person1 = new Thread(() -&gt; {\n            while (!spoon.pickUp()) {\n                System.out.println(\"Person 1: Waiting for spoon...\");\n                Thread.yield();  // Yield control to other threads\n            }\n            System.out.println(\"Person 1: Picked up spoon!\");\n        });\n\n        Thread person2 = new Thread(() -&gt; {\n            while (!spoon.pickUp()) {\n                System.out.println(\"Person 2: Waiting for spoon...\");\n                Thread.yield();  // Yield control to other threads\n            }\n            System.out.println(\"Person 2: Picked up spoon!\");\n        });\n\n        person1.start();\n        person2.start();\n    }\n}\n</code></pre> <p>Explanation</p> <ul> <li>Both threads (Person 1 and Person 2) are trying to pick up the spoon.</li> <li>If the spoon is not available, they yield control to the other thread to be polite.</li> <li>However, both threads keep yielding repeatedly, resulting in livelock\u2014neither thread can proceed.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#causes-of-livelock","title":"Causes of Livelock","text":"<ul> <li> <p>Excessive Yielding or Giving Way: Threads are too polite and keep yielding to each other and In Java, using <code>Thread.yield()</code> repeatedly can lead to livelock.</p> </li> <li> <p>Conflicting Retrying Logic: Both threads retry in response to each other\u2019s behavior, creating a circular dependency.</p> </li> <li> <p>Improper Design of Locking Mechanisms, Threads repeatedly release and reacquire locks without making useful progress.</p> </li> <li> <p>Poor Handling of Shared Resources, When shared resources are locked and unlocked too frequently, threads can repeatedly fail to acquire them.</p> </li> </ul>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#how-to-avoid-livelocks","title":"How to Avoid Livelocks","text":""},{"location":"langdives/Java/Locking-Issues-LiveLock/#use-timeouts-for-locking","title":"Use Timeouts for Locking","text":"<p>Using timeouts helps threads avoid indefinite waiting. If a thread cannot acquire the lock within a certain time, it can stop trying or take an alternative path.</p> Using <code>tryLock()</code> with Timeout <pre><code>import java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.ReentrantLock;\n\nclass Spoon {\n    private final ReentrantLock lock = new ReentrantLock();\n\n    public boolean pickUp() throws InterruptedException {\n        // Try to acquire the lock with a timeout\n        return lock.tryLock(1, TimeUnit.SECONDS);\n    }\n\n    public void putDown() {\n        lock.unlock();\n    }\n}\n\npublic class LivelockFixed {\n    public static void main(String[] args) {\n        Spoon spoon = new Spoon();\n\n        Thread person1 = new Thread(() -&gt; {\n            try {\n                if (spoon.pickUp()) {\n                    System.out.println(\"Person 1: Picked up spoon!\");\n                    spoon.putDown();\n                } else {\n                    System.out.println(\"Person 1: Couldn't get the spoon in time.\");\n                }\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        });\n\n        Thread person2 = new Thread(() -&gt; {\n            try {\n                if (spoon.pickUp()) {\n                    System.out.println(\"Person 2: Picked up spoon!\");\n                    spoon.putDown();\n                } else {\n                    System.out.println(\"Person 2: Couldn't get the spoon in time.\");\n                }\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        });\n\n        person1.start();\n        person2.start();\n    }\n}\n</code></pre> <p>Why it works ?</p> <p>If a thread fails to acquire the lock within 1 second, it backs off instead of trying indefinitely.</p>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#use-back-off-strategies","title":"Use Back-off Strategies","text":"<p>A back-off strategy makes threads wait for a random amount of time before retrying. This avoids a situation where two threads keep checking the same lock in sync.</p> Back-off Strategy Example <pre><code>import java.util.Random;\nimport java.util.concurrent.locks.ReentrantLock;\n\nclass Spoon {\n    private final ReentrantLock lock = new ReentrantLock();\n    private final Random random = new Random();\n\n    public boolean tryPickUp() {\n        return lock.tryLock();\n    }\n\n    public void putDown() {\n        lock.unlock();\n    }\n\n    public void backOff() throws InterruptedException {\n        Thread.sleep(random.nextInt(100));  // Wait for a random time\n    }\n}\n\npublic class LivelockWithBackoff {\n    public static void main(String[] args) {\n        Spoon spoon = new Spoon();\n\n        Thread person1 = new Thread(() -&gt; {\n            try {\n                while (!spoon.tryPickUp()) {\n                    System.out.println(\"Person 1: Waiting...\");\n                    spoon.backOff();  // Wait before retrying\n                }\n                System.out.println(\"Person 1: Picked up spoon!\");\n                spoon.putDown();\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        });\n\n        Thread person2 = new Thread(() -&gt; {\n            try {\n                while (!spoon.tryPickUp()) {\n                    System.out.println(\"Person 2: Waiting...\");\n                    spoon.backOff();  // Wait before retrying\n                }\n                System.out.println(\"Person 2: Picked up spoon!\");\n                spoon.putDown();\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        });\n\n        person1.start();\n        person2.start();\n    }\n}\n</code></pre> <p>Why it works ?</p> <p>The random back-off time prevents threads from retrying in lockstep, avoiding livelock.</p>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#avoid-excessive-yielding","title":"Avoid Excessive Yielding","text":"<p>Frequent use of <code>Thread.yield()</code> can lead to livelock. Instead, use timeouts or back-off strategies to prevent threads from constantly giving way to each other.</p>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#use-condition-variables","title":"Use Condition Variables","text":"<p>Use <code>Condition</code> variables (available with <code>ReentrantLock</code>) to properly coordinate threads waiting on specific conditions.</p> Using Condition Variables Example <pre><code>import java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.ReentrantLock;\n\nclass Spoon {\n    private boolean isAvailable = true;\n    private final ReentrantLock lock = new ReentrantLock();\n    private final Condition spoonAvailable = lock.newCondition();\n\n    public void pickUp() throws InterruptedException {\n        lock.lock();\n        try {\n            while (!isAvailable) {\n                spoonAvailable.await();  // Wait until spoon is available\n            }\n            isAvailable = false;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void putDown() {\n        lock.lock();\n        try {\n            isAvailable = true;\n            spoonAvailable.signal();  // Notify waiting thread\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n</code></pre> <p>Why it works ?</p> <p>Using condition variables ensures that only one thread proceeds when the spoon becomes available, avoiding busy-waiting and yielding.</p>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#best-practices","title":"Best Practices","text":"<ul> <li>Use Timeouts: Prevent indefinite waiting by setting time limits for acquiring locks.</li> <li>Back-off Strategies: Introduce random delays before retrying to avoid lockstep behavior.</li> <li>Avoid Yield Loops: Replace <code>yield()</code> with smarter coordination mechanisms like conditions.</li> <li>Use Fair Locks: Fair locks reduce the chance of thread contention leading to livelock.</li> <li>Monitor and Tune: Use tools like VisualVM or JConsole to monitor thread states and detect livelocks in production systems.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-LiveLock/#summary","title":"Summary","text":"<p>Livelocks can be tricky to detect because threads remain active, but they fail to make meaningful progress. By using timeouts, back-off strategies, condition variables, and proper locking mechanisms.</p>"},{"location":"langdives/Java/Locking-Issues-Others/","title":"Issues with Locking - Other Issues","text":"<p>Locking mechanisms in Java, while essential for ensuring thread safety in multithreaded applications, can introduce various issues if not used properly. </p> <p>We will cover key locking issues in Java in this article like race conditions, thread contention, missed signals, nested locks, overuse of locks, and performance impact. Each section contains causes, examples, solutions, and best practices to avoid or mitigate these issues.</p>"},{"location":"langdives/Java/Locking-Issues-Others/#race-conditions-despite-locking","title":"Race Conditions Despite Locking","text":"Cause <p>A race condition occurs when multiple threads access a shared resource without proper synchronization, leading to inconsistent results based on the timing of thread execution. Even with partial locks, a shared variable may still be accessed inconsistently if not protected properly.</p> <p>Race Condition Example</p> <pre><code>class Counter {\n    private int count = 0;\n\n    public void increment() {\n        synchronized (this) {\n            count++;\n        }\n    }\n\n    public int getCount() {\n        // Not synchronized, potential race condition.\n        return count;\n    }\n}\n</code></pre> <p>Problem</p> <ul> <li>Thread 1 increments <code>count</code> to 1.</li> <li>Before <code>count</code> can be read by Thread 2, Thread 3 increments it again.</li> <li>As <code>getCount()</code> is not synchronized, the returned value may skip increments due to improper timing.</li> </ul> Solution and Best Practices <ul> <li> <p>Always synchronize access to shared variables, even on read operations if other threads can modify the data. <pre><code>class Counter {\n    private int count = 0;\n\n    public synchronized void increment() {\n        count++;\n    }\n\n    public synchronized int getCount() {\n        return count;\n    }\n}\n</code></pre></p> </li> <li> <p>Use <code>AtomicInteger</code> if possible for thread-safe increments: <pre><code>import java.util.concurrent.atomic.AtomicInteger;\n\nclass Counter {\n    private final AtomicInteger count = new AtomicInteger(0);\n\n    public void increment() {\n        count.incrementAndGet();\n    }\n\n    public int getCount() {\n        return count.get();\n    }\n}\n</code></pre></p> </li> </ul>"},{"location":"langdives/Java/Locking-Issues-Others/#contention-performance-issues","title":"Contention &amp; Performance Issues","text":"Cause <p>When multiple threads compete for the same lock, they spend time waiting for the lock to become available, reducing throughput and performance.</p> <p>Contention Example</p> <pre><code>class BankAccount {\n    private int balance = 100;\n\n    public synchronized void withdraw(int amount) {\n        balance -= amount;\n    }\n\n    public synchronized int getBalance() {\n        return balance;\n    }\n}\n</code></pre> <p>Problem</p> <p>If multiple threads frequently access the <code>withdraw()</code> method, contention for the lock will occur, degrading performance.</p> Solution and Best Practices <ul> <li> <p>Minimize the Scope of Synchronized Blocks: <pre><code>public void withdraw(int amount) {\n    if (amount &lt;= 0) return;\n\n    synchronized (this) {\n        balance -= amount;\n    }\n}\n</code></pre></p> </li> <li> <p>Use <code>ReadWriteLock</code> if reads dominate writes: <pre><code>import java.util.concurrent.locks.ReentrantReadWriteLock;\n\nclass BankAccount {\n    private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\n    private int balance = 100;\n\n    public void withdraw(int amount) {\n        lock.writeLock().lock();\n        try {\n            balance -= amount;\n        } finally {\n            lock.writeLock().unlock();\n        }\n    }\n\n    public int getBalance() {\n        lock.readLock().lock();\n        try {\n            return balance;\n        } finally {\n            lock.readLock().unlock();\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>Use lock-free data structures like <code>AtomicInteger</code> or <code>ConcurrentHashMap</code> to reduce contention.</p> </li> </ul>"},{"location":"langdives/Java/Locking-Issues-Others/#missed-signals-lost-wake-ups","title":"Missed Signals &amp; Lost Wake-ups","text":"Cause <p>When a thread misses a <code>notify()</code> signal because it was not yet waiting on the lock, a lost wake-up occurs. This results in threads waiting indefinitely for a signal that has already been sent.</p> <p>Lost Wake-Up Example</p> <pre><code>public synchronized void produce() throws InterruptedException {\n    while (available) {\n        wait();  // Missed if notify() was called before reaching here.\n    }\n    available = true;\n    notify();\n}\n</code></pre> Solution and Best Practices <ul> <li> <p>Always Use a <code>while</code> Loop Instead of <code>if</code>, The <code>while</code> loop ensures the thread rechecks the condition after being notified (to avoid spurious wake-ups). <pre><code>public synchronized void produce() throws InterruptedException {\n    while (available) {\n        wait();\n    }\n    available = true;\n    notify();\n}\n</code></pre></p> </li> <li> <p>Use <code>Condition</code> Variables with <code>ReentrantLock</code> for finer control: <pre><code>private final ReentrantLock lock = new ReentrantLock();\nprivate final Condition condition = lock.newCondition();\nprivate boolean available = false;\n\npublic void produce() throws InterruptedException {\n    lock.lock();\n    try {\n        while (available) {\n            condition.await();  // Wait on condition.\n        }\n        available = true;\n        condition.signal();\n    } finally {\n        lock.unlock();\n    }\n}\n</code></pre></p> </li> </ul>"},{"location":"langdives/Java/Locking-Issues-Others/#nested-locks-ordering-issues","title":"Nested Locks &amp; Ordering Issues","text":"Cause <p>Using multiple locks can cause deadlocks if threads acquire locks in different orders.</p> <p>Deadlock Example</p> <pre><code>synchronized (lock1) {\n    synchronized (lock2) {\n        // Critical section\n    }\n}\n</code></pre> <p>Problem</p> <p>If Thread 1 acquires <code>lock1</code> and Thread 2 acquires <code>lock2</code>, both threads will wait indefinitely for each other\u2019s lock, resulting in a deadlock.</p> Solution and Best Practices <ul> <li>Use a consistent lock acquisition order across all threads.</li> <li>Use <code>tryLock()</code> with timeout to avoid blocking indefinitely: <pre><code>if (lock1.tryLock(1, TimeUnit.SECONDS)) {\n    if (lock2.tryLock(1, TimeUnit.SECONDS)) {\n        try {\n            // Critical section\n        } finally {\n            lock2.unlock();\n        }\n    }\n    lock1.unlock();\n}\n</code></pre></li> </ul>"},{"location":"langdives/Java/Locking-Issues-Others/#overuse-of-locks","title":"Overuse of Locks","text":"Cause <p>Using too many locks or locking too frequently can reduce parallelism, resulting in poor scalability, If every method in a class is synchronized, threads will frequently block each other, reducing concurrency and efficiency.</p> Solution and Best Practices <ul> <li>Minimize Lock Usage by synchronizing only critical sections.</li> <li>Use concurrent collections (like <code>ConcurrentHashMap</code>) instead of traditional synchronized collections: <pre><code>ConcurrentHashMap&lt;String, Integer&gt; map = new ConcurrentHashMap&lt;&gt;();\n</code></pre></li> </ul>"},{"location":"langdives/Java/Locking-Issues-Others/#overhead-of-locking","title":"Overhead of Locking","text":"Cause <p>Locking adds overhead in the form of: - Context switches between threads. - CPU cache invalidation. - JVM's monitor management for intrinsic locks.</p> <p>Performance Issues with Synchronized Code</p> <p>Excessive locking causes contention and frequent context switches, impacting throughput and latency.</p> Solution and Best Practices <ul> <li>Use atomic classes like <code>AtomicInteger</code> for simple counters.</li> <li>Use lock-free algorithms whenever possible.</li> <li>Use thread pools to reduce the overhead of creating and managing threads.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-Others/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Use <code>tryLock()</code> for non-blocking operations:    <pre><code>if (lock.tryLock()) {\n    try {\n        // Critical section\n    } finally {\n        lock.unlock();\n    }\n}\n</code></pre></p> </li> <li> <p>Minimize the scope of synchronized blocks to reduce contention.</p> </li> <li> <p>Use fair locks to avoid starvation:    <pre><code>ReentrantLock lock = new ReentrantLock(true);  // Fair lock\n</code></pre></p> </li> <li> <p>Use lock-free data structures when possible (e.g., <code>ConcurrentHashMap</code>).</p> </li> <li> <p>Monitor and detect deadlocks using tools like VisualVM or JConsole.</p> </li> <li> <p>Follow consistent lock ordering to prevent deadlocks.</p> </li> </ul>"},{"location":"langdives/Java/Locking-Issues-Others/#summary","title":"Summary","text":"<p>Locking is essential to ensure thread safety, but improper use can lead to issues such as race conditions, deadlocks, livelocks, contention, and performance degradation. Understanding these issues and following best practices will help you write efficient, scalable, and thread-safe code. Using fine-grained locks and concurrent utilities wisely to maximize concurrency while minimizing risks.</p>"},{"location":"langdives/Java/Locking-Issues-Starvation/","title":"Issues with Locking - Starvation","text":"<p>Locking mechanisms in Java, while essential for ensuring thread safety in multithreaded applications, can introduce various issues if not used properly. </p> <p>In this article, we\u2019ll explore how starvation occur, how to prevent them, and practical examples of various techniques to detect and resolve starvation.</p>"},{"location":"langdives/Java/Locking-Issues-Starvation/#what-is-starvation","title":"What is Starvation ?","text":"<p>Starvation is a condition where low-priority threads are unable to gain access to resources because higher-priority threads or unfair scheduling policies monopolize CPU time or locks. As a result, the low-priority thread starves and never gets the chance to run, even though it is ready to execute.</p> <p>This issue can manifest in multithreaded programs when locks or resources are continuously granted to specific threads, leaving others waiting indefinitely. It can occur not only due to CPU scheduling but also due to improper locking strategies, unfair algorithms, or resource starvation.</p>"},{"location":"langdives/Java/Locking-Issues-Starvation/#causes-of-starvation","title":"Causes of Starvation","text":"<ul> <li> <p>Unfair Locking Mechanism, When using unfair locks, the lock may always favor threads that request it recently over those that have been waiting longer. </p> </li> <li> <p>Priority Inversion, High-priority threads monopolize the CPU and low-priority threads rarely get scheduled. This is especially problematic in priority-based scheduling systems.</p> </li> <li> <p>Thread Contention and Resource Starvation, Too many threads competing for a limited number of resources (like I/O or locks), some threads may always be able to acquire the resources, leaving others waiting indefinitely.</p> </li> <li> <p>Busy-Waiting Loops, Threads that continuously request resources or repeatedly try to acquire locks without releasing the CPU can cause other threads to starve.</p> </li> <li> <p>Thread Prioritization in Java, If threads have different priorities, the JVM might schedule higher-priority threads more frequently, leading to starvation of lower-priority threads.</p> </li> </ul>"},{"location":"langdives/Java/Locking-Issues-Starvation/#example-of-starvation","title":"Example of Starvation","text":"Starvation with Unfair Lock Example <pre><code>import java.util.concurrent.locks.ReentrantLock;\n\npublic class StarvationDemo {\n    private static final ReentrantLock lock = new ReentrantLock();  // Unfair lock\n\n    public static void main(String[] args) {\n        Runnable task = () -&gt; {\n            while (true) {\n                if (lock.tryLock()) {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \" got the lock!\");\n                        break;\n                    } finally {\n                        lock.unlock();\n                    }\n                } else {\n                    System.out.println(Thread.currentThread().getName() + \" waiting...\");\n                }\n            }\n        };\n\n        Thread highPriority = new Thread(task, \"High-Priority\");\n        highPriority.setPriority(Thread.MAX_PRIORITY);\n\n        Thread lowPriority = new Thread(task, \"Low-Priority\");\n        lowPriority.setPriority(Thread.MIN_PRIORITY);\n\n        highPriority.start();\n        lowPriority.start();\n    }\n}\n</code></pre> <p>Explanation</p> <ul> <li>The ReentrantLock is unfair by default.</li> <li>The high-priority thread has a better chance of acquiring the lock repeatedly.</li> <li>The low-priority thread may never acquire the lock, resulting in starvation.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-Starvation/#how-to-avoid","title":"How to Avoid ?","text":""},{"location":"langdives/Java/Locking-Issues-Starvation/#use-fair-locks","title":"Use Fair Locks","text":"<p>Using fair locks ensures that the longest-waiting thread gets the lock first. This prevents threads from skipping the queue and ensures all threads get a chance to execute.</p> Fair Lock Example <pre><code>import java.util.concurrent.locks.ReentrantLock;\n\npublic class FairLockDemo {\n    private static final ReentrantLock lock = new ReentrantLock(true);  // Fair lock\n\n    public static void main(String[] args) {\n        Runnable task = () -&gt; {\n            while (true) {\n                if (lock.tryLock()) {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \" got the lock!\");\n                        break;\n                    } finally {\n                        lock.unlock();\n                    }\n                } else {\n                    System.out.println(Thread.currentThread().getName() + \" waiting...\");\n                }\n            }\n        };\n\n        Thread highPriority = new Thread(task, \"High-Priority\");\n        Thread lowPriority = new Thread(task, \"Low-Priority\");\n\n        highPriority.setPriority(Thread.MAX_PRIORITY);\n        lowPriority.setPriority(Thread.MIN_PRIORITY);\n\n        highPriority.start();\n        lowPriority.start();\n    }\n}\n</code></pre> <p>Note</p> <ul> <li>With the fair lock enabled, the thread that waits the longest gets access to the lock first.</li> <li>This prevents starvation and ensures fairness among threads.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-Starvation/#avoid-priority-based-scheduling","title":"Avoid Priority-Based Scheduling","text":"<p>Although Java allows you to assign priorities to threads, the JVM\u2019s thread scheduler may not always honor them consistently. It\u2019s generally recommended to avoid relying on thread priorities for critical tasks, If you need to control thread scheduling, use fair locks or condition variables instead of thread priorities.</p>"},{"location":"langdives/Java/Locking-Issues-Starvation/#backoff-strategies","title":"Backoff Strategies","text":"<p>Using backoff strategies (delays) between retries can help reduce contention for resources. This ensures that no thread monopolizes the CPU by continuously attempting to acquire a resource.</p> Backoff Strategy Example <pre><code>import java.util.concurrent.locks.ReentrantLock;\n\npublic class BackoffDemo {\n    private static final ReentrantLock lock = new ReentrantLock();\n\n    public static void main(String[] args) {\n        Runnable task = () -&gt; {\n            while (true) {\n                if (lock.tryLock()) {\n                    try {\n                        System.out.println(Thread.currentThread().getName() + \" got the lock!\");\n                        break;\n                    } finally {\n                        lock.unlock();\n                    }\n                } else {\n                    System.out.println(Thread.currentThread().getName() + \" waiting...\");\n                    try {\n                        Thread.sleep((long) (Math.random() * 100));  // Random delay\n                    } catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                    }\n                }\n            }\n        };\n\n        Thread t1 = new Thread(task, \"Thread-1\");\n        Thread t2 = new Thread(task, \"Thread-2\");\n\n        t1.start();\n        t2.start();\n    }\n}\n</code></pre> <p>Note</p> <p>Random delays ensure that threads do not engage in busy-waiting loops, reducing contention and improving fairness.</p>"},{"location":"langdives/Java/Locking-Issues-Starvation/#use-thread-pools","title":"Use Thread Pools","text":"<p>When dealing with many concurrent tasks, using a thread pool ensures that threads are fairly scheduled and resources are shared efficiently. </p> Using ThreadPoolExecutor Example <pre><code>import java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class ThreadPoolDemo {\n    public static void main(String[] args) {\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n\n        Runnable task = () -&gt; {\n            System.out.println(Thread.currentThread().getName() + \" is running\");\n        };\n\n        for (int i = 0; i &lt; 5; i++) {\n            executor.submit(task);\n        }\n\n        executor.shutdown();\n    }\n}\n</code></pre> <p>Note</p> <p>Using thread pools avoids creating too many threads and ensures fair resource sharing.</p>"},{"location":"langdives/Java/Locking-Issues-Starvation/#avoid-long-critical-sections","title":"Avoid Long Critical Sections","text":"<ul> <li>If a thread holds a lock for too long, it can cause starvation for other threads.</li> <li>Split large critical sections into smaller synchronized blocks to reduce lock contention.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-Starvation/#use-condition-variables","title":"Use Condition Variables","text":"<p>Instead of relying on priorities or busy-waiting, use <code>Condition</code> objects with ReentrantLock to manage thread coordination efficiently.</p> Condition Variables Example <pre><code>import java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class ConditionDemo {\n    private static final Lock lock = new ReentrantLock();\n    private static final Condition condition = lock.newCondition();\n\n    public static void main(String[] args) {\n        new Thread(() -&gt; {\n            lock.lock();\n            try {\n                System.out.println(\"Waiting...\");\n                condition.await();  // Wait for a signal\n                System.out.println(\"Resumed\");\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            } finally {\n                lock.unlock();\n            }\n        }).start();\n\n        new Thread(() -&gt; {\n            lock.lock();\n            try {\n                Thread.sleep(1000);\n                condition.signal();  // Signal the waiting thread\n                System.out.println(\"Signaled\");\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            } finally {\n                lock.unlock();\n            }\n        }).start();\n    }\n}\n</code></pre> <p>Note</p> <p>Using conditions helps avoid busy-waiting and ensures efficient thread signaling.</p>"},{"location":"langdives/Java/Locking-Issues-Starvation/#best-practices","title":"Best Practices","text":"<ul> <li>Use Fair Locks to prevent thread starvation.</li> <li>Avoid priority-based thread scheduling for critical operations.</li> <li>Implement backoff strategies to reduce contention.</li> <li>Use thread pools to manage threads efficiently.</li> <li>Minimize the time spent holding locks by breaking up large critical sections.</li> <li>Use Condition variables for better control of thread synchronization.</li> </ul>"},{"location":"langdives/Java/Locking-Issues-Starvation/#summary","title":"Summary","text":"<p>Starvation is a subtle but serious issue in multithreaded programs, particularly when some threads are prioritized over others or when resources are monopolized by specific threads. By using fair locks, thread pools, backoff strategies, and avoiding long critical sections.</p>"},{"location":"langdives/Java/Locking-Reentrant/","title":"Locking.","text":"<p>Locking is an essential concept in multithreaded programming to prevent race conditions and ensure thread safety. When multiple threads access shared resources, locks ensure that only one thread accesses the critical section at a time.</p> <p>This article covers reentrant locks.</p>"},{"location":"langdives/Java/Locking-Reentrant/#what-is-locking","title":"What is Locking ?","text":"<p>Locking is a way to ensure that only one thread at a time executes a critical section or modifies a shared resource, Without proper locks, multiple threads may interfere with each other, leading to data inconsistency or unexpected behavior (race conditions).</p> <p>Java offers various locking mechanisms, from synchronized blocks to explicit locks like <code>ReentrantLock</code>.</p>"},{"location":"langdives/Java/Locking-Reentrant/#what-is-reentrantlock","title":"What is <code>ReentrantLock</code> ?","text":"<p>The <code>ReentrantLock</code> class, introduced in Java 5, offers more control over thread synchronization than the <code>synchronized</code> keyword. It allows for advanced locking techniques such as fairness policies, tryLock, and interruptible locks. Let\u2019s explore everything about <code>ReentrantLock</code>, including its use cases, internal mechanisms, and best practices.</p> <p><code>ReentrantLock</code> is a concrete class in the <code>java.util.concurrent.locks</code> package that implements the Lock interface. </p> <p>Note</p> <ul> <li>Fine-grained control over locking, including fair and unfair locks.</li> <li>The ability for a thread to re-acquire a lock it already holds without blocking (hence the term \"reentrant\").</li> <li>Explicit unlocking, unlike the <code>synchronized</code> keyword, which automatically releases the lock when the block exits.</li> </ul> Example <pre><code>import java.util.concurrent.locks.ReentrantLock;\n\nclass Counter {\n    private int count = 0;\n    private final ReentrantLock lock = new ReentrantLock();\n\n    public void increment() {\n        lock.lock();  // Acquire the lock\n        try {\n            count++;\n        } finally {\n            lock.unlock();  // Release the lock\n        }\n    }\n\n    public int getCount() {\n        lock.lock();\n        try {\n            return count;\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws InterruptedException {\n        Counter counter = new Counter();\n\n        Thread t1 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) counter.increment();\n        });\n\n        Thread t2 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) counter.increment();\n        });\n\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n\n        System.out.println(\"Final Count: \" + counter.getCount());  // Output: 2000\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Locking-Reentrant/#how-it-works-internally","title":"How it Works Internally ?","text":"<p>Lock Acquisition: When a thread calls <code>lock()</code>, it tries to acquire the lock. If the lock is available, the thread proceeds otherwise, it blocks until the lock becomes available.</p> <p>Reentrancy: A thread that holds the lock can acquire the lock again without blocking. This is useful when a thread *nters a method that also calls another synchronized method or block that requires the same lock.</p> <p>Fair vs Unfair Locking:</p> <ul> <li> <p>Fair Lock: Threads are granted access in the order they requested the lock. this lock ensures that the longest-waiting thread gets the lock first, the main advantage is this avoids thread starvation and the disadvantage is it may have lower performence due to increased overhead    <pre><code>ReentrantLock lock = new ReentrantLock(true);  // Fair lock\n</code></pre></p> </li> <li> <p>Unfair Lock: Threads may skip the queue if the lock is released, improving performance but reducing fairness the main advantage is better throughout because threads are allowed to \"Jump the queue\" but disadvantage is it can lead to thread starvation where some threads may not get chance to execute.    <pre><code>ReentrantLock lock = new ReentrantLock();  // Unfair lock (default)\n</code></pre></p> </li> </ul>"},{"location":"langdives/Java/Locking-Reentrant/#advanced-locking-techniques","title":"Advanced Locking Techniques","text":""},{"location":"langdives/Java/Locking-Reentrant/#trylock","title":"tryLock()","text":"<p>The <code>tryLock()</code> method attempts to acquire the lock without blocking. It returns true if the lock is acquired, otherwise false.</p> Example <pre><code>if (lock.tryLock()) {\n    try {\n        // Perform task\n    } finally {\n        lock.unlock();\n    }\n} else {\n    System.out.println(\"Could not acquire lock, doing something else...\");\n}\n</code></pre> When to use ? <p>When you want to avoid blocking indefinitely if the lock is not available.</p>"},{"location":"langdives/Java/Locking-Reentrant/#trylock-with-timeout","title":"tryLock with Timeout","text":"<p>The <code>tryLock(long timeout, TimeUnit unit)</code> method waits for a specific amount of time to acquire the lock.</p> Example <pre><code>import java.util.concurrent.TimeUnit;\n\nif (lock.tryLock(1, TimeUnit.SECONDS)) {\n    try {\n        // Perform task\n    } finally {\n        lock.unlock();\n    }\n} else {\n    System.out.println(\"Could not acquire lock within timeout.\");\n}\n</code></pre> When to use ? <p>When waiting indefinitely is not practical, such as network operations or I/O tasks.</p>"},{"location":"langdives/Java/Locking-Reentrant/#interruptible-lock-acquisition","title":"Interruptible Lock Acquisition","text":"<p>The <code>lockInterruptibly()</code> method allows a thread to acquire the lock but respond to interrupts while waiting.</p> Example <pre><code>try {\n    lock.lockInterruptibly();  // Wait for lock, but respond to interrupts\n    try {\n        // Perform task\n    } finally {\n        lock.unlock();\n    }\n} catch (InterruptedException e) {\n    System.out.println(\"Thread was interrupted.\");\n}\n</code></pre> When to use ? <p>Use when a thread needs to be interrupted while waiting for a lock.</p>"},{"location":"langdives/Java/Locking-Reentrant/#behavior","title":"Behavior","text":"<p>A reentrant lock means that the same thread can acquire the lock multiple times without blocking itself. However, the thread must release the lock the same number of times to fully unlock it.</p> Behavior Example <pre><code>class ReentrantExample {\n    private final ReentrantLock lock = new ReentrantLock();\n\n    public void outerMethod() {\n        lock.lock();\n        try {\n            System.out.println(\"In outer method\");\n            innerMethod();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void innerMethod() {\n        lock.lock();\n        try {\n            System.out.println(\"In inner method\");\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n</code></pre> Explanation <p>In this example, <code>outerMethod</code> calls <code>innerMethod</code>, and both methods acquire the same lock. This works without issues because <code>ReentrantLock</code> allows reentrant locking.</p>"},{"location":"langdives/Java/Locking-Reentrant/#condition-variables","title":"Condition Variables","text":"<p>The <code>Condition</code> interface (associated with a <code>ReentrantLock</code>) allows a thread to wait for a condition to be met before proceeding. It provides better control than the traditional <code>wait()</code>/<code>notify()</code>.</p> Condition Variables Example <pre><code>import java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.ReentrantLock;\n\nclass ConditionExample {\n    private final ReentrantLock lock = new ReentrantLock();\n    private final Condition condition = lock.newCondition();\n    private boolean ready = false;\n\n    public void awaitCondition() throws InterruptedException {\n        lock.lock();\n        try {\n            while (!ready) {\n                condition.await();  // Wait for signal\n            }\n            System.out.println(\"Condition met, proceeding...\");\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void signalCondition() {\n        lock.lock();\n        try {\n            ready = true;\n            condition.signal();  // Signal waiting thread\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Locking-Reentrant/#performance","title":"Performance","text":"<p>ReentrantLock has more overhead than <code>synchronized</code> due to fairness policies and explicit lock management, Use <code>synchronized</code> for simple scenarios, use reentrantLock for more complex locking requirements(eg: tryLock, fairness).</p>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/","title":"Locking","text":"<p>Locking is an essential concept in multithreaded programming to prevent race conditions and ensure thread safety. When multiple threads access shared resources, locks ensure that only one thread accesses the critical section at a time.</p> <p>This article covers read-write locks.</p>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#what-is-locking","title":"What is Locking ?","text":"<p>Locking is a way to ensure that only one thread at a time executes a critical section or modifies a shared resource, Without proper locks, multiple threads may interfere with each other, leading to data inconsistency or unexpected behavior (race conditions).</p> <p>Java offers various locking mechanisms, from synchronized blocks to explicit locks like <code>ReentrantLock</code> and <code>ReentrantReadWriteLock</code>.</p>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#what-is-reentrantreadwritelock","title":"What is <code>ReentrantReadWriteLock</code>?","text":"<p>The <code>ReentrantReadWriteLock</code> is a specialized lock from Java\u2019s <code>java.util.concurrent.locks</code> package, designed to improve performance in concurrent systems by separating read and write operations. It provides more efficient locking behavior when the majority of operations are read-only, allowing multiple readers to access the shared resource simultaneously but blocking writers until all reading operations are complete.</p> <p>A <code>ReentrantReadWriteLock</code> maintains two types of locks:</p> <ul> <li>Read Lock: Multiple threads can acquire the read lock simultaneously if no thread holds the write lock.</li> <li>Write Lock: Allows only one thread to acquire the lock. All readers and other writers are blocked until the write operation completes.</li> </ul> <p>This separation helps optimize performance for read-heavy workloads.</p> Example <pre><code>import java.util.concurrent.locks.ReentrantReadWriteLock;\n\nclass SharedResource {\n    private int data = 0;\n    private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\n\n    public void write(int value) {\n        lock.writeLock().lock();  // Acquire write lock\n        try {\n            data = value;\n            System.out.println(\"Data written: \" + value);\n        } finally {\n            lock.writeLock().unlock();  // Release write lock\n        }\n    }\n\n    public int read() {\n        lock.readLock().lock();  // Acquire read lock\n        try {\n            System.out.println(\"Data read: \" + data);\n            return data;\n        } finally {\n            lock.readLock().unlock();  // Release read lock\n        }\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws InterruptedException {\n        SharedResource resource = new SharedResource();\n\n        // Writer thread\n        Thread writer = new Thread(() -&gt; resource.write(42));\n\n        // Reader threads\n        Thread reader1 = new Thread(() -&gt; resource.read());\n        Thread reader2 = new Thread(() -&gt; resource.read());\n\n        writer.start();\n        reader1.start();\n        reader2.start();\n\n        writer.join();\n        reader1.join();\n        reader2.join();\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#how-it-works","title":"How it Works ?","text":"<ul> <li>Multiple Threads can acquire the read lock simultaneously if no thread holds the write lock.</li> <li>A single thread can acquire the write lock, blocking other readers and writers.</li> <li>Write locks are exclusive, meaning only one thread can acquire it at a time.</li> <li>Read locks are shared, allowing multiple readers to read concurrently.</li> </ul>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#key-features","title":"Key Features","text":"<ul> <li> <p>Fair vs Unfair Locking: By default, <code>ReentrantReadWriteLock</code> uses unfair locking for better performance, but they may introduce performance overhead      <pre><code>ReentrantReadWriteLock lock = new ReentrantReadWriteLock(true);  // Fair lock\n</code></pre></p> </li> <li> <p>Reentrancy: A thread holding a write lock can acquire the read lock without blocking, This is useful for scenarios where a thread needs to read and modify shared data atomically.</p> </li> <li> <p>Downgrading: A thread can downgrade a write lock to a read lock without releasing the lock entirely.      <pre><code>lock.writeLock().lock();\ntry {\n    // Critical write section\n    lock.readLock().lock();  // Downgrade to read lock\n} finally {\n    lock.writeLock().unlock();  // Release write lock\n}\n</code></pre></p> </li> </ul>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#common-problems","title":"Common Problems","text":"Write Starvation <p>In scenarios with frequent readers, a writer may starve because readers keep acquiring the read lock, delaying the writer indefinitely.</p> <p>Solution</p> <p>Use a fair lock</p> <pre><code>ReentrantReadWriteLock lock = new ReentrantReadWriteLock(true);  // Enable fairness\n</code></pre> <p>Fair locks ensure that waiting writers get a chance to execute after the current readers finish.</p> DeadLock <p>If a read lock and write lock are acquired in an inconsistent order across multiple threads, it can lead to deadlock.</p> <p>Deadlock example</p> <pre><code>Thread 1: Acquire write lock -&gt; Attempt to acquire read lock (blocks)\nThread 2: Acquire read lock -&gt; Attempt to acquire write lock (blocks)\n</code></pre> <p>Solution</p> <ul> <li>Ensure consistent lock ordering across all threads.</li> <li>Avoid nested locks when using both read and write locks.</li> </ul> Performance Degradation with Too Many Write Operations <p>If there are frequent write operations, the system behaves similarly to using a normal ReentrantLock, as readers must wait for writers to release the lock.</p> <p>Solution</p> <p>Use lock-free data structures (like <code>AtomicReference</code>) or ReadWriteLock only when reads significantly outnumber writes.</p> Incorrect Use of Lock Downgrading <p>If a thread holding the write lock tries to release it before acquiring the read lock, data inconsistencies can occur.</p> <p>Correct Lock Downgrading Example</p> <pre><code>lock.writeLock().lock();\ntry {\n    // Write critical section\n    lock.readLock().lock();  // Downgrade to read lock\n} finally {\n    lock.writeLock().unlock();  // Release write lock\n}\n// Perform read operations under the read lock.\n</code></pre>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#when-to-use","title":"When to Use ?","text":"<ul> <li> <p>Read-heavy Workloads, when the majority of operations are reads and only a few writes occur.</p> </li> <li> <p>Improved Performance over <code>ReentrantLock</code>, In scenarios where multiple threads need to read data simultaneously, <code>ReentrantReadWriteLock</code> improves performance by allowing concurrent reads.</p> </li> <li> <p>When You Need to Separate Read and Write Operations, use it to prevent blocking readers unnecessarily during write operations.</p> </li> </ul>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#when-not-to-use","title":"When Not to Use ?","text":"<ul> <li> <p>Write-heavy Applications, If writes occur frequently, the write lock will block readers, negating the benefits of the read-write separation.</p> </li> <li> <p>Simple Synchronization Requirements, If your application doesn\u2019t require complex locking behavior, use <code>synchronized</code> or <code>ReentrantLock</code> instead.</p> </li> <li> <p>Lock-free Alternatives Available, consider atomic classes or concurrent data structures (e.g., <code>ConcurrentHashMap</code>) if they meet your needs.</p> </li> </ul>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Use Fair Locks Only When Necessary, Use unfair locks by default for better performance. Enable fairness only if starvation becomes an issue.</p> </li> <li> <p>Minimize the Duration of Locks, Avoid holding read or write locks longer than necessary to reduce contention.</p> </li> <li> <p>Use Lock Downgrading Cautiously, Always acquire the read lock before releasing the write lock to avoid inconsistencies.</p> </li> <li> <p>Monitor Lock Usage, Use tools like VisualVM or JConsole to monitor thread activity and detect potential contention or deadlocks.</p> </li> <li> <p>Use Lock-Free Data Structures When Possible, For simple counters or flags, use atomic classes (e.g., <code>AtomicInteger</code>) to avoid locking overhead.</p> </li> </ul>"},{"location":"langdives/Java/Locking-ReentrantReadWrite/#summary","title":"Summary","text":"<p><code>ReentrantReadWriteLock</code> is a powerful tool that allows multiple threads to read concurrently while ensuring exclusive access for writes. However, it is most effective in read-heavy scenarios. Understanding potential issues like write starvation, deadlocks, and performance degradation is essential for using this lock effectively, by following best practices like consistent lock ordering, minimizing lock duration, and monitoring lock usage, you can avoid common pitfalls and maximize the performance benefits of <code>ReentrantReadWriteLock</code>.</p>"},{"location":"langdives/Java/LockingIntrinsicReentrant/","title":"<code>synchronized</code> vs <code>ReentrantLock</code>","text":""},{"location":"langdives/Java/LockingIntrinsicReentrant/#differences","title":"Differences","text":"Feature <code>synchronized</code> <code>ReentrantLock</code> Basic Concept Uses intrinsic lock (monitor) on objects. Uses an explicit lock from <code>java.util.concurrent.locks</code>. Lock Acquisition Acquired implicitly when entering a synchronized block or method. Acquired explicitly via <code>lock()</code> method. Release of Lock Automatically released when the thread exits the synchronized block or method. Must be explicitly released via <code>unlock()</code>. Reentrancy Supports reentrancy (same thread can acquire the same lock multiple times). Supports reentrancy just like synchronized. Fairness Unfair by default (no control over thread access order). Can be fair or unfair (configurable with <code>ReentrantLock(true)</code>). Interruptibility Cannot respond to interrupts while waiting for the lock. Supports interruptible locking via <code>lockInterruptibly()</code>. Try Locking Not supported. A thread will block indefinitely if the lock is not available. Supports tryLock() to attempt locking without blocking or with timeout. Condition Variables Uses <code>wait()</code> / <code>notify()</code> / <code>notifyAll()</code> methods on the intrinsic lock. Supports multiple <code>Condition</code> objects for finer-grained wait/notify control. Timeout Support Not supported. If the lock is held by another thread, it will wait indefinitely. Supports timeout locking with <code>tryLock(long timeout, TimeUnit unit)</code>. Performance Overhead Low for simple scenarios with little contention. Higher overhead but provides greater control over locking behavior. Fair Locking Option Not supported (always unfair). Fair locking can be enabled with <code>ReentrantLock(true)</code>. Use in Non-blocking Operations Not possible. Possible with <code>tryLock()</code> (non-blocking). Flexibility and Control Limited to synchronized methods or blocks. Greater flexibility: lock multiple sections, lock only part of a method, or use multiple conditions. Suitability for Deadlock Avoidance Requires external logic to prevent deadlocks (acquire locks in the same order). Easier to prevent deadlocks using <code>tryLock()</code> and timeouts. Memory Usage No additional memory overhead. Uses the object\u2019s monitor. Requires additional memory for lock objects and lock metadata. Readability and Simplicity Easier to read and maintain (especially for small, simple use cases). More complex code with explicit lock management. Error Handling No need to manage lock release in a <code>finally</code> block. The lock is automatically released. Requires explicit unlock() in <code>finally</code> blocks to avoid deadlocks or memory leaks. Thread Starvation Prone to thread starvation in high contention scenarios. Can prevent starvation using fair lock mode. Recommended Use Case Best for simple synchronization needs where you don\u2019t need advanced control. Recommended for complex concurrency scenarios needing fine-grained locking, fairness, tryLock, or interruptibility."},{"location":"langdives/Java/LockingIntrinsicReentrant/#when-to-use","title":"When to Use ?","text":"Use <code>synchronized</code> Use <code>ReentrantLock</code> When you need simple, block-level or method-level synchronization. When you need advanced control over locking behavior (e.g., tryLock, fairness, or interruptibility). When you want automatic lock release (less error-prone). When you need multiple locks or condition variables. When performance matters in low-contention scenarios (lower overhead). When dealing with high contention and you need fair scheduling to prevent starvation. When you don't need non-blocking operations or timeouts. When you want non-blocking operations using <code>tryLock()</code> or timeout-based locking. When the code needs to be simple and easy to read. When code complexity is acceptable for greater flexibility."},{"location":"langdives/Java/LockingIntrinsicReentrant/#summary","title":"Summary","text":"<p>Both <code>synchronized</code> and <code>ReentrantLock</code> have their own strengths and use cases. Use <code>synchronized</code> for simpler, lower-level concurrency needs, and <code>ReentrantLock</code> when you need more control, fairness, or advanced features like non-blocking locking and condition variables. </p> <p>In general: - <code>synchronized</code> is easier to use and less error-prone. - <code>ReentrantLock</code> is more powerful and flexible, but with more overhead and complexity.</p>"},{"location":"langdives/Java/Maven/","title":"Maven","text":""},{"location":"langdives/Java/Maven/#what-is-maven","title":"What is Maven ?","text":"<p>Apache Maven is a build automation and project management tool primarily for Java projects. It uses XML (pom.xml) to describe the project's structure, dependencies, and build lifecycle. Maven focuses on the \u201cconvention over configuration\u201d principle, meaning it provides a standard way to structure and build projects with minimal configuration.</p>"},{"location":"langdives/Java/Maven/#how-maven-works","title":"How Maven Works ?","text":"<p>Maven operates using a build lifecycle consisting of pre-defined phases. When you execute a specific phase, all preceding phases are executed as well.</p> Maven Lifecycle Phases Phase Description <code>validate</code> Validates the project structure. <code>compile</code> Compiles the source code. <code>test</code> Runs the unit tests. <code>package</code> Packages the compiled code into a JAR or WAR. <code>verify</code> Verifies the package meets specifications. <code>install</code> Installs the JAR into the local Maven repository. <code>deploy</code> Deploys the artifact to a remote repository. <p>Maven revolves around the POM (Project Object Model), which defines:</p> <ul> <li>The project metadata (group ID, artifact ID, version).</li> <li>The dependencies required for the project.</li> <li>The build lifecycle and plugins to automate tasks like testing, packaging, and deploying.</li> </ul> <p>We will understand <code>pom.xml</code> in next section more.</p>"},{"location":"langdives/Java/Maven/#understanding-pomxml","title":"Understanding <code>pom.xml</code>","text":"<p>The POM (Project Object Model) file is the heart of a Maven project. It defines dependencies, build plugins, and project metadata.</p> <p>Basic Example of pom.xml</p> <pre><code>&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 \n                            http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n    &lt;groupId&gt;com.example&lt;/groupId&gt;\n    &lt;artifactId&gt;my-app&lt;/artifactId&gt;\n    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n    &lt;packaging&gt;jar&lt;/packaging&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;\n            &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;\n            &lt;version&gt;3.12.0&lt;/version&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;version&gt;3.8.1&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;1.8&lt;/source&gt;\n                    &lt;target&gt;1.8&lt;/target&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n&lt;/project&gt;\n</code></pre> <p>Key Components of <code>pom.xml</code></p> <ul> <li>Group ID: Represents the organization or group (e.g., <code>com.example</code>).</li> <li>Artifact ID: Unique name for the project (e.g., <code>my-app</code>).</li> <li>Version: Specifies the version (e.g., <code>1.0-SNAPSHOT</code>).</li> <li>Dependencies: Lists external libraries needed for the project.</li> <li>Build Plugins: Configures tasks such as compiling and packaging (e.g., <code>maven-compiler-plugin</code>).</li> </ul>"},{"location":"langdives/Java/Maven/#dependency-management","title":"Dependency Management","text":"<p>Maven simplifies dependency management by automatically downloading required libraries from repositories.</p> <p>Scopes of Dependencies</p> <ul> <li><code>compile</code>: Available at compile time and runtime (default scope).</li> <li><code>test</code>: Only used for testing purposes.</li> <li><code>provided</code>: Available at compile time but not packaged (e.g., Servlet API).</li> <li><code>runtime</code>: Available at runtime only.</li> </ul> <p>Example Dependency Declaration</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;\n    &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;\n    &lt;version&gt;3.12.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"langdives/Java/Maven/#maven-repositories","title":"Maven Repositories","text":"<p>Maven resolves dependencies from repositories:</p> <ul> <li>Local Repository: Located at <code>~/.m2/repository</code>, stores downloaded artifacts.</li> <li>Central Repository: Maven Central (public repository of libraries).</li> <li>Remote Repository: Custom/private repositories (e.g., Nexus, Artifactory).</li> </ul> <p>Adding a Custom Repository</p> <pre><code>&lt;repositories&gt;\n    &lt;repository&gt;\n        &lt;id&gt;my-repo&lt;/id&gt;\n        &lt;url&gt;https://my-repo-url&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n</code></pre>"},{"location":"langdives/Java/Maven/#maven-plugins","title":"Maven Plugins","text":"<p>Maven plugins extend its functionality. Plugins can handle tasks such as compiling, testing, or packaging.</p> <p>Maven Compiler Plugin</p> <p><pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n    &lt;version&gt;3.8.1&lt;/version&gt;\n    &lt;configuration&gt;\n        &lt;source&gt;1.8&lt;/source&gt;\n        &lt;target&gt;1.8&lt;/target&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre> This plugin ensures the source code is compiled with Java 8.</p>"},{"location":"langdives/Java/Maven/#maven-project-structure","title":"Maven Project Structure","text":"Maven recommended standard directory structure<pre><code>/my-project\n\u2502\n\u251c\u2500\u2500 pom.xml               # Project Object Model configuration\n\u251c\u2500\u2500 src\n\u2502   \u2514\u2500\u2500 main\n\u2502       \u2514\u2500\u2500 java          # Source code\n\u2502   \u2514\u2500\u2500 test\n\u2502       \u2514\u2500\u2500 java          # Unit tests\n\u2514\u2500\u2500 target                # Output directory (JAR, WAR)\n</code></pre> <ul> <li><code>src/main/java</code>: Contains the application source code.</li> <li><code>src/test/java</code>: Contains unit test code.</li> <li><code>target/</code>: Contains compiled artifacts (like JARs).</li> </ul> <p>Maven supports multi-module projects, allowing multiple related projects to be managed together.</p> Directory Structure<pre><code>/parent-project\n\u2502\n\u251c\u2500\u2500 pom.xml (parent)\n\u251c\u2500\u2500 module-1/\n\u2502   \u2514\u2500\u2500 pom.xml\n\u2514\u2500\u2500 module-2/\n    \u2514\u2500\u2500 pom.xml\n</code></pre> The parent pom.xml defines the modules:<pre><code>&lt;modules&gt;\n    &lt;module&gt;module-1&lt;/module&gt;\n    &lt;module&gt;module-2&lt;/module&gt;\n&lt;/modules&gt;\n</code></pre> Building all modules<pre><code>mvn install\n</code></pre>"},{"location":"langdives/Java/Maven/#maven-wrapper-mvnw","title":"Maven Wrapper (mvnw)","text":"<p>Similar to Gradle, Maven has a wrapper (<code>mvnw</code>) that ensures the project uses a specific Maven version.</p> Add Maven Wrapper<pre><code>mvn -N io.takari:maven:wrapper\n</code></pre> <ul> <li>Unix/Mac: <code>./mvnw clean install</code></li> <li>Windows: <code>mvnw.cmd clean install</code></li> </ul>"},{"location":"langdives/Java/Maven/#maven-commands","title":"Maven Commands","text":"<p>Here are some common Maven commands</p> Command Description <code>mvn compile</code> Compiles the source code. <code>mvn test</code> Runs unit tests. <code>mvn package</code> Packages the code into a JAR/WAR. <code>mvn install</code> Installs the artifact to the local repository. <code>mvn deploy</code> Deploys the artifact to a remote repository. <code>mvn clean</code> Cleans the <code>target/</code> directory. <code>mvn dependency:tree</code> Displays the project's dependency tree."},{"location":"langdives/Java/Maven/#best-practices","title":"Best Practices","text":"<ul> <li>Use Maven Wrapper for consistent builds.</li> <li>Store dependencies in a remote repository (like Nexus or Artifactory) for faster builds.</li> <li>Define dependency scopes carefully to avoid bloated artifacts.</li> <li>Use CI/CD pipelines (e.g., Jenkins, GitHub Actions) to automate builds and deployments.</li> </ul>"},{"location":"langdives/Java/Maven/#summary","title":"Summary","text":"<p>Maven is a mature, stable tool that simplifies building and managing Java applications. Its focus on conventions reduces the need for complex configurations, making it ideal for enterprise projects. While Maven may lack some of the flexibility and speed of Gradle, it is widely used in large organizations for its reliability and standardization. For projects requiring strict conventions and extensive dependency management, Maven remains a popular choice.</p>"},{"location":"langdives/Java/MavenVsGradle/","title":"Maven vs Gradle","text":""},{"location":"langdives/Java/MavenVsGradle/#comparision","title":"Comparision","text":"Aspect Maven Gradle Configuration Style Uses XML (<code>pom.xml</code>). Uses Groovy/Kotlin DSL (<code>build.gradle</code>). Performance Slower, especially for large projects (no build caching). Faster with incremental builds and caching. Flexibility Follows convention over configuration, less customizable. Highly customizable, supports custom build logic. Dependency Management Maven Central and custom repositories. Supports Maven Central, JCenter, Ivy, and custom repositories. Plugin System Pre-built Maven plugins (strict lifecycle integration). More flexible plugins with multiple custom task types. Build Output Produces JARs, WARs, and other artifacts. Produces JARs, WARs, and custom artifacts more easily. Multi-Project Support Good for enterprise projects with structured multi-module builds. Excellent for multi-module projects, especially in complex setups. Integration with CI/CD Easily integrates with Jenkins, GitHub Actions, Bamboo. Same level of integration with Jenkins, CircleCI, GitHub Actions. Use in Android Development Not suitable. Preferred build tool for Android development. Incremental Builds Not supported. Supported, resulting in faster builds. Offline Mode Uses the local Maven repository (<code>~/.m2/repository</code>). Uses a local cache (<code>~/.gradle/caches/</code>) and has offline mode. Version Control of Build Tool Maven Wrapper (mvnw) ensures consistent versions. Gradle Wrapper (gradlew) ensures consistent versions. Preferred Projects Enterprise Java applications with well-defined standards. Android apps, complex and large projects with custom build requirements."},{"location":"langdives/Java/MavenVsGradle/#when-to-use-gradle","title":"When to Use Gradle ?","text":"<ul> <li>For Android development gradle is the default and recommended build tool.</li> <li>When you need fine-grained control over the build process for Large complex projects.</li> <li>Gradle excels with multi-module projects that require custom dependencies and task chaining.</li> <li>Use when performance is critical, as it got incremental builds caching, so faster builds.</li> <li>When your project needs custom workflows and builds, tasks beyond standard lifecycles.</li> </ul>"},{"location":"langdives/Java/MavenVsGradle/#when-to-use-maven","title":"When to Use Maven ?","text":"<ul> <li>Maven works well for standard enterprise projects that adhere to established conventions.</li> <li>Maven\u2019s default conventions are great for straightforward builds for simple projects.</li> <li>Maven\u2019s dependency resolution and management is robust for large enterprise projects with heavy dependency management.</li> <li>When you need reproducible builds with a focus on consistency and stability helpful with team projects with strict versioning.</li> <li>Maven is easier to learn if you are already familiar with XML based configurations.</li> </ul>"},{"location":"langdives/Java/MavenVsGradle/#advantages-of-gradle","title":"Advantages of Gradle","text":"<ul> <li>Faster builds due to incremental builds and caching.</li> <li>Highly customizable with task-based dependencies so flexible.</li> <li>The preferred tool for Android projects.</li> <li>Runs independent tasks in parallel, reducing build times.</li> <li>Uses Groovy or Kotlin DSL for more concise configurations.</li> </ul>"},{"location":"langdives/Java/MavenVsGradle/#advantages-of-maven","title":"Advantages of Maven","text":"<ul> <li>Follows standard conventions for project structure and lifecycle, making it easy to start.</li> <li>Great for large projects that rely on multiple libraries for robust dependency management.</li> <li>Well-suited for enterprise level Java applications with multiple modules.</li> <li>Comes with many pre-built plugins for common tasks with rich plugin eco system.</li> <li>Standardized approach ensures that all builds behave similarly across environments so strong consistency.</li> </ul>"},{"location":"langdives/Java/MavenVsGradle/#which-tool-is-preferred","title":"Which Tool is Preferred?","text":"<ul> <li>For Android Development Gradle is the clear winner (it\u2019s required by Android Studio).</li> <li>For Large, Complex Builds Gradle is better due to its flexibility and performance.</li> <li>For Simple, Standard Builds Maven is preferred because it requires minimal configuration.</li> <li>For Enterprise Applications Maven is usually chosen for its standardization and ease of dependency management.</li> <li>For Projects Needing Speed Gradle is preferred because of its incremental builds and caching features.</li> </ul>"},{"location":"langdives/Java/MavenVsGradle/#where-gradle-maven-fit","title":"Where Gradle Maven Fit ?","text":"Component Role Gradle / Maven Interaction JDK (Java Development Kit) Provides tools to compile Java code into bytecode. Gradle and Maven use the JDK compiler (javac) to build code. JVM (Java Virtual Machine) Runs the compiled bytecode (.class files). Gradle/Maven can execute unit tests and applications on the JVM. JRE (Java Runtime Environment) Provides the libraries required to run Java applications. The output artifacts (e.g., JAR/WAR) produced by Gradle/Maven require the JRE to run. <ul> <li>Both Gradle and Maven use the JDK to compile code, JVM to run tests, and JRE for running packaged artifacts (like JARs).</li> <li>These tools do not replace the JDK, JVM, or JRE, instead, they automate the processes involved in building, testing, and packaging Java applications.</li> </ul>"},{"location":"langdives/Java/MavenVsGradle/#summary","title":"Summary","text":"<ul> <li> <p>Use Maven if:</p> <ul> <li>Your project is enterprise-level or follows standard Java conventions.</li> <li>You want a simpler setup with a standardized approach.</li> <li>Your team is familiar with XML-based configurations.</li> </ul> </li> <li> <p>Use Gradle if:</p> <ul> <li>You need faster builds and incremental caching.</li> <li>Your project is an Android app or involves complex custom builds.</li> <li>You want fine-grained control over the build lifecycle.</li> </ul> </li> </ul> <p>In conclusion, both Maven and Gradle are excellent tools, and the choice depends on the project requirements. For enterprise applications, Maven remains a solid choice. For Android apps, large multi-module projects, or performance-critical builds, Gradle stands out as the preferred option.</p>"},{"location":"langdives/Java/MemoryModel/","title":"Java Memory Model","text":"<p>Java uses a memory model that divides memory into different areas, primarily the heap and stack. </p>"},{"location":"langdives/Java/MemoryModel/#heap-memory","title":"Heap Memory","text":"<p>The heap is mainly used for dynamic memory allocation. Objects created using the <code>new</code> keyword are stored in the heap. Coming to it's life time objects in the heap remain in memory until they are no longer referenced and are garbage collected. This means the lifetime of an object is not tied to the scope of a method and Accessing memory in the heap is slower than in the stack due to its dynamic nature and the potential for fragmentation.</p> <p>Note</p> <ul> <li>The heap size can be adjusted using JVM options (e.g., <code>-Xms</code> for initial heap size and <code>-Xmx</code> for maximum heap size). </li> <li>Java automatically manages memory in the heap through a process called garbage collection, which frees up memory by removing objects that are no longer in use.</li> <li>Heap memory is allocated at execution time when objects are created using the <code>new</code> keyword.</li> <li>When you instantiate an object, memory for that object is dynamically allocated from the heap.   Example<pre><code>MyClass obj = new MyClass(); // Heap allocation\n</code></pre></li> </ul>"},{"location":"langdives/Java/MemoryModel/#stack-memory","title":"Stack Memory","text":"<p>The stack is mainly used for static memory allocation. It stores method call frames, which contain local variables, method parameters, and return addresses. coming to the lifetime of a variable in the stack is limited to the duration of the method call. Once the method returns, the stack frame is popped off, and the memory is reclaimed and accessing stack memory is faster than heap memory because it follows a Last In, First Out (LIFO) order, allowing for quick allocation and deallocation.</p> <p>Note</p> <ul> <li>Stack memory is generally smaller than heap memory. The stack size can also be adjusted using JVM options (e.g., <code>-Xss</code>).</li> <li>Stack memory is allocated at execution time, specifically when a method is called.</li> <li>Each time a method is invoked, a new stack frame is created. This frame contains: Local variables, Method parameters, Return address</li> </ul>"},{"location":"langdives/Java/MemoryModel/#example","title":"Example","text":"<p>Example</p> <pre><code>public class MemoryExample {\n    public static void main(String[] args) {\n        int localVar = 10; // Stack memory\n\n        MemoryExample obj = new MemoryExample(); // Heap memory\n        obj.display(localVar); // Passing parameter, stack memory\n    }\n\n    public void display(int param) { // Stack memory\n        System.out.println(param);\n        String message = \"Hello\"; // Heap memory (String object)\n    }\n}\n</code></pre>"},{"location":"langdives/Java/MemoryModel/#differences","title":"Differences","text":"Feature Heap Stack Allocation Dynamic Static Lifetime Until garbage collected Duration of method call Memory Size Larger (configurable) Smaller (configurable) Access Speed Slower Faster Data Type Objects, arrays Primitive types, references Management Garbage collection Automatically managed by JVM"},{"location":"langdives/Java/PrimitiveReferenceTypes/","title":"Primitive and Reference Types","text":""},{"location":"langdives/Java/PrimitiveReferenceTypes/#primitive-types","title":"Primitive Types","text":"<p>Java has 8 primitive data types that store simple values directly in memory.</p> Type Size Default Value Range Example <code>byte</code> 1 byte (8 bits) 0 -128 to 127 <code>byte b = 100;</code> <code>short</code> 2 bytes (16 bits) 0 -32,768 to 32,767 <code>short s = 30000;</code> <code>int</code> 4 bytes (32 bits) 0 -2^31 to (2^31)-1 <code>int i = 100000;</code> <code>long</code> 8 bytes (64 bits) 0L -2^63 to (2^63)-1 <code>long l = 100000L;</code> <code>float</code> 4 bytes (32 bits) 0.0f ~\u00b13.4E38 (7 decimal digits precision) <code>float f = 3.14f;</code> <code>double</code> 8 bytes (64 bits) 0.0 ~\u00b11.8E308 (15 decimal digits precision) <code>double d = 3.14159;</code> <code>char</code> 2 bytes (16 bits) '\\u0000' Unicode characters (0 to 65,535) <code>char c = 'A';</code> <code>boolean</code> 1 bit (virtual) false true or false <code>boolean b = true;</code>"},{"location":"langdives/Java/PrimitiveReferenceTypes/#reference-types","title":"Reference Types","text":"<p>Reference types store references (addresses) to objects in memory, unlike primitive types that store values directly.</p> <ul> <li> <p><code>String</code>:  Represents a sequence of characters.    <pre><code>String str = \"Hello, World!\";\n</code></pre></p> </li> <li> <p>Arrays:  Collections of elements of the same type.    <pre><code>int[] numbers = {1, 2, 3};\n</code></pre></p> </li> <li> <p>Classes and Objects:  Custom data types representing real-world entities.    <pre><code>class Person {\n    String name;\n}\nPerson p = new Person();\n</code></pre></p> </li> <li> <p>Interfaces:  Contracts that classes can implement.    <pre><code>interface Animal {\n    void sound();\n}\n</code></pre></p> </li> <li> <p>Enums:  Special classes that define a set of constants.    <pre><code>enum Day {\n    MONDAY, TUESDAY, WEDNESDAY;\n}\n</code></pre></p> </li> <li> <p>Wrapper Classes:  Used to convert primitive types into objects (auto-boxing/unboxing).</p> </li> </ul> Primitive Wrapper Class <code>byte</code> <code>Byte</code> <code>short</code> <code>Short</code> <code>int</code> <code>Integer</code> <code>long</code> <code>Long</code> <code>float</code> <code>Float</code> <code>double</code> <code>Double</code> <code>char</code> <code>Character</code> <code>boolean</code> <code>Boolean</code>"},{"location":"langdives/Java/PrimitiveReferenceTypes/#differences","title":"Differences","text":"Aspect Primitive Types Reference Types Storage Store actual values. Store references to objects in memory. Memory Allocation Stored in stack memory. Stored in heap memory. Default Values Zero/false equivalents. <code>null</code> for uninitialized references. Examples <code>int</code>, <code>char</code>, <code>boolean</code>. <code>String</code>, Arrays, Classes, Interfaces, etc."},{"location":"langdives/Java/ReferenceTypesInDepth/","title":"Reference Types In Depth.","text":"<p>Let's deep dive to understand How memory management, object references, and behaviors work in Java in this article, with a focus on String handling and other reference types like arrays, classes, and wrapper objects.</p>"},{"location":"langdives/Java/ReferenceTypesInDepth/#intro","title":"Intro","text":"<p>Primitive types store values directly in stack memory Where as Reference types store references (addresses) to objects located in heap memory, When you assign a reference type (e.g., <code>String</code> or an array), only the reference (address) is copied, not the actual data. This means multiple references can point to the same object.</p>"},{"location":"langdives/Java/ReferenceTypesInDepth/#string","title":"String","text":"<p>The <code>String</code> class in Java is a special reference type with some unique behaviors. Strings are immutable once a <code>String</code> object is created, it cannot be changed. Any modification on a <code>String</code> results in the creation of a new object in memory.</p>"},{"location":"langdives/Java/ReferenceTypesInDepth/#string-pool-interned-strings","title":"String Pool (Interned Strings)","text":"<p>A special memory area inside the heap used to store string literals. If a string literal like <code>\"Hello\"</code> is created, Java first checks the string pool to see if it already exists. If it does, it returns the reference from the pool. If not, the string is added to the pool.</p> Example <pre><code>String s1 = \"Hello\";  // Stored in the String Pool\nString s2 = \"Hello\";  // s2 points to the same object as s1\n\nSystem.out.println(s1 == s2);  // true (same reference)\n</code></pre>"},{"location":"langdives/Java/ReferenceTypesInDepth/#heap-memory","title":"Heap Memory","text":"<p>When you use the <code>new</code> keyword, a new <code>String</code> object is always created in the heap memory. Even if the same string already exists in the string pool, the <code>new</code> keyword forces the creation of a separate instance in the heap.</p> Example <p><pre><code>String s1 = new String(\"Hello\"); // creates a new object outside the pool in the heap.\n\nString s2 = \"Hello\"; // Stored in the String Pool\n\nSystem.out.println(s1 == s2);  // false (different references)\n</code></pre> When you use <code>new String()</code>, Java forces the creation of a new object in heap even if the same string exists in the pool.</p>"},{"location":"langdives/Java/ReferenceTypesInDepth/#arrays","title":"Arrays","text":"<p>Arrays are reference types, meaning the array variable stores a reference to the memory location where the array data is stored.</p> Example <pre><code>int[] arr1 = {1, 2, 3};\nint[] arr2 = arr1;  // arr2 now references the same array as arr1\n\narr2[0] = 10;  // Modifies the original array\n\nSystem.out.println(arr1[0]);  // Output: 10 (both arr1 and arr2 reference the same array)\n</code></pre> <p>How Array References Work:</p> <ul> <li><code>arr1</code> and <code>arr2</code> point to the same memory location in the heap.</li> <li>If you change the array via <code>arr2</code>, the change will reflect in <code>arr1</code> because both refer to the same object.</li> </ul>"},{"location":"langdives/Java/ReferenceTypesInDepth/#classes-and-objects","title":"Classes and Objects","text":"<p>When you create an object using <code>new</code>, the reference variable points to the object in heap memory.</p> Example <pre><code>class Person {\n    String name;\n}\n\nPerson p1 = new Person();\np1.name = \"Alice\";\n\nPerson p2 = p1;  // p2 points to the same object as p1\np2.name = \"Bob\";\n\nSystem.out.println(p1.name);  // Output: Bob (both references point to the same object)\n</code></pre> <p>How References Work with Objects:</p> <ul> <li><code>p1</code> and <code>p2</code> point to the same Person object. Changing the object via <code>p2</code> affects <code>p1</code>.</li> <li>This is how shallow copies work, only the reference is copied, not the object itself.</li> </ul>"},{"location":"langdives/Java/ReferenceTypesInDepth/#wrapper-classes","title":"Wrapper Classes","text":"<p>Wrapper classes (<code>Integer</code>, <code>Double</code>, <code>Boolean</code>, etc.) wrap primitive types into objects. These are reference types, and Java performs autoboxing/unboxing to convert between primitive types and wrapper objects.</p> Example <pre><code>Integer num1 = 100;\nInteger num2 = 100;\n\nSystem.out.println(num1 == num2);  // true (for values within -128 to 127)\n\nInteger num3 = 200;\nInteger num4 = 200;\n\nSystem.out.println(num3 == num4);  // false (new objects for values beyond 127)\n</code></pre> <p>Wrapper Caching</p> <ul> <li>Java caches <code>Integer</code> objects in the range -128 to 127 for performance.</li> <li>Beyond this range, new objects are created.</li> </ul>"},{"location":"langdives/Java/ReferenceTypesInDepth/#reference-and-deep-copy","title":"Reference and Deep Copy","text":"<p>Shallow Copy: Copies only the reference, so both variables refer to the same object.</p> Example <pre><code>int[] original = {1, 2, 3};\nint[] shallowCopy = original;  // Points to the same array\n\nshallowCopy[0] = 100;\nSystem.out.println(original[0]);  // Output: 100\n</code></pre> <p>Deep Copy: Creates a new object with the same data.</p> Example <pre><code>int[] original = {1, 2, 3};\nint[] deepCopy = original.clone();  // Creates a new array\n\ndeepCopy[0] = 100;\nSystem.out.println(original[0]);  // Output: 1\n</code></pre>"},{"location":"langdives/Java/ReferenceTypesInDepth/#nullnullpointerexception","title":"Null/<code>NullPointerException</code>","text":"<p>When a reference is not initialized, it holds the value <code>null</code>. Accessing a field or method on a <code>null</code> reference throws a <code>NullPointerException</code>.</p> Example <pre><code>Person p = null;\nSystem.out.println(p.name);  // Throws NullPointerException\n</code></pre>"},{"location":"langdives/Java/ReferenceTypesInDepth/#garbage-collection","title":"Garbage Collection","text":"<p>Java uses Garbage Collection to manage memory. When no references point to an object, it becomes eligible for garbage collection.</p> Example <pre><code>Person p1 = new Person();  // Object created\np1 = null;  // Now eligible for garbage collection\n</code></pre> <p>We will learn about garbage collection more in depth in another article.</p>"},{"location":"langdives/Java/ReferenceTypesInDepth/#summary","title":"Summary","text":"<p>Strings are immutable and stored in the String Pool when created with literals, while using new String() creates a separate object. Arrays are reference types, allowing multiple variables to point to the same array object. For classes, objects are referenced in memory, meaning multiple references can point to the same object. Wrapper classes utilize caching for certain ranges, such as Integer values between -128 and 127. Objects become eligible for garbage collection when no active references point to them.</p>"},{"location":"langdives/Java/ReferenceTypesInDepth/#string-pool-in-depth","title":"String Pool In Depth","text":"<p>The String Pool (also called the intern pool) in Java is implemented using a Hash Table-like data structure internally. Let\u2019s explore the design and behavior behind this structure:</p>"},{"location":"langdives/Java/ReferenceTypesInDepth/#internals","title":"Internals","text":"<ul> <li> <p>Hash Table: The String Pool uses a Hash Map-like structure internally, where the key is the string literal, and the value is a reference to the interned string in the pool. This ensures fast lookups and deduplication of identical strings because hash-based structures allow O(1) average-time complexity for lookup operations.</p> </li> <li> <p>Behavior of String Pool: If a new string literal is created, the pool checks if the string already exists (by computing its hash), If the string exists, it returns the existing reference. If not, the string is added to the pool.</p> </li> <li> <p>Rehashing and Thread Safety: The interned pool is part of the JVM's heap and managed by the Java String class. Since Java 7, the pool is stored in the heap instead of the PermGen space to allow better memory management. The pool structure is thread-safe, meaning multiple threads can safely use the pool.</p> </li> </ul> Simplified conceptual pseudocode Example <p>How the pool works internally<pre><code>class StringPool {\n    private static Map&lt;String, String&gt; pool = new HashMap&lt;&gt;();\n\n    public static String intern(String str) {\n        if (pool.containsKey(str)) {\n            return pool.get(str);  // Return existing reference\n        } else {\n            pool.put(str, str);    // Add to the pool\n            return str;\n        }\n    }\n}\n</code></pre> When calling <code>String.intern()</code>, Java interns the string, meaning it adds the string to the pool if it's not already present.</p> String Pool Usage Example <pre><code>public class Main {\n    public static void main(String[] args) {\n        String s1 = new String(\"Hello\");\n        String s2 = s1.intern();  // Adds \"Hello\" to the pool, if not already present\n\n        String s3 = \"Hello\";  // Uses the interned string from the pool\n\n        System.out.println(s2 == s3);  // true (same reference from the pool)\n    }\n}\n</code></pre>"},{"location":"langdives/Java/ReferenceTypesInDepth/#why-use-hash-table","title":"Why Use Hash Table ?","text":"<ul> <li>A hash table allows constant time complexity (O(1)) for faster lookups.</li> <li>Strings are immutable, so duplicate strings are avoided, improving memory usage so efficient meemory management.</li> <li>The JVM ensures that the pool is safe for concurrent access, so multiple threads can use the intern pool efficiently.</li> </ul> <p>Key Takeaways</p> <ul> <li>Since Java 7, the string pool has been moved to the heap, so it grows dynamically with the application\u2019s memory needs.</li> <li>Before Java 7, the pool was in PermGen space, which had a fixed size and could lead to <code>OutOfMemoryError</code> if too many strings were interned.</li> <li>Interning Costs, Calling <code>intern()</code> on every string can increase the overhead slightly (because of the hash lookup). It\u2019s only beneficial for reducing memory usage when you expect many repeated strings.</li> </ul>"},{"location":"langdives/Java/ReferenceTypesInDepth/#summary_1","title":"Summary","text":"<p>The String Pool is implemented using a Hash Table-like data structure, This allows for efficient string reuse through fast lookups and ensures no duplicate literals are created. Strings added via literals or <code>intern()</code> are stored in the pool, with existing references returned on subsequent requests.</p>"},{"location":"langdives/Java/StreamsLambdas/","title":"Streams and Lambdas","text":""},{"location":"langdives/Java/StreamsLambdas/#lambda-expressions","title":"Lambda Expressions","text":"<p>Enables functional programming by treating functions as first-class citizens.</p> <ul> <li>Syntax: <code>(parameters) -&gt; expression</code> or <code>(parameters) -&gt; { statements }</code></li> </ul> Lamba Example <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\nnames.forEach(name -&gt; System.out.println(name));\n</code></pre>"},{"location":"langdives/Java/StreamsLambdas/#functional-interfaces","title":"Functional Interfaces","text":"<p>A functional interface is an interface with only one abstract method. This is important because lambda expressions can be used to provide the implementation for these interfaces. </p> Functional Interface Example Define functional interface<pre><code>@FunctionalInterface  // Optional but ensures the interface has only one abstract method.\ninterface MyFunction {\n    int apply(int a, int b);  // Single abstract method\n}\n</code></pre> <p>Now, when you want to use this interface, you don\u2019t need to create a class and provide an implementation like before. Instead, you can use a lambda expression to quickly provide the logic.</p> Using Lambda with MyFunction<pre><code>MyFunction addition = (a, b) -&gt; a + b;  // Lambda expression for addition\nSystem.out.println(addition.apply(5, 3));  // Output: 8\n</code></pre> Explanation <ul> <li><code>(a, b) -&gt; a + b</code> is the lambda expression.</li> <li>It directly implements the <code>apply(int a, int b)</code> method of the <code>MyFunction</code> interface.</li> </ul>"},{"location":"langdives/Java/StreamsLambdas/#method-references","title":"Method References","text":"<p>A method reference is a shorthand way of writing a lambda when a method already exists that matches the lambda\u2019s purpose. This makes the code more concise and readable.</p> Example with <code>forEach</code> and Method Reference <p>Consider the following list of names: <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\n</code></pre></p> <p>You want to print all names using <code>forEach()</code>. You could do it with a lambda like this: <pre><code>names.forEach(name -&gt; System.out.println(name));  // Lambda expression\n</code></pre></p> <p>Now, Java provides a shorthand: Method Reference. Since <code>System.out.println()</code> already matches the structure <code>(String) -&gt; void</code>, you can write: <pre><code>names.forEach(System.out::println);  // Method reference\n</code></pre></p> Explanation <ul> <li><code>System.out::println</code> is a method reference to the <code>println()</code> method of <code>System.out</code>.</li> <li>It behaves just like the lambda <code>name -&gt; System.out.println(name)</code> but is cleaner.</li> </ul> <p>Use method references when:</p> <ul> <li>A lambda calls an existing method directly without modifying the input.</li> <li>It improves readability of the code.</li> </ul> More Examples <pre><code>// 1. Static method reference\nFunction&lt;String, Integer&gt; parse = Integer::parseInt;\nSystem.out.println(parse.apply(\"123\"));  // Output: 123\n\n// 2. Instance method reference on an arbitrary object\nList&lt;String&gt; words = Arrays.asList(\"one\", \"two\", \"three\");\nwords.sort(String::compareToIgnoreCase);  // Sorts case-insensitively\n</code></pre>"},{"location":"langdives/Java/StreamsLambdas/#streams-api","title":"Streams API","text":"<p>Introduced in Java 8 to process collections in a declarative way.</p> <p>Core Stream Operations</p>"},{"location":"langdives/Java/StreamsLambdas/#creation","title":"Creation","text":"<pre><code>Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3, 4);\nList&lt;String&gt; list = Arrays.asList(\"A\", \"B\", \"C\");\nStream&lt;String&gt; streamFromList = list.stream();\n</code></pre>"},{"location":"langdives/Java/StreamsLambdas/#intermediate-operations-return-new-streams-lazy-evaluation","title":"Intermediate Operations (return new streams, lazy evaluation)","text":"filter()<pre><code>// Filters elements based on a predicate.\nList&lt;Integer&gt; evenNumbers = stream.filter(n -&gt; n % 2 == 0).toList();\n</code></pre> map()<pre><code>// Transforms elements.\nList&lt;Integer&gt; lengths = list.stream().map(String::length).toList();\n</code></pre> sorted()<pre><code>// Sorts elements.\nList&lt;Integer&gt; sortedList = stream.sorted().toList();\n</code></pre>"},{"location":"langdives/Java/StreamsLambdas/#terminal-operations-trigger-computation","title":"Terminal Operations (trigger computation)","text":"forEach()<pre><code>// Iterates through elements.\nlist.stream().forEach(System.out::println);\n</code></pre> collect()<pre><code>// Collects elements into a collection.\nList&lt;String&gt; newList = list.stream().filter(s -&gt; s.startsWith(\"A\")).collect(Collectors.toList());\n</code></pre> reduce()<pre><code>// Reduces the elements to a single result.\nint sum = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);\n</code></pre>"},{"location":"langdives/Java/StreamsLambdas/#parallel-streams","title":"Parallel Streams","text":"<pre><code>// Used to process elements in parallel for better performance.\nlist.parallelStream().forEach(System.out::println);\n</code></pre>"},{"location":"langdives/Java/StreamsLambdas/#examples-streamslambdas","title":"Examples Streams/Lambdas","text":"Find the sum of even numbers <pre><code>int sumOfEvens = Stream.of(1, 2, 3, 4, 5, 6)\n                      .filter(n -&gt; n % 2 == 0)\n                      .reduce(0, Integer::sum);\nSystem.out.println(sumOfEvens);  // Output: 12\n</code></pre> Convert List of Strings to Uppercase <pre><code>List&lt;String&gt; upperCaseNames = list.stream()\n                                  .map(String::toUpperCase)\n                                  .collect(Collectors.toList());\n</code></pre> Group elements by length <pre><code>Map&lt;Integer, List&lt;String&gt;&gt; groupedByLength = list.stream()\n                                                .collect(Collectors.groupingBy(String::length));\n</code></pre>"},{"location":"langdives/Java/StreamsLambdas/#best-practices","title":"Best Practices","text":"<ul> <li>Prefer Streams over loops for readability.</li> <li>Use parallel streams with caution (only when operations are stateless).</li> <li>Avoid side effects in Intermediate Operations (e.g., printing inside <code>map()</code>).</li> </ul>"},{"location":"langdives/Java/ThreadPoolTuning/","title":"Thread Pool Configuration Tuning","text":"<p>Thread pool configuration is critical for optimizing the performance of your applications. Poorly configured thread pools can lead to problems such as CPU starvation, thread contention, memory exhaustion, or poor resource utilization. In this Article, we\u2019ll dive deep into CPU-bound vs I/O-bound tasks, explore how to determine optimal thread pool sizes, and discuss key considerations such as queue types and rejection policies.</p>"},{"location":"langdives/Java/ThreadPoolTuning/#cpu-vs-io-bound-tasks","title":"CPU vs I/O Bound Tasks","text":"<p>When configuring thread pools, it is essential to classify your tasks as CPU-bound or I/O-bound, as this distinction guides the number of threads your pool should maintain.</p>"},{"location":"langdives/Java/ThreadPoolTuning/#cpu-bound-tasks","title":"CPU-Bound Tasks","text":"<p>Tasks that perform intensive computations (e.g., mathematical calculations, data processing, encoding), and here limiting factor is the CPU core availability. So its better to avoid context switching overhead by keeping the number of threads close to the available CPU cores.</p> Optimal Thread Pool Size for CPU-Bound Tasks<pre><code>int coreCount = Runtime.getRuntime().availableProcessors();\nExecutorService cpuBoundPool = Executors.newFixedThreadPool(coreCount);\n</code></pre> <p>Note</p> <p>If more threads than CPU cores are running, threads will compete for CPU cycles, causing context switching, which adds overhead. <pre><code>Optimal Threads = Number of Cores\n</code></pre></p> When to use ? <ul> <li>Data crunching (e.g., scientific calculations).</li> <li>Image or video processing.</li> <li>Encryption/decryption tasks.</li> </ul>"},{"location":"langdives/Java/ThreadPoolTuning/#io-bound-tasks","title":"I/O-Bound Tasks","text":"<p>Tasks that spend most of the time waiting for I/O operations (e.g., network, database, file I/O). and here the limiting factor is the time spent waiting on I/O. So it's better to use more threads than the number of cores to ensure that idle CPU cycles are used efficiently while waiting for I/O.</p> Optimal Thread Pool Size for I/O-Bound Tasks<pre><code>int coreCount = Runtime.getRuntime().availableProcessors();\nint optimalThreads = coreCount * 2 + 1;\nExecutorService ioBoundPool = Executors.newFixedThreadPool(optimalThreads);\n</code></pre> <p>Note</p> <p>Since the tasks spend significant time waiting for I/O, more threads can be created to make sure the CPU is not idle while other threads wait for input/output operations. <pre><code>Optimal Threads = Number of Cores * (1 + Wait Time / Compute Time)\n</code></pre></p> When to use ? <ul> <li>Web servers handling multiple HTTP requests.</li> <li>Database query processing.</li> <li>File upload/download tasks.</li> </ul>"},{"location":"langdives/Java/ThreadPoolTuning/#queues-for-threadpoolexecutor","title":"Queues for ThreadPoolExecutor","text":"<p>Choosing the right work queue is crucial for memory management and task scheduling. The queue holds tasks waiting to be executed when all threads are busy.</p>"},{"location":"langdives/Java/ThreadPoolTuning/#unbounded-queue","title":"Unbounded Queue","text":"<p>A queue with no size limit, but if too many tasks are submitted, it can lead to memory exhaustion (out-of-memory errors).</p> LinkedBlockingQueue<pre><code>BlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;();\n</code></pre> When to use ? <p>Suitable only if you expect tasks to complete quickly and the queue will not grow indefinitely.</p>"},{"location":"langdives/Java/ThreadPoolTuning/#bounded-queue","title":"Bounded Queue","text":"<p>A queue with a fixed size limit, it prevents unbounded memory usage, and If the queue is full, tasks will be rejected or handled based on a rejection policy.</p> ArrayBlockingQueue<pre><code>BlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;&gt;(10);\n</code></pre> When to use ? <p>Ideal for controlled environments where you want to cap the number of waiting tasks.</p>"},{"location":"langdives/Java/ThreadPoolTuning/#thread-pool-size-tuning","title":"Thread Pool Size Tuning","text":"For CPU-Bound Tasks<pre><code>Optimal Threads = Number of Cores\n</code></pre> For I/O-Bound Tasks<pre><code>Optimal Threads = Number of Cores * (1 + Wait Time / Compute Time)\n</code></pre> Example <p>If a thread spends 70% of the time waiting on I/O, and only 30% performing work:  <pre><code>Optimal Threads = 4 * (1 + 0.7 / 0.3) = 12\n</code></pre></p>"},{"location":"langdives/Java/ThreadPoolTuning/#rejection-policies","title":"Rejection Policies","text":"<p>When the task queue is full and the pool is at its maximum size, the <code>ThreadPoolExecutor</code> must decide what to do with new tasks. You can configure rejection policies to handle these situations.</p>"},{"location":"langdives/Java/ThreadPoolTuning/#abortpolicy-default","title":"AbortPolicy (Default)","text":"<ul> <li>Throws a <code>RejectedExecutionException</code>.</li> <li>Use when you want to fail fast upon task overload.    <pre><code>new ThreadPoolExecutor.AbortPolicy();\n</code></pre></li> </ul>"},{"location":"langdives/Java/ThreadPoolTuning/#callerrunspolicy","title":"CallerRunsPolicy","text":"<ul> <li>Executes the task in the calling thread (the thread that submitted the task).</li> <li>Prevents task loss but slows down the caller.    <pre><code>new ThreadPoolExecutor.CallerRunsPolicy();\n</code></pre></li> </ul>"},{"location":"langdives/Java/ThreadPoolTuning/#discardpolicy","title":"DiscardPolicy","text":"<ul> <li>Silently discards the rejected task.</li> <li>Use when tasks are non-critical.    <pre><code>new ThreadPoolExecutor.DiscardPolicy();\n</code></pre></li> </ul>"},{"location":"langdives/Java/ThreadPoolTuning/#discardoldestpolicy","title":"DiscardOldestPolicy","text":"<ul> <li>Discards the oldest unhandled task in the queue to make room for the new task.</li> <li>Use when newer tasks are more critical.    <pre><code>new ThreadPoolExecutor.DiscardOldestPolicy();\n</code></pre></li> </ul>"},{"location":"langdives/Java/ThreadPoolTuning/#monitoring-thread-pools","title":"Monitoring Thread Pools","text":"<p>Monitoring thread pools ensures that your configuration is correct and performing well. You can monitor the following metrics:</p> <p>Key Metrics to Monitor</p> <ul> <li>Active Threads: Check how many threads are actively working.</li> <li>Queue Size: Monitor how many tasks are waiting in the queue.</li> <li>Rejected Tasks: Track rejected tasks to see if the pool is overwhelmed.</li> <li>Average Task Time: Measure how long tasks take to execute.</li> </ul> Example: Monitoring Active Threads <pre><code>ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 30, TimeUnit.SECONDS,\n      new ArrayBlockingQueue&lt;&gt;(2));\n\nSystem.out.println(\"Active Threads: \" + executor.getActiveCount());\nSystem.out.println(\"Task Count: \" + executor.getTaskCount());\nSystem.out.println(\"Completed Tasks: \" + executor.getCompletedTaskCount());\n</code></pre>"},{"location":"langdives/Java/ThreadPoolTuning/#dynamic-thread-pool-adjustment","title":"Dynamic Thread Pool Adjustment","text":"<p>Sometimes, you may need to adjust the pool size at runtime to respond to changing workloads.</p> Example: Adjusting Thread Pool Size Dynamically <pre><code>ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 30, TimeUnit.SECONDS,\n      new ArrayBlockingQueue&lt;&gt;(10));\n\n// Adjust core and max pool size dynamically\nexecutor.setCorePoolSize(3);\nexecutor.setMaximumPoolSize(6);\n</code></pre>"},{"location":"langdives/Java/ThreadPoolTuning/#best-practices","title":"Best Practices","text":"<ul> <li>For CPU-bound tasks, set the size close to the number of CPU cores. <pre><code>int poolSize = Runtime.getRuntime().availableProcessors();\nExecutorService executor = Executors.newFixedThreadPool(poolSize);\n</code></pre></li> <li> <p>For I/O-bound tasks, use more threads than the number of cores.</p> </li> <li> <p>Use bounded queues to prevent memory issues.</p> </li> <li> <p>Monitor and tune Continuously monitor thread pools and adjust configuration as needed.</p> </li> <li> <p>Gracefully shutdown thread pools to prevent resource leaks <pre><code>executor.shutdown();\ntry {\n      if (!executor.awaitTermination(60, TimeUnit.SECONDS)) {\n         executor.shutdownNow();\n      }\n} catch (InterruptedException e) {\n      executor.shutdownNow();\n}\n</code></pre></p> </li> <li> <p>Use <code>CallerRunsPolicy</code> for tasks that must be executed but are non-critical (to prevent task loss).</p> </li> </ul>"},{"location":"langdives/Java/ThreadPools/","title":"Thread Pools.","text":""},{"location":"langdives/Java/ThreadPools/#what-is-a-thread-pool","title":"What is a Thread Pool ?","text":"<p>A thread pool is a collection of worker threads that are created at the start and reused to perform multiple tasks. When tasks are submitted to the pool, a free thread picks up the task and executes it. If no threads are free, the tasks wait in a queue until one becomes available.</p>"},{"location":"langdives/Java/ThreadPools/#advantages-of-thread-pooling","title":"Advantages of Thread Pooling","text":"<ul> <li>Reduces the overhead of creating and destroying threads improving performence.</li> <li>Prevents overloading the system with too many threads with better resource management.</li> <li>Handles the submission of multiple concurrent tasks efficiently.</li> <li>Provides better scalability for server applications.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#creating-thread-pools","title":"Creating Thread Pools","text":""},{"location":"langdives/Java/ThreadPools/#ways-to-create","title":"Ways to Create","text":"<ul> <li> <p>The <code>Executors</code> class provides convenient factory methods to create thread pools:</p> <ul> <li><code>newFixedThreadPool()</code></li> <li><code>newCachedThreadPool()</code></li> <li><code>newSingleThreadExecutor()</code></li> <li><code>newScheduledThreadPool()</code></li> </ul> </li> <li> <p>For greater control, you can instantiate <code>ThreadPoolExecutor</code> directly.</p> </li> </ul>"},{"location":"langdives/Java/ThreadPools/#fixed-thread-pool","title":"Fixed Thread Pool","text":"<p>Creates a pool with a fixed number of threads. When all threads are busy, tasks are placed in a queue and executed as soon as a thread becomes available.</p> <code>newFixedThreadPool</code> <pre><code>import java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class FixedThreadPoolExample {\n    public static void main(String[] args) {\n        ExecutorService executor = Executors.newFixedThreadPool(3);\n\n        for (int i = 1; i &lt;= 6; i++) {\n            int taskId = i;\n            executor.execute(() -&gt; {\n                System.out.println(\"Task \" + taskId + \" executed by \" + Thread.currentThread().getName());\n            });\n        }\n\n        executor.shutdown();\n    }\n}\n</code></pre> Advantages <ul> <li>Limits the number of concurrent threads.</li> <li>Ideal when the number of tasks is known in advance.</li> <li>Helps avoid resource exhaustion by limiting threads.</li> </ul> When to Use ? <ul> <li>CPU-bound tasks where the thread count is close to the number of available processors.</li> <li>Server applications that need to serve a fixed number of requests at any given time.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#cached-thread-pool","title":"Cached Thread Pool","text":"<p>A dynamic thread pool where threads are created as needed. If threads are idle for 60 seconds, they are terminated. If a thread is available, it will be reused for a new task.</p> <code>newCachedThreadPool</code> <pre><code>import java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class CachedThreadPoolExample {\n    public static void main(String[] args) {\n        ExecutorService executor = Executors.newCachedThreadPool();\n\n        for (int i = 1; i &lt;= 5; i++) {\n            int taskId = i;\n            executor.execute(() -&gt; {\n                System.out.println(\"Task \" + taskId + \" executed by \" + Thread.currentThread().getName());\n            });\n        }\n\n        executor.shutdown();\n    }\n}\n</code></pre> Advantages <ul> <li>Highly scalable, creates threads as needed.</li> <li>Best for short-lived, lightweight tasks.</li> </ul> When to Use ? <ul> <li>I/O-bound tasks that spend most of the time waiting (e.g., network requests).</li> <li>Scenarios where the number of tasks fluctuates frequently.</li> </ul> Drawbacks <ul> <li>Can potentially overwhelm the system with too many threads if tasks arrive rapidly.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#single-thread-executor","title":"Single Thread Executor","text":"<p>A single-threaded executor that ensures tasks are executed sequentially in the order they are submitted. If the thread dies due to an exception, a new thread is created to replace it.</p> <code>newSingleThreadExecutor</code> <pre><code>import java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class SingleThreadExecutorExample {\n    public static void main(String[] args) {\n        ExecutorService executor = Executors.newSingleThreadExecutor();\n\n        for (int i = 1; i &lt;= 3; i++) {\n            int taskId = i;\n            executor.execute(() -&gt; {\n                System.out.println(\"Task \" + taskId + \" executed by \" + Thread.currentThread().getName());\n            });\n        }\n\n        executor.shutdown();\n    }\n}\n</code></pre> Advantages <ul> <li>Guarantees sequential execution of tasks.</li> <li>Thread safety No need for additional synchronization between tasks.</li> </ul> When to Use ? <ul> <li>Useful when tasks must be executed in a strict sequence (e.g., writing logs).</li> <li>Scenarios that require single-threaded logic (e.g., managing a shared resource).</li> </ul>"},{"location":"langdives/Java/ThreadPools/#scheduled-thread-pool","title":"Scheduled Thread Pool","text":"<p>A scheduled thread pool allows you to schedule tasks to run after a delay or periodically at a fixed rate.</p> <code>newScheduledThreadPool</code> <pre><code>import java.util.concurrent.Executors;\nimport java.util.concurrent.ScheduledExecutorService;\nimport java.util.concurrent.TimeUnit;\n\npublic class ScheduledThreadPoolExample {\n    public static void main(String[] args) {\n        ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(2);\n\n        Runnable task = () -&gt; System.out.println(\"Task executed by \" + Thread.currentThread().getName());\n\n        // Schedule task to run after 3 seconds\n        scheduler.schedule(task, 3, TimeUnit.SECONDS);\n\n        // Schedule task to run repeatedly every 2 seconds\n        scheduler.scheduleAtFixedRate(task, 1, 2, TimeUnit.SECONDS);\n\n        // Allow the tasks to complete after 10 seconds\n        scheduler.schedule(() -&gt; scheduler.shutdown(), 10, TimeUnit.SECONDS);\n    }\n}\n</code></pre> Advantages <ul> <li>Delayed and periodic execution of tasks.</li> <li>Ideal for timing-sensitive operations.</li> </ul> When to Use ? <ul> <li>Polling services or periodic background tasks (e.g., refreshing a cache).</li> <li>Scheduled events, like sending notifications at intervals.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#threadpoolexecutor","title":"ThreadPoolExecutor","text":"<p><code>ThreadPoolExecutor</code> is the core implementation of thread pools in Java. Using it allows you to fine-tune the thread pool\u2019s behavior with more control over the number of threads, queue type, and rejection policy.</p> Parameters of ThreadPoolExecutor<pre><code>ThreadPoolExecutor executor = new ThreadPoolExecutor(\n        corePoolSize,      // Minimum number of threads\n        maximumPoolSize,   // Maximum number of threads\n        keepAliveTime,     // Idle time before a thread is terminated\n        timeUnit,          // Time unit for keepAliveTime\n        workQueue,         // Queue to hold waiting tasks\n        threadFactory,     // Factory to create new threads\n        handler            // Rejection policy when the queue is full\n);\n</code></pre> Custom Thread Pool <pre><code>import java.util.concurrent.*;\n\npublic class CustomThreadPoolExecutorExample {\n    public static void main(String[] args) {\n        ThreadPoolExecutor executor = new ThreadPoolExecutor(\n                2, 4, 30, TimeUnit.SECONDS,\n                new LinkedBlockingQueue&lt;&gt;(2),   // Task queue with capacity 2\n                Executors.defaultThreadFactory(),\n                new ThreadPoolExecutor.CallerRunsPolicy() // Rejection policy\n        );\n\n        // Submit 6 tasks to the pool\n        for (int i = 1; i &lt;= 6; i++) {\n            int taskId = i;\n            executor.execute(() -&gt; {\n                System.out.println(\"Task \" + taskId + \" executed by \" + Thread.currentThread().getName());\n            });\n        }\n\n        executor.shutdown();\n    }\n}\n</code></pre> Advantages <ul> <li>Fine-tuned control over thread management.</li> <li>Allows using custom queues and rejection policies.</li> </ul> When to Use ? <ul> <li>Applications with complex task management needs.</li> <li>Systems where you need to monitor and control thread behavior closely.</li> </ul> <p>Common Rejection Policies in <code>ThreadPoolExecutor</code></p> <ul> <li>AbortPolicy: Throws <code>RejectedExecutionException</code> when a task is rejected.</li> <li>CallerRunsPolicy: Executes the rejected task in the caller's thread.</li> <li>DiscardPolicy: Silently discards the rejected task.</li> <li>DiscardOldestPolicy: Discards the oldest unhandled task.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#comparison","title":"Comparison","text":"Thread Pool Type Concurrency Parallelism Task Type When to Use Fixed Thread Pool Yes Yes Long-running tasks Limited number of known tasks. Cached Thread Pool Yes Yes Short-lived tasks Dynamic workloads with many I/O tasks. Single Thread Executor No No Sequential tasks Strictly ordered execution. Scheduled Thread Pool Yes Yes Timed or periodic tasks Periodic background tasks. Custom ThreadPoolExecutor Yes Yes Mixed Advanced control and tuning."},{"location":"langdives/Java/ThreadPools/#interface-concepts","title":"Interface Concepts","text":""},{"location":"langdives/Java/ThreadPools/#runnable-interface","title":"Runnable Interface","text":"<p>The <code>Runnable</code> interface represents a task that can run asynchronously in a thread but does not return any result or throw a checked exception.</p> Structure<pre><code>@FunctionalInterface\npublic interface Runnable {\n    void run();\n}\n</code></pre> Example <pre><code>public class RunnableExample {\n    public static void main(String[] args) {\n        Runnable task = () -&gt; {\n            System.out.println(\"Executing task in: \" + Thread.currentThread().getName());\n        };\n\n        Thread thread = new Thread(task);\n        thread.start();\n    }\n}\n</code></pre> When to Use ? <ul> <li>Use <code>Runnable</code> when no result is expected from the task.</li> <li>Commonly used to run simple background tasks.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#callable-interface","title":"Callable Interface","text":"<p>The <code>Callable</code> interface is similar to <code>Runnable</code>, but it can return a result and throw a checked exception.</p> Structure<pre><code>@FunctionalInterface\npublic interface Callable&lt;V&gt; {\n    V call() throws Exception;\n}\n</code></pre> Example <pre><code>import java.util.concurrent.Callable;\n\npublic class CallableExample {\n    public static void main(String[] args) throws Exception {\n        Callable&lt;Integer&gt; task = () -&gt; {\n            System.out.println(\"Executing task in: \" + Thread.currentThread().getName());\n            return 42;\n        };\n\n        // Direct call (for demonstration)\n        Integer result = task.call();\n        System.out.println(\"Task result: \" + result);\n    }\n}\n</code></pre> When to Use ? <ul> <li>Use <code>Callable</code> when a result or an exception is expected.</li> <li>Works well with thread pools where tasks need to return values (e.g., for parallel computation).</li> </ul>"},{"location":"langdives/Java/ThreadPools/#future-interface","title":"Future Interface","text":"<p>A <code>Future</code> represents the result of an asynchronous computation. It provides methods to check if the computation is complete, wait for the result, and cancel the task if necessary.</p> Structure<pre><code>public interface Future&lt;V&gt; {\n    boolean cancel(boolean mayInterruptIfRunning);\n    boolean isCancelled();\n    boolean isDone();\n    V get() throws InterruptedException, ExecutionException;\n    V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;\n}\n</code></pre> Example <pre><code>import java.util.concurrent.*;\n\npublic class FutureExample {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        ExecutorService executor = Executors.newSingleThreadExecutor();\n\n        Callable&lt;Integer&gt; task = () -&gt; {\n            Thread.sleep(2000); // Simulate some work\n            return 42;\n        };\n\n        Future&lt;Integer&gt; future = executor.submit(task);\n\n        // Do something else while the task executes asynchronously\n        System.out.println(\"Task is running...\");\n\n        // Wait for the result\n        Integer result = future.get();\n        System.out.println(\"Task result: \" + result);\n\n        executor.shutdown();\n    }\n}\n</code></pre> When to Use ? <ul> <li><code>Future</code> allows you to submit tasks to thread pools and retrieve their results once completed.</li> <li>Useful for waiting for multiple tasks to finish.</li> </ul> Key Methods <ul> <li><code>get()</code>: Blocks until the task completes and returns the result.</li> <li><code>isDone()</code>: Checks if the task is completed.</li> <li><code>cancel()</code>: Cancels the task if it's still running.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#blockingqueue-interface","title":"BlockingQueue Interface","text":"<p><code>BlockingQueue</code> is a thread-safe queue that blocks the calling thread when:</p> <ul> <li>Retrieving from an empty queue: The thread waits until an item becomes available.</li> <li>Adding to a full queue: The thread waits until space is available.</li> </ul> Structure<pre><code>public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; {\n    void put(E e) throws InterruptedException;\n    E take() throws InterruptedException;\n    // Other methods for timed operations, size, etc.\n}\n</code></pre> Example <pre><code>import java.util.concurrent.*;\n\npublic class BlockingQueueExample {\n    public static void main(String[] args) {\n        BlockingQueue&lt;Integer&gt; queue = new ArrayBlockingQueue&lt;&gt;(2);\n\n        // Producer thread\n        new Thread(() -&gt; {\n            try {\n                queue.put(1);\n                System.out.println(\"Added 1 to the queue\");\n                queue.put(2);\n                System.out.println(\"Added 2 to the queue\");\n                queue.put(3); // This will block until space is available\n                System.out.println(\"Added 3 to the queue\");\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        }).start();\n\n        // Consumer thread\n        new Thread(() -&gt; {\n            try {\n                Thread.sleep(1000); // Simulate some delay\n                System.out.println(\"Removed from queue: \" + queue.take());\n                System.out.println(\"Removed from queue: \" + queue.take());\n                System.out.println(\"Removed from queue: \" + queue.take());\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        }).start();\n    }\n}\n</code></pre> Usages ? <ul> <li><code>BlockingQueue</code> is commonly used for task queues in thread pools (<code>ThreadPoolExecutor</code>).</li> <li>Ensures proper handoff between producers and consumers without explicit synchronization.</li> </ul> <p>Types of BlockingQueues</p> <ul> <li><code>ArrayBlockingQueue</code>: A fixed-size queue.</li> <li><code>LinkedBlockingQueue</code>: A potentially unbounded queue.</li> <li><code>PriorityBlockingQueue</code>: A priority-based queue.</li> </ul>"},{"location":"langdives/Java/ThreadPools/#runnable-vs-callable","title":"Runnable vs Callable","text":"Aspect Runnable Callable Result No result Returns a result Exception Handling Cannot throw checked exceptions Can throw checked exceptions Functional Interface Yes (<code>run()</code> method) Yes (<code>call()</code> method) Use Case Simple background tasks Tasks that need to return a value or throw an exception"},{"location":"langdives/Java/ThreadPools/#how-these-work-together","title":"How These Work Together","text":"Using Runnable in a Thread Pool<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);\nRunnable task = () -&gt; System.out.println(\"Task executed by \" + Thread.currentThread().getName());\nexecutor.execute(task);\nexecutor.shutdown();\n</code></pre> Using Callable with Future in a Thread Pool<pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);\nCallable&lt;Integer&gt; task = () -&gt; 42;\nFuture&lt;Integer&gt; future = executor.submit(task);\nSystem.out.println(\"Result: \" + future.get());\nexecutor.shutdown();\n</code></pre> Using BlockingQueue with ThreadPoolExecutor<pre><code>BlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(2);\nThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, 30, TimeUnit.SECONDS, queue);\nRunnable task = () -&gt; System.out.println(\"Task executed by \" + Thread.currentThread().getName());\nexecutor.execute(task);\nexecutor.shutdown();\n</code></pre>"},{"location":"langdives/Java/Threads-Atomicity/","title":"Atomicity","text":"<p>Atomicity is a fundamental concept in multithreading and concurrency that ensures operations are executed entirely or not at all, with no intermediate states visible to other threads. In Java, atomicity plays a crucial role in maintaining data consistency in concurrent environments.</p> <p>This Article covers everything about atomic operations, issues with atomicity, atomic classes in Java, and best practices to ensure atomic behavior in your code.</p>"},{"location":"langdives/Java/Threads-Atomicity/#what-is-atomicity","title":"What is Atomicity ?","text":"<p>In a multithreaded program, atomicity guarantees that operations are executed as a single, indivisible unit. When an operation is atomic, it ensures that:</p> <ul> <li>No other thread can see the intermediate state of the operation.</li> <li>The operation either completes fully or fails without any effect.</li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#why-it-is-important","title":"Why it is Important ?","text":"<p>Without atomic operations, multiple threads could interfere with each other, leading to race conditions and data inconsistencies. For example, if two threads try to increment a shared counter simultaneously, the result may not reflect both increments due to interleaving of operations.</p>"},{"location":"langdives/Java/Threads-Atomicity/#problems","title":"Problems ?","text":"Non-Atomic Operations on Primitive Data Types Counter Increment Example<pre><code>class Counter {\n    private int count = 0;\n\n    public void increment() {\n        count++;  // Not atomic\n    }\n\n    public int getCount() {\n        return count;\n    }\n}\n</code></pre> <p>Problem</p> <p>The statement <code>count++</code> is not atomic. It consists of three operations</p> <ul> <li>Read the value of <code>count</code>.</li> <li>Increment the value.</li> <li>Write the new value back to <code>count</code>.</li> </ul> <p>If two threads execute <code>count++</code> simultaneously, one increment might be lost due to race conditions.</p>"},{"location":"langdives/Java/Threads-Atomicity/#how-to-ensure-atomicity","title":"How to Ensure Atomicity ?","text":"<p>Java provides several ways to ensure atomicity, including:</p> <ul> <li><code>synchronized</code> blocks and methods.</li> <li>Explicit locks using <code>ReentrantLock</code>.</li> <li>Atomic classes from the <code>java.util.concurrent.atomic</code> package (recommended for simple atomic operations).</li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#javas-atomic-classes","title":"Java\u2019s <code>Atomic</code> Classes","text":"<p>The <code>java.util.concurrent.atomic</code> package offers classes that support lock-free, thread-safe operations on single variables. These classes rely on low-level atomic operations (like CAS \u2014 Compare-And-Swap) provided by the underlying hardware.</p>"},{"location":"langdives/Java/Threads-Atomicity/#common-atomic-classes","title":"Common Atomic Classes","text":"<ul> <li><code>AtomicInteger</code> \u2013 Atomic operations on integers.</li> <li><code>AtomicLong</code> \u2013 Atomic operations on long values.</li> <li><code>AtomicBoolean</code> \u2013 Atomic operations on boolean values.</li> <li><code>AtomicReference&lt;V&gt;</code> \u2013 Atomic operations on reference variables.</li> <li><code>AtomicStampedReference&lt;V&gt;</code> \u2013 Supports versioned references to prevent ABA problems.</li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#atomicinteger","title":"<code>AtomicInteger</code>","text":"Example: Solving the Increment Problem <pre><code>import java.util.concurrent.atomic.AtomicInteger;\n\nclass AtomicCounter {\n    private final AtomicInteger count = new AtomicInteger(0);\n\n    public void increment() {\n        count.incrementAndGet();  // Atomic increment\n    }\n\n    public int getCount() {\n        return count.get();\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws InterruptedException {\n        AtomicCounter counter = new AtomicCounter();\n\n        Thread t1 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) {\n                counter.increment();\n            }\n        });\n\n        Thread t2 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) {\n                counter.increment();\n            }\n        });\n\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n\n        System.out.println(\"Final Count: \" + counter.getCount());  // Output: 2000\n    }\n}\n</code></pre> Explanation <ul> <li>The <code>incrementAndGet()</code> method ensures atomicity without using locks.</li> <li>This solution is faster and more scalable than using <code>synchronized</code> or <code>ReentrantLock</code>.</li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#atomicboolean","title":"<code>AtomicBoolean</code>","text":"Example: Managing Flags Safely <pre><code>import java.util.concurrent.atomic.AtomicBoolean;\n\nclass FlagManager {\n    private final AtomicBoolean isActive = new AtomicBoolean(false);\n\n    public void activate() {\n        if (isActive.compareAndSet(false, true)) {\n            System.out.println(\"Flag activated.\");\n        } else {\n            System.out.println(\"Flag already active.\");\n        }\n    }\n\n    public void deactivate() {\n        if (isActive.compareAndSet(true, false)) {\n            System.out.println(\"Flag deactivated.\");\n        } else {\n            System.out.println(\"Flag already inactive.\");\n        }\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        FlagManager manager = new FlagManager();\n\n        Thread t1 = new Thread(manager::activate);\n        Thread t2 = new Thread(manager::activate);\n\n        t1.start();\n        t2.start();\n    }\n}\n</code></pre> Explanation <p><code>compareAndSet()</code> changes the flag only if it matches the expected value, ensuring thread safety.</p>"},{"location":"langdives/Java/Threads-Atomicity/#atomicreference","title":"<code>AtomicReference</code>","text":"Example: Atomic Operations on Objects <pre><code>import java.util.concurrent.atomic.AtomicReference;\n\nclass Person {\n    String name;\n\n    Person(String name) {\n        this.name = name;\n    }\n}\n\npublic class AtomicReferenceExample {\n    public static void main(String[] args) {\n        AtomicReference&lt;Person&gt; personRef = new AtomicReference&lt;&gt;(new Person(\"Alice\"));\n\n        // Atomic update of the reference\n        personRef.set(new Person(\"Bob\"));\n        System.out.println(\"Updated Person: \" + personRef.get().name);\n    }\n}\n</code></pre> <p>When to Use ?</p> <p>Use <code>AtomicReference</code> when you need atomic operations on object references.</p>"},{"location":"langdives/Java/Threads-Atomicity/#atomicstampedreference","title":"<code>AtomicStampedReference</code>","text":"<p>The ABA problem occurs when a value changes from <code>A</code> to <code>B</code> and then back to <code>A</code>. <code>AtomicStampedReference</code> solves this by associating a version (stamp) with the value.</p> Example: ABA problem prevention <pre><code>import java.util.concurrent.atomic.AtomicStampedReference;\n\npublic class AtomicStampedReferenceExample {\n    public static void main(String[] args) {\n        AtomicStampedReference&lt;Integer&gt; ref = new AtomicStampedReference&lt;&gt;(1, 0);\n\n        int[] stamp = new int[1];\n        Integer value = ref.get(stamp);\n        System.out.println(\"Initial Value: \" + value + \", Stamp: \" + stamp[0]);\n\n        boolean success = ref.compareAndSet(1, 2, stamp[0], stamp[0] + 1);\n        System.out.println(\"CAS Success: \" + success + \", New Value: \" + ref.get(stamp) + \", New Stamp: \" + stamp[0]);\n    }\n}\n</code></pre> Explanation <p><code>AtomicStampedReference</code> ensures that the same value change does not go undetected by tracking the version.</p>"},{"location":"langdives/Java/Threads-Atomicity/#performance","title":"Performance ?","text":"<ul> <li>No Locks: Atomic operations are non-blocking and do not require heavy locks, improving throughput.</li> <li>Scalability: They perform well in highly concurrent environments.</li> <li>Low Overhead: CAS operations are supported natively by hardware, providing low-latency operations.</li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#when-to-use","title":"When to Use ?","text":"<ul> <li> <p>Use <code>AtomicInteger</code> or <code>AtomicBoolean</code> instead of <code>synchronized</code> methods like simple counters or flags.</p> </li> <li> <p>Use <code>AtomicReference</code> for lock-free algorithms (Non blocking Algos).</p> </li> <li> <p>Use <code>AtomicStampedReference</code> for versioned updates to prevent ABA problems.</p> </li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#limitations","title":"Limitations ?","text":"<ul> <li> <p>Atomic classes only work with single variables. For multiple variables, use <code>synchronized</code> or <code>ReentrantLock</code>.</p> </li> <li> <p>For complex operations involving multiple state changes, atomic classes are insufficient.</p> </li> <li> <p>Atomic operations avoid deadlocks but can still suffer from livelocks (threads continuously retrying without progress).</p> </li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#best-practices","title":"Best Practices","text":"<ul> <li>Use atomic classes for simple state management (e.g., counters, flags).</li> <li>Avoid overuse of atomic classes for complex operations, use <code>synchronized</code> or <code>ReentrantLock</code>.</li> <li>Monitor performance while atomic operations are faster, they might not suit every situation (e.g., write-heavy workloads).</li> <li>Avoid busy-waiting with atomic classes to prevent CPU wastage.</li> </ul>"},{"location":"langdives/Java/Threads-Atomicity/#summary","title":"Summary","text":"<p>The atomic classes in Java\u2019s <code>java.util.concurrent.atomic</code> package offer lock-free, thread-safe operations that are ideal for simple state management. By ensuring atomicity, these classes help avoid race conditions and improve the performance and scalability of multithreaded applications. However, they are best suited for single-variable updates for more complex operations, locks or transactional mechanisms may still be necessary.</p>"},{"location":"langdives/Java/Threads/","title":"Threads","text":"<p>Java offers multithreading to perform multiple tasks concurrently, improving performance and responsiveness. This deep dive covers every key concept of Java threading with detailed explanations and code examples. </p> <p>Before that let's have a quick rewind of fundamental concept of concurrency and parallelism.</p>"},{"location":"langdives/Java/Threads/#concurrency-and-parallelism","title":"Concurrency and Parallelism","text":"<p>Concurrency: Multiple tasks start, run, and complete in overlapping time periods (not necessarily simultaneously).</p> <p>Parallelism: Multiple tasks run exactly at the same time (requires multi-core processors).</p> <p>We have another article where we gone through fundamentals of concurrency and parallelism in depth though we cover some of the stuff here to but its recommeneded to go through this artice Concurrency and Parallelism</p> <p>Java achieves both using threads, thread pools, and various libraries such as Executors, Fork/Join Framework, and Streams API, We will go through them one by one and in this article we mostly cover Threads.</p>"},{"location":"langdives/Java/Threads/#what-is-a-thread","title":"What is a Thread?","text":"<p>A thread is a lightweight sub-process. A Java program has at least one thread \u2014 the main thread, which starts with the <code>main()</code> method. You can create additional threads to execute code concurrently. Each thread shares the same process memory, but has its own stack, registers, and program counter.</p>"},{"location":"langdives/Java/Threads/#how-to-create","title":"How to Create ?","text":"<p>You can create a thread in two ways:</p> Extending the Thread class<pre><code>class MyThread extends Thread {\n    public void run() {\n        System.out.println(\"Thread running: \" + Thread.currentThread().getName());\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        MyThread t1 = new MyThread();\n        t1.start();  // Start the thread\n    }\n}\n</code></pre> Implementing the Runnable interface<pre><code>class MyRunnable implements Runnable {\n    public void run() {\n        System.out.println(\"Runnable running: \" + Thread.currentThread().getName());\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Thread t1 = new Thread(new MyRunnable());\n        t1.start();  // Start the thread\n    }\n}\n</code></pre> <p>When to Use ?</p> <ul> <li><code>Runnable</code>: When you need to inherit from another class, use <code>Runnable</code> since Java does not support multiple inheritance.</li> <li><code>Thread</code>: If your class does not need to extend any other class, extending <code>Thread</code> might be more intuitive.</li> </ul>"},{"location":"langdives/Java/Threads/#thread-lifecycle","title":"Thread Lifecycle","text":"<p>A thread in Java goes through the following states:</p> <p>Thread Lifecycle</p> <ul> <li>NEW: Thread is created but not started yet.</li> <li>RUNNABLE: Thread is ready to run or running but waiting for CPU time.</li> <li>BLOCKED / WAITING / TIMED_WAITING: Thread is waiting for a resource or condition.</li> <li>RUNNING: Thread is executing.</li> <li>TERMINATED: Thread has completed execution or stopped due to an exception.</li> </ul> Example: Thread Lifecycle <pre><code>class MyThread extends Thread {\n    public void run() {\n        System.out.println(\"Running thread: \" + Thread.currentThread().getName());\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws InterruptedException {\n        MyThread t1 = new MyThread();  // NEW\n        t1.start();  // RUNNABLE\n\n        // Join to wait for the thread to complete\n        t1.join();  // Terminated once finished\n        System.out.println(\"Thread has terminated.\");\n    }\n}\n</code></pre> <p>Note</p> <ul> <li>Blocked State: Occurs when the thread is waiting for a monitor lock (e.g., waiting for I/O or a lock in synchronized methods).</li> <li>Waiting State: Occurs when a thread calls <code>wait()</code> or waits indefinitely.</li> <li>Timed Waiting: Happens when <code>sleep()</code> or <code>join(time)</code> is invoked, meaning the thread will resume after a specific time.</li> </ul>"},{"location":"langdives/Java/Threads/#daemon-threads","title":"Daemon Threads","text":"<p>A daemon thread is a background thread that provides support services, like the garbage collector. It does not prevent the JVM from shutting down once all user threads are completed.</p> Example of Daemon Thread <pre><code>class DaemonThread extends Thread {\n    public void run() {\n        if (Thread.currentThread().isDaemon()) {\n            System.out.println(\"This is a daemon thread.\");\n        } else {\n            System.out.println(\"This is a user thread.\");\n        }\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        DaemonThread t1 = new DaemonThread();\n        t1.setDaemon(true);  // Set as daemon thread\n        t1.start();\n\n        DaemonThread t2 = new DaemonThread();\n        t2.start();\n    }\n}\n</code></pre> <p>When to use Daemon Threads ?</p> <p>For background tasks like logging, garbage collection, or monitoring services.</p>"},{"location":"langdives/Java/Threads/#thread-priority","title":"Thread Priority","text":"<p>Java assigns a priority to each thread, ranging from 1 (MIN_PRIORITY) to 10 (MAX_PRIORITY). The default priority is 5 (NORM_PRIORITY). Thread priority affects scheduling, but it\u2019s platform-dependent \u2014 meaning it doesn\u2019t guarantee execution order.</p> Setting Thread Priority Example <pre><code>class PriorityThread extends Thread {\n    public void run() {\n        System.out.println(\"Running thread: \" + Thread.currentThread().getName() +\n                        \" with priority: \" + Thread.currentThread().getPriority());\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        PriorityThread t1 = new PriorityThread();\n        PriorityThread t2 = new PriorityThread();\n\n        t1.setPriority(Thread.MIN_PRIORITY);  // Priority 1\n        t2.setPriority(Thread.MAX_PRIORITY);  // Priority 10\n\n        t1.start();\n        t2.start();\n    }\n}\n</code></pre> <p>When to use Priority Threads</p> <p>Only when certain tasks should have preferential scheduling over others. However, Java thread scheduling is not guaranteed, so don't rely solely on priority.</p>"},{"location":"langdives/Java/Threads/#thread-synchronization","title":"Thread Synchronization","text":"<p>When multiple threads access shared resources (like variables), synchronization ensures that only one thread modifies the resource at a time. Use the <code>synchronized</code> keyword to prevent race conditions.</p> Synchronization Example <pre><code>class Counter {\n    private int count = 0;\n\n    public synchronized void increment() {\n        count++;  // Only one thread can increment at a time\n    }\n\n    public int getCount() {\n        return count;\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws InterruptedException {\n        Counter counter = new Counter();\n\n        Thread t1 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) counter.increment();\n        });\n\n        Thread t2 = new Thread(() -&gt; {\n            for (int i = 0; i &lt; 1000; i++) counter.increment();\n        });\n\n        t1.start();\n        t2.start();\n        t1.join();\n        t2.join();\n\n        System.out.println(\"Final count: \" + counter.getCount());\n    }\n}\n</code></pre> <p>When to use Synchronization ?</p> <p>When multiple threads access critical sections of code to avoid inconsistent data.</p>"},{"location":"langdives/Java/Threads/#inter-thread-communication","title":"Inter-thread Communication","text":"<p>Java allows threads to communicate using wait-notify methods, avoiding busy waiting. </p> <ul> <li><code>wait()</code>: Makes the thread wait until another thread notifies it.</li> <li><code>notify()</code>: Wakes up a single waiting thread.</li> <li><code>notifyAll()</code>: Wakes up all waiting threads.</li> </ul> Inter-thread Communication Example <pre><code>class SharedResource {\n    private int value;\n    private boolean available = false;\n\n    public synchronized void produce(int val) throws InterruptedException {\n        while (available) {\n            wait();  // Wait if value is already available\n        }\n        value = val;\n        available = true;\n        System.out.println(\"Produced: \" + value);\n        notify();  // Notify the consumer thread\n    }\n\n    public synchronized void consume() throws InterruptedException {\n        while (!available) {\n            wait();  // Wait if value is not available\n        }\n        System.out.println(\"Consumed: \" + value);\n        available = false;\n        notify();  // Notify the producer thread\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        SharedResource resource = new SharedResource();\n\n        Thread producer = new Thread(() -&gt; {\n            try {\n                for (int i = 1; i &lt;= 5; i++) resource.produce(i);\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        });\n\n        Thread consumer = new Thread(() -&gt; {\n            try {\n                for (int i = 1; i &lt;= 5; i++) resource.consume();\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        });\n\n        producer.start();\n        consumer.start();\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Threads/#thread-local-variables","title":"Thread-Local Variables","text":"<p><code>ThreadLocal</code> provides a way to create thread-isolated variables. Each thread gets its own copy of the variable, and changes made by one thread do not affect others. This is useful when you don\u2019t want threads to share a common state.</p> ThreadLocal Usage Example <pre><code>public class ThreadLocalExample {\n    private static ThreadLocal&lt;Integer&gt; threadLocal = ThreadLocal.withInitial(() -&gt; 1);\n\n    public static void main(String[] args) {\n        Thread t1 = new Thread(() -&gt; {\n            threadLocal.set(100);\n            System.out.println(\"Thread 1: \" + threadLocal.get());\n        });\n\n        Thread t2 = new Thread(() -&gt; {\n            threadLocal.set(200);\n            System.out.println(\"Thread 2: \" + threadLocal.get());\n        });\n\n        t1.start();\n        t2.start();\n    }\n}\n</code></pre> <p>When to use ?</p> <p>Useful in multi-threaded environments (like database transactions) where each thread needs its own context without interference from other threads.</p>"},{"location":"langdives/Java/Threads/#volatile-variables","title":"Volatile Variables","text":"<p>The <code>volatile</code> keyword ensures visibility of changes to variables across threads. Without <code>volatile</code>, thread-local caches may not reflect the latest changes made by other threads.</p> Volatile Example <pre><code>public class VolatileExample {\n    private static volatile boolean running = true;\n\n    public static void main(String[] args) {\n        Thread t = new Thread(() -&gt; {\n            while (running) {\n                // Busy-wait\n            }\n            System.out.println(\"Thread stopped.\");\n        });\n\n        t.start();\n\n        try { Thread.sleep(1000); } catch (InterruptedException e) { }\n        running = false;  // Change will be visible to other threads\n    }\n}\n</code></pre> <p>When to Use Volatile</p> <p>Use volatile for variables accessed by multiple threads without needing synchronization (e.g., flags).</p>"},{"location":"langdives/Java/Threads/#when-to-use-volatile","title":"When to Use <code>volatile</code> ?","text":"<ul> <li>When Multiple threads are reading and writing a shared variable.</li> <li>When No complex operations (like increments) are performed on the variable.</li> <li>When you don\u2019t want to use synchronized due to overhead, but memory visibility is still required.</li> </ul> Example Where <code>volatile</code> is Necessary <pre><code>class VolatileExample {\n    private volatile boolean running = true;\n\n    public void stop() {\n        running = false;  // Change becomes immediately visible to other threads\n    }\n\n    public void run() {\n        while (running) {\n            // Do something\n        }\n        System.out.println(\"Thread stopped.\");\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        VolatileExample example = new VolatileExample();\n\n        Thread t = new Thread(example::run);\n        t.start();\n\n        Thread.sleep(1000);\n        example.stop();  // Stop the thread\n    }\n}\n</code></pre> Explanation <p>Here, <code>volatile</code> ensures that the change to <code>running</code> made by the <code>stop()</code> method is immediately visible to the thread executing <code>run()</code>. Without <code>volatile</code>, the <code>run()</code> thread might never see the change and keep running indefinitely.</p>"},{"location":"langdives/Java/Threads/#when-not-to-use-volatile","title":"When Not to Use <code>volatile</code> ?","text":"<ul> <li>When Operations depend on the current value (like <code>count++</code>).</li> <li>When You need atomic operations (which require locks or <code>Atomic</code> classes).</li> </ul> Problem with Volatile for Non-Atomic Operations <pre><code>class Counter {\n    private volatile int count = 0;\n\n    public void increment() {\n        count++;  // Not atomic! Two threads can still read the same value.\n    }\n\n    public int getCount() {\n        return count;\n    }\n}\n</code></pre> <p>Issue</p> <p>Even though <code>count</code> is marked <code>volatile</code>, <code>count++</code> is not atomic. Two threads could read the same value and increment it, leading to lost updates. To fix this, use synchronized or <code>AtomicInteger</code>.</p>"},{"location":"langdives/Java/Threads/#volatile-vs-synchronized","title":"Volatile vs Synchronized","text":""},{"location":"langdives/Java/Threads/#no-synchronized-or-volatile","title":"No <code>synchronized</code> or <code>volatile</code> ?","text":"<p>If you don\u2019t use <code>volatile</code> or <code>synchronized</code>, some dangerous scenarios can occur. Like this:</p> Example <pre><code>class SharedResource {\n    private boolean available = false;\n\n    public void produce() {\n        available = true;  // Change not guaranteed to be visible immediately\n    }\n\n    public void consume() {\n        while (!available) {\n            // Busy-waiting, might never see the change to `available`\n        }\n        System.out.println(\"Consumed!\");\n    }\n}\n</code></pre> <p>Problem</p> <p>If <code>available</code> is not marked <code>volatile</code>, the change made by <code>produce()</code> might not be visible to the <code>consume()</code> thread immediately. The consumer thread might be stuck in an infinite loop because it doesn't see the latest value of <code>available</code>.</p> <p>Note</p> <ul> <li>Threads may cache variables locally in CPU registers or thread-local memory.</li> <li>No guarantee that updates made by one thread will be immediately visible to other threads unless <code>volatile</code> or <code>synchronized</code> is used.</li> </ul>"},{"location":"langdives/Java/Threads/#synchronized-over-volatile","title":"<code>Synchronized</code> over <code>volatile</code> ?","text":"<p>Let's go through an example where its okay to use just synchroinized instead of volatile</p> Example <pre><code>public synchronized void produce(int val) throws InterruptedException {\n    while (available) {\n        wait();  // Wait if value is already available\n    }\n    value = val;\n    available = true;\n    System.out.println(\"Produced: \" + value);\n    notify();  // Notify the consumer thread\n}\n</code></pre> <p>Synchronized Keyword: </p> <ul> <li>When a thread enters a <code>synchronized</code> block or method (like <code>produce()</code> or <code>consume()</code>), it acquires a lock on the <code>SharedResource</code> object. This ensures mutual exclusion \u2014 only one thread can access the critical section at a time.</li> <li>Memory visibility: Synchronization flushes the thread-local cache to main memory when a thread exits the <code>synchronized</code> block. This ensures that the latest value of <code>available</code> is visible to all other threads.</li> </ul> <p>Wait-Notify Mechanism:</p> <ul> <li>The <code>wait()</code> and <code>notify()</code> methods release and acquire the lock, enforcing happens-before relationships (meaning operations before <code>notify()</code> or <code>wait()</code> are visible to other threads).</li> <li>This ensures that if one thread sets <code>available = true</code> in <code>produce()</code>, another thread waiting in <code>consume()</code> will see the updated value when it wakes up.</li> </ul> <p>Because this code uses <code>synchronized</code> methods and wait-notify, the necessary memory visibility is achieved without needing <code>volatile</code>. </p>"},{"location":"langdives/Java/Threads/#differences","title":"Differences","text":"Aspect <code>volatile</code> <code>synchronized</code> Visibility Ensures visibility of changes. Ensures visibility and atomicity. Atomicity Not guaranteed. Guaranteed (only one thread at a time). Performance Faster (no locking). Slower (locking involved). Use Case For flags, simple state updates. For complex operations, critical sections. Overhead Low (no blocking). High (involves blocking and context switches)."},{"location":"langdives/Java/Threads/#thread-memory","title":"Thread Memory","text":"<p>The memory consumption per thread and the maximum number of threads in Java depend on several factors, such as:</p> <ul> <li>JVM and OS configurations (32-bit vs 64-bit JVM).</li> <li>Thread stack size (which can be configured).</li> <li>Available system memory.</li> <li>OS-imposed limits.</li> </ul>"},{"location":"langdives/Java/Threads/#memory-used-by-thread","title":"Memory used by Thread","text":"<p>Each Java thread consumes two key areas of memory:</p> <ul> <li>Java Thread Stack Memory (allocated per thread).</li> <li>Native Thread Metadata / Overhead (handled by the OS).</li> </ul> <p>Thread Stack Memory: Each thread gets its own stack, which holds Local variables (primitives, references), Method call frames, Intermediate results during method execution.</p> <p>Note</p> <p>The default stack size depends on the JVM and platform:</p> <ul> <li>Linux / macOS / Windows 64-bit: ~1 MB per thread.</li> <li>32-bit JVM: ~320 KB to 512 KB per thread.</li> </ul> <p>You can change the stack size with the <code>-Xss</code> JVM option: <pre><code>java -Xss512k YourProgram\n</code></pre></p> <p>Native Thread Metadata: In addition to stack memory, the OS kernel allocates metadata per thread (for thread control structures). This varies by platform but is typically in the range of 8 KB to 16 KB per thread.</p>"},{"location":"langdives/Java/Threads/#memory-per-thread","title":"Memory per Thread ?","text":"<p>The typical memory consumption per thread:</p> <ul> <li>Stack size: 512 KB to 1 MB.</li> <li>Native metadata overhead: ~16 KB (depends on OS).</li> </ul> <p>Thus, a single thread could use ~1 MB to 1.1 MB of memory.</p>"},{"location":"langdives/Java/Threads/#max-threads-you-can-create","title":"Max Threads you Can Create ?","text":"<p>The number of threads you can create depends on:</p> <ul> <li>Available system memory.</li> <li>JVM heap size (configurable with <code>-Xmx</code>).</li> <li>Thread stack size (configurable with <code>-Xss</code>).</li> <li>OS limits on threads per process.</li> </ul> Practical Calculation Example <p>Let's say:</p> <ul> <li>Available physical memory: 8 GB.</li> <li>JVM heap size: 2 GB (<code>-Xmx2g</code>).</li> <li>Available memory for threads: 6 GB (8 GB - 2 GB heap).</li> <li>Stack size per thread: 1 MB (<code>-Xss1m</code>).</li> </ul> <p>Maximum threads = <code>6 GB / 1 MB per thread = ~6000 threads</code>.</p> <p>OS Limits on Threads</p> <p>Even if memory allows for thousands of threads, the OS imposes limits:</p> <ul> <li>Linux: 1024 - 32,768 threads (configurable with <code>/etc/security/limits.conf</code>).</li> <li>Windows: Around 2000-3000 threads per process.</li> </ul>"},{"location":"langdives/Java/Threads/#too-many-threads-created","title":"Too Many Threads Created ?","text":"<ul> <li> <p><code>OutOfMemoryError: unable to create new native thread</code> Occurs when the OS can't allocate more native threads.</p> </li> <li> <p>Performance Degradation as context switching between many threads becomes expensive, leading to CPU thrashing.</p> </li> </ul>"},{"location":"langdives/Java/Threads/#optimizing-thread-usage","title":"Optimizing Thread Usage","text":"<p>Rather than creating many threads manually, use thread pools to manage a fixed number of threads efficiently:</p> Thread Pools Example <pre><code>import java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class ThreadPoolExample {\n    public static void main(String[] args) {\n        ExecutorService executor = Executors.newFixedThreadPool(10);\n        for (int i = 0; i &lt; 100; i++) {\n            executor.submit(() -&gt; {\n                System.out.println(\"Running thread: \" + Thread.currentThread().getName());\n            });\n        }\n        executor.shutdown();\n    }\n}\n</code></pre> <p>Thread pools reuse threads, reducing memory usage and improving performance.</p>"},{"location":"langdives/Java/Threads/#how-to-increase-max-thread","title":"How to Increase Max Thread ?","text":"<p>On Linux, you can increase the maximum threads per process</p> Check current limits<pre><code>ulimit -u  # Max user processes\n</code></pre> Increase limit (temporary)<pre><code>ulimit -u 65535\n</code></pre> Permanent change: Edit '/etc/security/limits.conf' and add<pre><code>your_user_name  hard  nproc  65535\nyour_user_name  soft  nproc  65535\n</code></pre> <p>Key points</p> <ul> <li>Memory per thread: Typically 1 MB to 1.1 MB.</li> <li>Number of threads: Limited by available memory and OS restrictions.</li> <li>Practical upper limit: A system with 8 GB RAM and 1 MB stack size can support around 6000 threads, but OS limits (like Linux: ~32K, Windows: ~2K) may restrict this.</li> </ul>"},{"location":"langdives/Java/Spring/","title":"Spring","text":""},{"location":"langdives/Java/Spring/#what-is-spring","title":"What is Spring ?","text":"<p>Spring is a popular, open-source Java-based framework used to create enterprise-level applications. It provides a comprehensive programming and configuration model that simplifies Java development. At its core, Spring focuses on dependency injection and inversion of control (IoC), providing an abstraction over Java's complexity.</p>"},{"location":"langdives/Java/Spring/#core-goals-of-spring","title":"Core goals of Spring","text":"<ul> <li>Simplify Java development.</li> <li>Promote loosely coupled and testable code.</li> <li>Offer modularity through different projects (Spring Data, Spring Security, Spring MVC, etc.).</li> </ul>"},{"location":"langdives/Java/Spring/#ecosystem-overview","title":"Ecosystem Overview","text":"<p>The Spring ecosystem consists of various projects for different use cases:</p> <ul> <li>Core Spring Framework \u2013 Foundation for building Java applications with dependency injection and IoC.</li> <li>Spring Boot \u2013 Simplifies the creation of stand-alone, production-ready Spring applications.</li> <li>Spring MVC \u2013 Web framework for building RESTful APIs and web applications.</li> <li>Spring Security \u2013 Framework for authentication and authorization.</li> <li>Spring Data \u2013 Simplifies interaction with databases.</li> <li>Spring Cloud \u2013 Toolkit for building cloud-native, microservices applications.</li> </ul>"},{"location":"langdives/Java/Spring/SpringAnnotations/","title":"Spring Annotations","text":"<p>A comprehensive list of Spring Boot annotations, covering core Spring Boot, configuration, web, data, testing, and more. I'll organize them by categories with keys (annotation names) and values (purpose/use cases) for easy reference.</p>"},{"location":"langdives/Java/Spring/SpringAnnotations/#core-annotations","title":"Core Annotations","text":"Annotation Purpose/Use Case <code>@SpringBootApplication</code> Main entry point for a Spring Boot application. Combines <code>@Configuration</code>, <code>@ComponentScan</code>, and <code>@EnableAutoConfiguration</code>. <code>@EnableAutoConfiguration</code> Enables automatic configuration of Spring beans based on the classpath and defined properties. <code>@ComponentScan</code> Scans the package and its sub-packages for Spring components (e.g., <code>@Component</code>, <code>@Service</code>). <code>@Configuration</code> Marks a class as a source of bean definitions. Used to define Spring beans programmatically. <code>@Bean</code> Declares a method as a Spring bean, registered in the application context. <code>@Import</code> Imports additional configuration classes. <code>@ImportResource</code> Loads bean definitions from external XML configuration files."},{"location":"langdives/Java/Spring/SpringAnnotations/#web-and-rest-annotations","title":"Web and REST Annotations","text":"Annotation Purpose/Use Case <code>@RestController</code> Marks a class as a REST API controller. Combines <code>@Controller</code> and <code>@ResponseBody</code>. <code>@Controller</code> Marks a class as a web controller. Works with view templates (like Thymeleaf). <code>@RequestMapping</code> Maps HTTP requests to specific handler methods or classes. Can be used on classes or methods. <code>@GetMapping</code> Maps HTTP GET requests to specific handler methods. <code>@PostMapping</code> Maps HTTP POST requests to specific handler methods. <code>@PutMapping</code> Maps HTTP PUT requests to specific handler methods. <code>@DeleteMapping</code> Maps HTTP DELETE requests to specific handler methods. <code>@PatchMapping</code> Maps HTTP PATCH requests to specific handler methods. <code>@RequestBody</code> Binds the HTTP request body to a Java object. Used in REST controllers. <code>@ResponseBody</code> Binds the return value of a method directly to the HTTP response body. <code>@RequestParam</code> Binds HTTP query parameters to method arguments. <code>@PathVariable</code> Binds URI template variables to method parameters. <code>@RequestHeader</code> Binds HTTP request headers to method parameters. <code>@CookieValue</code> Binds cookie values to method parameters. <code>@ModelAttribute</code> Binds form data to a model object. <code>@SessionAttributes</code> Declares session-scoped model attributes. <code>@CrossOrigin</code> Enables cross-origin requests (CORS) for specific endpoints."},{"location":"langdives/Java/Spring/SpringAnnotations/#jpa-jdbc-annotations","title":"JPA, JDBC Annotations","text":"Annotation Purpose/Use Case <code>@Entity</code> Marks a class as a JPA entity. <code>@Table</code> Specifies the database table for a JPA entity. <code>@Id</code> Marks a field as the primary key of a JPA entity. <code>@GeneratedValue</code> Specifies how the primary key value should be generated. <code>@Column</code> Specifies the mapping of a field to a database column. <code>@OneToOne</code> Establishes a one-to-one relationship between entities. <code>@OneToMany</code> Establishes a one-to-many relationship between entities. <code>@ManyToOne</code> Establishes a many-to-one relationship between entities. <code>@ManyToMany</code> Establishes a many-to-many relationship between entities. <code>@JoinColumn</code> Specifies the foreign key column for a relationship. <code>@Query</code> Defines a custom JPQL or SQL query on a repository method. <code>@Transactional</code> Marks a method or class as transactional. Ensures ACID properties in data operations. <code>@EnableJpaRepositories</code> Enables JPA repositories for data access. <code>@Repository</code> Marks a class as a data repository. <code>@EnableTransactionManagement</code> Enables declarative transaction management."},{"location":"langdives/Java/Spring/SpringAnnotations/#security-annotations","title":"Security Annotations","text":"Annotation Purpose/Use Case <code>@EnableWebSecurity</code> Enables Spring Security for web applications. <code>@EnableGlobalMethodSecurity</code> Enables method-level security annotations like <code>@PreAuthorize</code> and <code>@PostAuthorize</code>. <code>@PreAuthorize</code> Applies authorization logic before a method is invoked. <code>@PostAuthorize</code> Applies authorization logic after a method has executed. <code>@Secured</code> Secures a method by roles (deprecated in favor of <code>@PreAuthorize</code>). <code>@RolesAllowed</code> Specifies which roles are allowed to access a method. <code>@WithMockUser</code> Simulates a user for testing security."},{"location":"langdives/Java/Spring/SpringAnnotations/#testing-annotations","title":"Testing Annotations","text":"Annotation Purpose/Use Case <code>@SpringBootTest</code> Runs integration tests for a Spring Boot application. Loads the full application context. <code>@WebMvcTest</code> Tests only web layer components (e.g., controllers). <code>@DataJpaTest</code> Tests only JPA repositories. Configures an in-memory database. <code>@MockBean</code> Replaces a bean with a mock during tests. <code>@SpyBean</code> Replaces a bean with a spy during tests. <code>@TestConfiguration</code> Provides additional bean configurations for tests. <code>@BeforeEach</code> Runs before each test method in a test class. <code>@AfterEach</code> Runs after each test method in a test class."},{"location":"langdives/Java/Spring/SpringAnnotations/#profiles-annotations","title":"Profiles Annotations","text":"Annotation Purpose/Use Case <code>@ConfigurationProperties</code> Binds external configuration properties to a Java bean. <code>@EnableConfigurationProperties</code> Enables support for <code>@ConfigurationProperties</code> beans. <code>@Profile</code> Specifies the profile under which a bean is active (e.g., dev, prod). <code>@Value</code> Injects a value from the properties or environment. <code>@PropertySource</code> Loads properties from an external file. <code>@Environment</code> Provides access to the current environment settings."},{"location":"langdives/Java/Spring/SpringAnnotations/#actuator-metrics-annotations","title":"Actuator &amp; Metrics Annotations","text":"Annotation Purpose/Use Case <code>@Endpoint</code> Defines a custom Actuator endpoint. <code>@ReadOperation</code> Marks a method as a read operation for an Actuator endpoint. <code>@WriteOperation</code> Marks a method as a write operation for an Actuator endpoint. <code>@DeleteOperation</code> Marks a method as a delete operation for an Actuator endpoint. <code>@Timed</code> Measures the execution time of a method. <code>@Gauge</code> Exposes a gauge metric to Actuator. <code>@Metered</code> Marks a method to be counted as a metric (deprecated in favor of <code>@Timed</code>)."},{"location":"langdives/Java/Spring/SpringAnnotations/#microservices-annotations","title":"Microservices Annotations","text":"Annotation Purpose/Use Case <code>@EnableDiscoveryClient</code> Enables service registration with Eureka, Consul, or Zookeeper. <code>@EnableFeignClients</code> Enables Feign clients for inter-service communication. <code>@CircuitBreaker</code> Implements circuit-breaking logic using Resilience4j. <code>@Retryable</code> Enables retry logic for a method. <code>@LoadBalanced</code> Enables load balancing for REST clients."},{"location":"langdives/Java/Spring/SpringAnnotations/#miscellaneous-annotations","title":"Miscellaneous Annotations","text":"Annotation Purpose/Use Case <code>@Conditional</code> Conditionally registers a bean based on custom logic. <code>@Async</code> Marks a method to run asynchronously. <code>@Scheduled</code> Schedules a method to run at fixed intervals or cron expressions. <code>@EventListener</code> Marks a method to listen for application events. <code>@Cacheable</code> Caches the result of a method. <code>@CacheEvict</code> Evicts entries from a cache."},{"location":"langdives/Java/Spring/SpringAnnotations/#summary","title":"Summary","text":"<p>This is a comprehensive list of all major Spring Boot annotations, categorized by their functionality. With these annotations, Spring Boot makes it easier to develop applications by reducing boilerplate code, automating configuration, and offering powerful tools for testing, security, and microservices development.</p>"},{"location":"langdives/Java/Spring/SpringBoot/","title":"Spring Boot","text":"<p>This article covers how Spring Boot automates configurations, deals with microservices, and manages monitoring, security, and performance.</p>"},{"location":"langdives/Java/Spring/SpringBoot/#what-is-spring-boot","title":"What is Spring Boot ?","text":"<p>Spring Boot is an extension of the Spring Framework that simplifies the development of Java applications by offering:</p> <ul> <li>Convention over Configuration: Minimizes manual configurations.</li> <li>Embedded Server Support: Includes servers like Tomcat/Jetty for quick setups.</li> <li>Auto-Configuration: Automatically configures your application based on included dependencies.</li> <li>Production-ready Tools: Provides health monitoring, metrics, and more with Spring Boot Actuator.</li> </ul> <p>The goal of Spring Boot is to help developers build stand-alone, production-grade applications quickly and with less fuss.</p>"},{"location":"langdives/Java/Spring/SpringBoot/#application-architecture","title":"Application Architecture","text":"<p>A Spring Boot application consists of</p> <ul> <li>Spring Boot Starters: Dependency bundles for specific use cases (e.g., <code>spring-boot-starter-web</code> for web apps).</li> <li>Auto-Configuration: Based on what is in the classpath (e.g., if JPA libraries are present, Spring Boot configures a DataSource and EntityManagerFactory).</li> <li>Embedded Servers: Applications run directly with Tomcat, Jetty, or Undertow.</li> <li>Application Properties: Customizable settings using <code>application.properties</code> or <code>application.yml</code>.</li> </ul>"},{"location":"langdives/Java/Spring/SpringBoot/#key-components","title":"Key Components","text":""},{"location":"langdives/Java/Spring/SpringBoot/#annotations","title":"Annotations","text":"<ul> <li> <p><code>@SpringBootApplication</code>: Combines three core annotations</p> <ul> <li><code>@Configuration</code>: Marks the class as a source of bean definitions.</li> <li><code>@EnableAutoConfiguration</code>: Enables auto-configuration based on classpath contents.</li> <li><code>@ComponentScan</code>: Scans for Spring components (beans, services, controllers).</li> </ul> </li> <li> <p><code>@RestController</code>: Marks a class as a controller with REST endpoints.</p> </li> <li> <p><code>@Autowired</code>: Injects dependencies automatically by type.</p> </li> <li> <p><code>@Value</code>: Injects values from properties files.</p> </li> <li> <p><code>@Profile</code>: Activates beans only under specific profiles (e.g., dev, prod).</p> </li> </ul>"},{"location":"langdives/Java/Spring/SpringBoot/#starters","title":"Starters","text":"<p>Starters are pre-configured dependency bundles for common functionalities</p> <ul> <li><code>spring-boot-starter-web</code>: For web applications.</li> <li><code>spring-boot-starter-data-jpa</code>: For working with databases using JPA.</li> <li><code>spring-boot-starter-security</code>: For authentication and authorization.</li> <li><code>spring-boot-starter-actuator</code>: For monitoring and management.</li> </ul>"},{"location":"langdives/Java/Spring/SpringBoot/#how-auto-config-works","title":"How Auto-Config Works ?","text":"<p>Spring Boot uses <code>@EnableAutoConfiguration</code> to detect dependencies and automatically configure beans for you. </p> <p>For example: If <code>spring-boot-starter-data-jpa</code> is present, it will</p> <ol> <li>Configure a <code>DataSource</code>.</li> <li>Configure an <code>EntityManagerFactory</code> to manage JPA entities.</li> <li>Enable transaction management using <code>@EnableTransactionManagement</code>.</li> </ol> <p>How to Debug Auto-Configuration:</p> <ul> <li> <p>Add <code>--debug</code> to the application start command to list all auto-configurations.   <pre><code>$ java -jar myapp.jar --debug\n</code></pre></p> </li> <li> <p>If you need to exclude an auto-configuration, use:   <pre><code>@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})\n</code></pre></p> </li> </ul>"},{"location":"langdives/Java/Spring/SpringBoot/#application-lifecycle","title":"Application Lifecycle","text":"<p>Startup: Spring Boot applications initialize with SpringApplication.run(), The lifecycle involves loading beans, initializing contexts, and wiring dependencies.</p> <p>Embedded Server: By default, Spring Boot uses Tomcat as the embedded server. Others include Jetty and Undertow, The server listens on a configurable port (default: <code>8080</code>).</p> <p>Shutdown: Spring Boot provides graceful shutdown using <code>@PreDestroy</code> or hooks via <code>SpringApplication.addShutdownHook()</code>.</p>"},{"location":"langdives/Java/Spring/SpringBoot/#configuration-in-depth","title":"Configuration in Depth","text":""},{"location":"langdives/Java/Spring/SpringBoot/#using-applicationproperties","title":"Using <code>application.properties</code>","text":"<p>Spring Boot applications are configured using either <code>application.properties</code></p> Examples of <code>application.properties</code> <pre><code>server.port=8081\nspring.datasource.url=jdbc:mysql://localhost:3306/mydb\nspring.datasource.username=root\nspring.datasource.password=password\n</code></pre>"},{"location":"langdives/Java/Spring/SpringBoot/#using-applicationyml","title":"Using <code>application.yml</code>","text":"<p>Using Profiles (e.g., Dev vs. Prod) in <code>application.yml</code></p> Example of <code>application.yml</code> <pre><code>server:\n  port: 8080\nspring:\n  profiles:\n    active: dev\n\n---\nspring:\n  profiles: dev\n  datasource:\n    url: jdbc:h2:mem:testdb\n\n---\nspring:\n  profiles: prod\n  datasource:\n    url: jdbc:mysql://localhost:3306/proddb\n</code></pre> <p>You can activate profiles programmatically or through command-line options</p> <pre><code>$ java -Dspring.profiles.active=prod -jar myapp.jar\n</code></pre>"},{"location":"langdives/Java/Spring/SpringBoot/#custom-configuration","title":"Custom Configuration","text":"<p>You can define your own custom properties and inject them into beans using <code>@ConfigurationProperties</code>.</p> Example <pre><code>@ConfigurationProperties(prefix = \"custom\")\npublic class CustomConfig {\n    private String name;\n    private int timeout;\n\n    // Getters and Setters\n}\n</code></pre> application.properties<pre><code>custom.name=SpringApp\ncustom.timeout=5000\n</code></pre> Inject the CustomConfig bean<pre><code>@Autowired\nprivate CustomConfig customConfig;\n</code></pre>"},{"location":"langdives/Java/Spring/SpringBoot/#embedded-server-customization","title":"Embedded Server Customization","text":"<p>You can customize the embedded server by configuring the <code>EmbeddedServletContainerFactory</code>.</p> Changing the Tomcat thread pool size <pre><code>@Bean\npublic ConfigurableServletWebServerFactory webServerFactory() {\n    TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory();\n    factory.setPort(9090);\n    factory.addConnectorCustomizers(connector -&gt; {\n        connector.setAttribute(\"maxThreads\", 200);\n    });\n    return factory;\n}\n</code></pre>"},{"location":"langdives/Java/Spring/SpringBoot/#actuator-and-monitoring","title":"Actuator and Monitoring","text":""},{"location":"langdives/Java/Spring/SpringBoot/#spring-boot-actuator","title":"Spring Boot Actuator","text":"<p>Exposes application management and monitoring endpoints.</p> <p>Some common endpoints:</p> <ul> <li><code>/actuator/health</code>: Health status.</li> <li><code>/actuator/info</code>: Application information.</li> <li><code>/actuator/metrics</code>: Metrics data (e.g., memory usage, request counts).</li> </ul> Securing Actuator Endpoints<pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health, info\n  security:\n    enabled: true\n</code></pre> <p>You can customize or add your own metrics by using <code>@Timed</code> or <code>MeterRegistry</code>.</p>"},{"location":"langdives/Java/Spring/SpringBoot/#security","title":"Security","text":"<ul> <li> <p>Basic Authentication Setup: Add <code>spring-boot-starter-security</code> dependency, by default, Spring Boot enables basic authentication with a generated password.</p> </li> <li> <p>Custom Authentication    <pre><code>@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n            .antMatchers(\"/public/\").permitAll()\n            .anyRequest().authenticated()\n            .and()\n            .httpBasic();\n    }\n}\n</code></pre></p> </li> <li> <p>JWT Authentication: Use JSON Web Tokens (JWT) for token-based authentication in microservices architectures.</p> </li> </ul>"},{"location":"langdives/Java/Spring/SpringBoot/#building-microservices","title":"Building Microservices","text":"<ul> <li>Service Registration and Discovery: Use Eureka for service discovery.</li> <li>Load Balancing: Use Spring Cloud LoadBalancer or Netflix Ribbon.</li> <li>API Gateway: Use Spring Cloud Gateway for routing and security.</li> <li>Resilience: Implement Circuit Breakers using Resilience4j or Hystrix.</li> </ul>"},{"location":"langdives/Java/Spring/SpringBoot/#testing","title":"Testing","text":"<ul> <li> <p>Unit Testing: Use <code>@SpringBootTest</code> for integration testing, Mock beans with <code>@MockBean</code>.     <pre><code>@SpringBootTest\npublic class MyServiceTest {\n    @MockBean\n    private MyRepository repository;\n\n    @Autowired\n    private MyService service;\n\n    @Test\n    public void testService() {\n        when(repository.findById(1L)).thenReturn(Optional.of(new MyEntity()));\n        assertTrue(service.findById(1L).isPresent());\n    }\n}\n</code></pre></p> </li> <li> <p>Test Containers: Use Testcontainers for running databases or services in Docker containers during tests.</p> </li> </ul>"},{"location":"langdives/Java/Spring/SpringBoot/#summary","title":"Summary","text":"<p>Spring Boot streamlines the development process by providing auto-configuration, embedded servers, and a production-ready environment. It empowers developers to build and deploy microservices quickly, backed by powerful features like Spring Security, Spring Data, Actuator, and more. With its opinionated defaults and deep customizability, Spring Boot strikes a balance between simplicity and flexibility making it ideal for both beginners and advanced developers.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/","title":"Spring Core Framework","text":"<p>the foundation of the entire Spring ecosystem. We'll explore each component and mechanism in detail, so by the end, you\u2019ll have a thorough understanding of how Spring Core works, including the IoC container, Dependency Injection (DI), Beans, ApplicationContext, Bean Lifecycle, AOP, and more.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#what-is-spring-core-framework","title":"What is Spring Core Framework","text":"<p>The Spring Core Framework is the heart of the Spring ecosystem. It provides the essential features required to build Java applications, with a focus on dependency injection (DI) and inversion of control (IoC). At its core, Spring aims to eliminate the complexities of creating objects, managing dependencies, and wiring different components together.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#modules","title":"Modules","text":""},{"location":"langdives/Java/Spring/SpringCoreFramework/#spring-core","title":"Spring Core","text":"<p>The foundational module that provides the IoC container and the basic tools for dependency injection (DI), It includes the core interfaces and classes like BeanFactory, ApplicationContext, BeanPostProcessor, BeanDefinition, and others.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#spring-beans","title":"Spring Beans","text":"<p>Manages the configuration, creation, and lifecycle of Spring beans.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#spring-context","title":"Spring Context","text":"<p>Provides a runtime environment for applications using the IoC container. It builds on the Spring Core and adds additional functionality like events and internationalization (i18n).</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#spring-spel","title":"Spring SpEL","text":"<p>SpEL(Spring Expression Language) A powerful expression language that can be used to dynamically query or manipulate bean properties.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#core-concepts","title":"Core Concepts","text":""},{"location":"langdives/Java/Spring/SpringCoreFramework/#inversion-of-control-ioc","title":"Inversion of Control (IoC)","text":"<p>The Inversion of Control (IoC) principle is at the core of the Spring Framework. It shifts the control of object creation and management from the developer to the IoC container, promoting loose coupling and enhancing testability. Let\u2019s break it down conceptually and then dive into the Spring implementation.</p> <p>In traditional programming, the application code creates and manages its dependencies directly.</p> Example <pre><code>public class OrderService {\n    private PaymentService paymentService;\n\n    public OrderService() {\n        this.paymentService = new PaymentService(); // Tight coupling\n    }\n}\n</code></pre> <p>Explanation</p> <ul> <li>The <code>OrderService</code> class directly instantiates <code>PaymentService</code>, meaning these two classes are tightly coupled. If the <code>PaymentService</code> class changes, you must modify the <code>OrderService</code> code as well.</li> <li>This design also makes unit testing harder since the <code>OrderService</code> always uses a real <code>PaymentService</code> instead of a mock service.</li> </ul> <p>IoC Solution With Inversion of Control (IoC), the responsibility of creating the <code>PaymentService</code> is \"inverted\" and delegated to the Spring IoC container. Now, the IoC container injects the dependency into <code>OrderService</code>.</p> IoC Solution Example <pre><code>@Component\npublic class OrderService {\n    private final PaymentService paymentService;\n\n    @Autowired\n    public OrderService(PaymentService paymentService) {\n        this.paymentService = paymentService;  // Dependency injection\n    }\n}\n</code></pre> <p>Explanation</p> <ul> <li>The <code>OrderService</code> no longer creates the <code>PaymentService</code> itself.</li> <li>The Spring IoC container handles the lifecycle of <code>PaymentService</code> and provides it to <code>OrderService</code>.</li> </ul>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#types-of-ioc-containers","title":"Types of IoC Containers","text":""},{"location":"langdives/Java/Spring/SpringCoreFramework/#beanfactory","title":"BeanFactory","text":"<p>BeanFactory is the basic IoC container in Spring. It provides basic dependency injection and bean management functionality. </p> <p>Features of BeanFactory:</p> <ul> <li>Lazy Initialization: Beans are created only when they are requested.</li> <li>Minimal memory usage since beans are not pre-initialized.</li> <li>Useful in scenarios with resource constraints, such as mobile applications.</li> </ul> Usage Example <pre><code>BeanFactory factory = new XmlBeanFactory(new FileSystemResource(\"beans.xml\"));\nOrderService service = (OrderService) factory.getBean(\"orderService\");\n</code></pre> <p>However, BeanFactory is rarely used now because it lacks advanced features like event propagation, internationalization, and eager initialization, which are provided by ApplicationContext.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#applicationcontext","title":"ApplicationContext","text":"<p>ApplicationContext is a more powerful IoC container that extends BeanFactory. It is widely used in modern Spring applications because of its rich features.</p> <p>Features of ApplicationContext:</p> <ul> <li>Eager Initialization: Beans are instantiated during startup, improving performance for large-scale applications.</li> <li>Event Propagation: Publishes and listens to application events (like <code>ContextRefreshedEvent</code>).</li> <li>Internationalization (i18n): Supports localization for different languages.</li> <li>Bean Autowiring: Automatically injects dependencies with @Autowired or other annotations.</li> <li>Environment Abstraction: Manages application profiles and environment variables.</li> </ul> Usage Example <pre><code>ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\nOrderService service = context.getBean(OrderService.class);\n</code></pre> <p>In most cases, developers use <code>AnnotationConfigApplicationContext</code> or <code>Spring Boot</code> to load configurations and manage beans.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#beanfactory-vs-applicationcontext","title":"BeanFactory vs ApplicationContext","text":"Aspect BeanFactory ApplicationContext Bean Initialization Lazy (on-demand) Eager (at startup) Event Handling Not supported Supports event handling Internationalization Not supported Supports i18n Bean Lifecycle Hooks Basic Full support for lifecycle hooks Common Usage Legacy or constrained environments Modern Spring applications"},{"location":"langdives/Java/Spring/SpringCoreFramework/#ioc-flow","title":"IoC Flow","text":"<p>Step-by-Step</p> <ol> <li> <p>Define Beans and Dependencies: Beans can be defined in XML, Java Configuration, or through Annotations like <code>@Component</code>. <pre><code>&lt;bean id=\"paymentService\" class=\"com.example.PaymentService\"/&gt;\n&lt;bean id=\"orderService\" class=\"com.example.OrderService\"&gt;\n    &lt;constructor-arg ref=\"paymentService\"/&gt;\n&lt;/bean&gt;\n</code></pre></p> </li> <li> <p>Spring IoC Container Loads Configuration: The IoC container reads the configuration (XML, annotations, or Java-based) during startup.</p> </li> <li> <p>Dependency Injection (DI): The IoC container identifies the dependencies and injects them using constructor, setter, or field injection.</p> </li> <li> <p>Bean Initialization: The IoC container initializes all necessary beans (eagerly or lazily).</p> </li> <li> <p>Bean Usage: The beans are now available for use by the application.</p> </li> </ol>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#dependency-injection-di","title":"Dependency Injection (DI)","text":""},{"location":"langdives/Java/Spring/SpringCoreFramework/#what-is-di","title":"What is DI ?","text":"<p>Dependency Injection (DI) is a pattern where objects are provided with their dependencies at runtime by the IoC container instead of creating them directly. Spring supports multiple types of dependency injection:</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#types-of-di","title":"Types of DI","text":"<p>Constructor Injection: Dependencies are provided through the class constructor, Recommended for mandatory dependencies.</p> Constructor Injection Example <pre><code>@Component\npublic class OrderService {\n    private final PaymentService paymentService;\n\n    @Autowired\n    public OrderService(PaymentService paymentService) {\n        this.paymentService = paymentService;\n    }\n}\n</code></pre> <p>Setter Injection: Dependencies are injected using setter methods, Useful for optional dependencies.</p> Setter Injection Example <pre><code>@Component\npublic class OrderService {\n    private PaymentService paymentService;\n\n    @Autowired\n    public void setPaymentService(PaymentService paymentService) {\n        this.paymentService = paymentService;\n    }\n}\n</code></pre> <p>Field Injection: Dependencies are injected directly into class fields, Not recommended since it makes unit testing harder.</p> Field Injection <pre><code>@Component\npublic class OrderService {\n    @Autowired\n    private PaymentService paymentService;\n}\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#why-ioc-and-di-are-essential","title":"Why IoC and DI are Essential","text":"<ul> <li> <p>Loose Coupling: Objects don\u2019t manage their dependencies, making them easier to modify, extend, or replace.</p> </li> <li> <p>Testability: Dependencies can be easily mocked during unit tests, enhancing test coverage.</p> </li> <li> <p>Reusability: Components are easier to reuse across different parts of the application.</p> </li> <li> <p>Configuration Management: Centralized configuration of beans ensures that all components behave consistently.</p> </li> </ul>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#challenges-with-ioc","title":"Challenges with IoC","text":"<ul> <li> <p>Configuration Overhead: Without frameworks like Spring, managing dependencies can lead to complex code. Spring solves this by centralizing configurations.</p> </li> <li> <p>Circular Dependencies: Two beans dependent on each other can cause issues. Spring detects such circular dependencies and throws exceptions.</p> </li> <li> <p>Managing Large Applications: With many components, configuration can get complicated. Spring Boot simplifies this with auto-configuration and starters.</p> </li> </ul>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#full-ioc-implementation","title":"Full IoC Implementation","text":"<p>Let\u2019s look at a complete example using Spring Core with constructor injection:</p> Full IoC Implementation Example Java Configuration Example<pre><code>@Configuration\npublic class AppConfig {\n\n    @Bean\n    public PaymentService paymentService() {\n        return new PaymentService();\n    }\n\n    @Bean\n    public OrderService orderService(PaymentService paymentService) {\n        return new OrderService(paymentService);\n    }\n}\n</code></pre> OrderService and PaymentService<pre><code>@Component\npublic class PaymentService {\n    public void processPayment() {\n        System.out.println(\"Payment processed.\");\n    }\n}\n\n@Component\npublic class OrderService {\n    private final PaymentService paymentService;\n\n    @Autowired\n    public OrderService(PaymentService paymentService) {\n        this.paymentService = paymentService;\n    }\n\n    public void placeOrder() {\n        System.out.println(\"Order placed.\");\n        paymentService.processPayment();\n    }\n}\n</code></pre> Main Class to Run<pre><code>public class Main {\n    public static void main(String[] args) {\n        ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);\n        OrderService orderService = context.getBean(OrderService.class);\n        orderService.placeOrder();\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#beans-and-ioc-container","title":"Beans and IoC Container","text":"<p>Spring beans are the building blocks of any Spring application. They represent the objects that the Spring IoC container manages throughout their lifecycle. Understanding beans and their lifecycle is critical for mastering the Spring Core framework. Let\u2019s explore everything about beans\u2014from creation, scopes, lifecycle, initialization, destruction, and more\u2014in detail.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#what-is-a-bean","title":"What is a Bean ?","text":"<p>A bean in Spring is an object that is instantiated, assembled, and managed by the IoC container. The container creates, initializes, and wires these beans, ensuring that all dependencies are injected as needed. Beans are usually defined using:</p> <ul> <li>XML configuration files</li> <li>Java-based configuration classes</li> <li>Annotations (<code>@Component</code>, <code>@Service</code>, <code>@Repository</code>, <code>@Controller</code>)</li> </ul>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#configuring-beans","title":"Configuring Beans","text":"<p>Spring provides multiple ways to declare beans and register them with the IoC container:</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#xml-based-configuration","title":"XML-based Configuration","text":"<p>Traditional way of defining beans using XML files.</p> XML Config Example <pre><code>&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" \n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://www.springframework.org/schema/beans \n    http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt;\n\n    &lt;bean id=\"paymentService\" class=\"com.example.PaymentService\"/&gt;\n    &lt;bean id=\"orderService\" class=\"com.example.OrderService\"&gt;\n        &lt;constructor-arg ref=\"paymentService\"/&gt;\n    &lt;/bean&gt;\n&lt;/beans&gt;\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#java-based-configuration","title":"Java-based Configuration","text":"<p>Spring allows you to use Java classes to define beans. This is cleaner and avoids XML boilerplate.</p> Java Config Example <pre><code>@Configuration\npublic class AppConfig {\n\n    @Bean\n    public PaymentService paymentService() {\n        return new PaymentService();\n    }\n\n    @Bean\n    public OrderService orderService() {\n        return new OrderService(paymentService());\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#component-scanning-with-annotations","title":"Component Scanning with Annotations","text":"<p>You can annotate classes with @Component, @Service, @Repository, or @Controller. Spring automatically detects these beans if @ComponentScan is enabled.</p> Annotations Example <pre><code>@Component\npublic class PaymentService { }\n\n@Component\npublic class OrderService {\n    private final PaymentService paymentService;\n\n    @Autowired\n    public OrderService(PaymentService paymentService) {\n        this.paymentService = paymentService;\n    }\n}\n</code></pre> <pre><code>@Configuration\n@ComponentScan(basePackages = \"com.example\")\npublic class AppConfig { }\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#bean-scopes","title":"Bean Scopes","text":"<p>The scope of a bean defines the lifecycle and visibility of that bean within the Spring IoC container.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#types-of-bean-scopes","title":"Types of Bean Scopes","text":"<p>singleton (default): A single instance of the bean is created and shared across the entire application, Used for stateless beans.</p> Example <pre><code>@Scope(\"singleton\")\n@Component\npublic class SingletonBean { }\n</code></pre> <p>prototype: A new instance is created every time the bean is requested, Useful for stateful objects or temporary tasks.</p> Example <pre><code>@Scope(\"prototype\")\n@Component\npublic class PrototypeBean { }\n</code></pre> <p>request: A new bean instance is created for each HTTP request, Used in web applications.    </p> <p>session: A single instance is created per HTTP session.</p> <p>globalSession: A global session scope for applications using portlets.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#bean-lifecycle","title":"Bean Lifecycle","text":"<p>Each Spring bean goes through several lifecycle phases, starting from instantiation to destruction. The Spring IoC container manages this lifecycle internally.</p> <p>Bean Lifecycle Phases</p> <ul> <li> <p>Bean Instantiation: The IoC container instantiates the bean using the constructor or factory method.</p> </li> <li> <p>Dependency Injection (DI): The container injects dependencies (via constructor, setter, or field injection).</p> </li> <li> <p>Custom Initialization: If the bean implements <code>InitializingBean</code> or uses the <code>@PostConstruct</code> annotation, the initialization logic is executed here.</p> </li> <li> <p>Bean Ready to Use: After initialization, the bean is ready for use by the application.</p> </li> <li> <p>Custom Destruction: When the IoC container is shutting down, beans with <code>@PreDestroy</code> or <code>DisposableBean</code> are given a chance to release resources.</p> </li> </ul>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#bean-lifecycle-callbacks","title":"Bean Lifecycle Callbacks","text":"<p>InitializingBean Interface: If a bean implements the <code>InitializingBean</code> interface, it must override the <code>afterPropertiesSet()</code> method, which is called after all properties are set.</p> Example <pre><code>public class MyService implements InitializingBean {\n    @Override\n    public void afterPropertiesSet() {\n        System.out.println(\"MyService is initialized.\");\n    }\n}\n</code></pre> <p>DisposableBean Interface: If a bean implements the <code>DisposableBean</code> interface, it must override the <code>destroy()</code> method, which is called during the destruction phase.</p> Example <pre><code>public class MyService implements DisposableBean {\n    @Override\n    public void destroy() {\n        System.out.println(\"MyService is being destroyed.\");\n    }\n}\n</code></pre> <p>Using <code>@PostConstruct</code> and <code>@PreDestroy</code>: These annotations are the recommended way to manage initialization and destruction callbacks.</p> Example <pre><code>@Component\npublic class MyService {\n\n    @PostConstruct\n    public void init() {\n        System.out.println(\"Initialization logic in @PostConstruct.\");\n    }\n\n    @PreDestroy\n    public void cleanup() {\n        System.out.println(\"Cleanup logic in @PreDestroy.\");\n    }\n}\n</code></pre> <p>Custom Initialization and Destruction Methods: You can also specify custom methods in the bean configuration.</p> Example (Java Config) <pre><code>@Bean(initMethod = \"init\", destroyMethod = \"cleanup\")\npublic MyService myService() {\n    return new MyService();\n}\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#eager-vs-lazy-initialization","title":"Eager vs. Lazy Initialization","text":""},{"location":"langdives/Java/Spring/SpringCoreFramework/#eager-initialization","title":"Eager Initialization","text":"<p>All singleton beans are created at the time of application startup (default behavior), Useful for performance since all dependencies are resolved upfront.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#lazy-initialization","title":"Lazy Initialization","text":"<p>Beans are created only when they are first requested, You can enable lazy initialization at the bean level using <code>@Lazy</code>.</p> Example <pre><code>@Lazy\n@Component\npublic class LazyBean { }\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#di-and-bean-relationships","title":"DI and Bean Relationships","text":"<p>Spring IoC container resolves bean dependencies through constructor injection, setter injection, or field injection, You can specify bean dependencies explicitly using the <code>depends-on</code> attribute in XML.</p> Example (XML) <pre><code>&lt;bean id=\"databaseConnection\" class=\"com.example.DatabaseConnection\"/&gt;\n&lt;bean id=\"orderService\" class=\"com.example.OrderService\" depends-on=\"databaseConnection\"/&gt;\n</code></pre> <p>This ensures that the <code>databaseConnection</code> bean is initialized before the <code>orderService</code> bean.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#beans-circular-dependencies","title":"Beans Circular Dependencies","text":"<p>A circular dependency occurs when two or more beans are mutually dependent on each other.</p> Example <pre><code>@Component\npublic class A {\n    @Autowired\n    private B b;\n}\n\n@Component\npublic class B {\n    @Autowired\n    private A a;\n}\n</code></pre> <p>Spring tries to resolve circular dependencies using singleton beans by injecting proxies, but it fails for constructor injection. To avoid circular dependencies: - Refactor the code to reduce dependencies. - Use setter injection instead of constructor injection.</p>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#bean-definition-inheritance","title":"Bean Definition Inheritance","text":"<p>Spring allows bean definitions to inherit properties from a parent bean. This helps reduce configuration duplication.</p> Example (XML) <pre><code>&lt;bean id=\"parentBean\" class=\"com.example.BaseService\"&gt;\n    &lt;property name=\"name\" value=\"Base Service\"/&gt;\n&lt;/bean&gt;\n\n&lt;bean id=\"childBean\" class=\"com.example.ChildService\" parent=\"parentBean\"&gt;\n    &lt;property name=\"name\" value=\"Child Service\"/&gt;\n&lt;/bean&gt;\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#aspect-oriented-programming","title":"Aspect-Oriented Programming","text":"<p>AOP allows you to separate cross-cutting concerns (like logging, security, or transaction management) from the business logic. In Spring, AOP is implemented using aspects, advice, and pointcuts.</p> <ul> <li>Aspect: A module that encapsulates cross-cutting logic.</li> <li>Advice: Code that runs at a specific point (before, after, or around a method).</li> <li>Pointcut: Defines where the advice applies.</li> <li>Weaving: The process of applying aspects to target objects.</li> </ul> AOP Example in Spring Define an Aspect<pre><code>@Aspect\n@Component\npublic class LoggingAspect {\n    @Before(\"execution(* com.example.*.*(..))\")\n    public void logBefore(JoinPoint joinPoint) {\n        System.out.println(\"Before method: \" + joinPoint.getSignature().getName());\n    }\n}\n</code></pre> Enable AOP<pre><code>@Configuration\n@EnableAspectJAutoProxy\npublic class AppConfig { }\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#spring-events","title":"Spring Events","text":"<p>Spring supports an event-driven model that allows you to build decoupled components. The ApplicationContext can publish events and allow listeners to respond to them.</p> Example of a Custom Event <pre><code>public class CustomEvent extends ApplicationEvent {\n    public CustomEvent(Object source) {\n        super(source);\n    }\n}\n</code></pre> <pre><code>@Component\npublic class CustomEventListener implements ApplicationListener&lt;CustomEvent&gt; {\n    @Override\n    public void onApplicationEvent(CustomEvent event) {\n        System.out.println(\"Received custom event: \" + event);\n    }\n}\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#spring-expression-lang-spel","title":"Spring Expression Lang (SpEL)","text":"<p>SpEL allows you to manipulate and query beans dynamically. It can be used inside XML or annotations.</p> Example of SpEL <pre><code>&lt;bean id=\"myBean\" class=\"com.example.MyClass\"&gt;\n    &lt;property name=\"value\" value=\"#{2 + 3}\"/&gt;\n&lt;/bean&gt;\n</code></pre>"},{"location":"langdives/Java/Spring/SpringCoreFramework/#summary","title":"Summary","text":"<ul> <li>Spring Core simplifies Java development with IoC and DI, promoting loose coupling and testability.</li> <li>IoC Container manages the creation and lifecycle of beans, ensuring efficient dependency management.</li> <li>AOP adds modularity by separating cross-cutting concerns.</li> <li>SpEL provides dynamic querying and manipulation of beans.</li> <li>ApplicationContext enhances the BeanFactory with additional features, like event propagation and i18n support.</li> </ul>"},{"location":"langdives/Java/Spring/SpringFrameworkVsSpringBoot/","title":"Difference B/W Spring Framework &amp; Boot","text":"<p>A detailed comparison table that covers all possible differences between Spring Boot and Spring Framework. This comparison covers everything from setup, configuration, embedded servers, web applications, testing, microservices support, and much more.</p>"},{"location":"langdives/Java/Spring/SpringFrameworkVsSpringBoot/#differences","title":"Differences","text":"Category Spring Framework Spring Boot Purpose A comprehensive framework for building Java applications. An extension of Spring Framework to simplify configuration and create stand-alone applications. Setup Requires manual setup, including XML or Java-based configuration. Minimal setup with auto-configuration based on the classpath. Main Focus Provides flexibility and control over every aspect of the application. Focuses on rapid development with sensible defaults and opinions. Configuration Can use XML, Java-based, or annotation-based configuration. Uses annotations and properties/YAML files for configuration. Learning Curve Requires more learning time due to complexity. Easier to get started with for beginners due to auto-configuration and pre-built setups. Project Dependencies Requires managing multiple dependencies for each feature manually. Provides starters (e.g., <code>spring-boot-starter-web</code>) to include required dependencies. Embedded Server No embedded server support; WAR files must be deployed to external servers (Tomcat, Jetty, etc.). Comes with embedded servers (Tomcat, Jetty, or Undertow) for running stand-alone applications. Deployment Deploy WAR/EAR files to external servers. Runs applications directly as JAR files with embedded servers. Auto-Configuration No auto-configuration; requires manual configuration of components. Auto-configures components based on available classpath dependencies. Application Entry Point Relies on external servlet containers to manage the lifecycle. Uses <code>@SpringBootApplication</code> as the entry point with <code>SpringApplication.run()</code>. Microservices Support Not specialized for microservices; requires additional tools. Built with microservices architecture in mind. Supports Spring Cloud, Eureka, Feign, etc. Performance Requires more configuration to optimize performance. Better suited for lightweight and high-performance microservices. Profiles Supports profiles for environment-specific configurations but requires more setup. Supports profiles easily through <code>application.yml</code> or <code>application.properties</code>. Testing Provides JUnit support but requires manual configuration for context loading. Provides easy testing with <code>@SpringBootTest</code>, <code>@MockBean</code>, <code>@DataJpaTest</code>, and others. Security Uses Spring Security but requires manual integration. Integrates Spring Security easily with <code>spring-boot-starter-security</code>. Database Access Provides JDBC, JPA, ORM support, but requires more configuration. Simplifies database access with Spring Data JPA and auto-configuration of <code>DataSource</code>. Starters and Dependency Management Requires manual management of dependencies and configurations. Provides Spring Boot Starters that bundle all required dependencies for specific use cases. Template Engines Supports Thymeleaf, JSP, and others with manual setup. Supports template engines with starters (e.g., <code>spring-boot-starter-thymeleaf</code>). Command-Line Interface (CLI) No built-in CLI support. Provides Spring Boot CLI to run Groovy scripts for quick development. Actuator and Monitoring Requires external monitoring tools or custom configurations. Comes with Spring Boot Actuator to monitor application health, metrics, and endpoints. DevTools for Hot Reload Requires manual setup for hot reloading of code changes. Provides Spring Boot DevTools for hot reloading during development. Support for Reactive Programming Supports Spring WebFlux and Project Reactor (from version 5.x). Fully supports Spring WebFlux for reactive, non-blocking programming. Circuit Breakers &amp; Resilience Requires integration with third-party libraries like Hystrix. Seamlessly integrates with Resilience4j and Spring Cloud for resilience. Integration with Cloud Platforms Requires Spring Cloud or manual setup for cloud integration. Seamlessly integrates with Spring Cloud for cloud-native development. Logging Configuration Requires manual configuration of logging frameworks (e.g., Log4j, SLF4J). Provides auto-configured logging using Logback by default. Health Checks and Metrics Requires manual configuration to expose health metrics. Provides Actuator endpoints (<code>/actuator/health</code>, <code>/actuator/metrics</code>) out-of-the-box. Web Framework Uses Spring MVC for building web applications. Uses Spring MVC or Spring WebFlux with easy setup through starters. Restful API Development Requires manual setup of controllers and components. Provides easy development with <code>@RestController</code> and auto-configuration of REST endpoints. Command-Line Arguments Support Requires manual handling of command-line arguments. Easily reads command-line arguments with <code>SpringApplication</code> or <code>@Value</code>. Caching Support Requires setting up EhCache, Guava, or other caching solutions manually. Provides easy caching configuration with <code>@EnableCaching</code> and auto-configuration. Internationalization (i18n) Supports i18n but requires more setup. Supports i18n with minimal configuration through <code>application.properties</code>. Job Scheduling Requires integration with Quartz or other scheduling libraries. Supports scheduling with <code>@Scheduled</code> and Task Executors. Dependency Injection (DI) Provides dependency injection with IoC container. Same as Spring Framework but simplifies it with auto-wiring using <code>@Autowired</code>. Backward Compatibility Must manually update configurations when upgrading versions. Provides backward compatibility with most Spring projects. Community and Ecosystem Large community and extensive ecosystem. Built on top of Spring Framework with additional tools for modern development."},{"location":"langdives/Java/Spring/SpringFrameworkVsSpringBoot/#summary","title":"Summary","text":"<p>Spring Boot simplifies Spring Framework by:</p> <ul> <li>Automating configuration.</li> <li>Providing embedded servers.</li> <li>Offering out-of-the-box starters for common features.</li> </ul> <p>Spring Framework gives more control and flexibility but at the cost of manual setup and configuration.</p> <p>Spring Boot is optimized for rapid development, especially for microservices and cloud-native applications.</p> <p>Spring Framework is still relevant for legacy applications or when fine-grained control is necessary.</p>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/","title":"High Availability and Fault Tolerance","text":""},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#high-availability-ha","title":"High Availability (HA)","text":"<p>High Availability (HA) refers to a system or infrastructure's ability to remain operational and accessible for a very high percentage of time, minimizing downtime. In essence, it's a design principle used in IT to ensure that services, applications, or systems are continuously available, even in the event of hardware failures, software issues, or unexpected disruptions. </p> <p>Key Aspects of High Availability</p> <ul> <li> <p>Redundancy:  Multiple components (like servers, databases, or network paths) are set up so that if one fails, another can take over immediately without interrupting the service.  </p> </li> <li> <p>Failover:  If a primary system component fails, the workload automatically switches to a backup or standby system to avoid service disruptions.</p> </li> <li> <p>Load Balancing:  Distribution of workloads across multiple servers or resources helps prevent any single system from becoming overwhelmed and failing. This also increases performance and resiliency.</p> </li> <li> <p>Clustering:  Multiple servers or resources act as a \"cluster,\" functioning together as a single system. If one server fails, the cluster can redistribute the tasks to the remaining ones.</p> </li> <li> <p>Monitoring and Alerts:  Constant health checks and monitoring tools are used to detect potential problems early. Alerts can notify administrators to address issues before they impact availability.</p> </li> <li> <p>Data Replication:  Critical data is often replicated across multiple locations or systems. This ensures that in case of a failure, there\u2019s no data loss and services can continue with minimal disruption.</p> </li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ha-levels","title":"HA Levels","text":"<p>Availability is often expressed as a percentage. For instance, an uptime of 99.99% means the service is expected to be down for only 52 minutes in a year.</p> <p>Common availability standards</p> <ul> <li>99% uptime: ~3.65 days of downtime per year.</li> <li>99.9% uptime (three nines): ~8.76 hours of downtime per year.</li> <li>99.99% uptime (four nines): ~52 minutes of downtime per year.</li> <li>99.999% uptime (five nines): ~5.26 minutes of downtime per year.</li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ha-use-cases","title":"HA Use Cases","text":"<ul> <li> <p>Data Centers: Cloud providers like AWS, Microsoft Azure, and Google Cloud offer high availability zones to ensure service uptime even during hardware failures or network outages.</p> </li> <li> <p>Web Applications: E-commerce sites (like Amazon) employ HA architecture to ensure they remain operational at all times, as any downtime directly impacts revenue.</p> </li> <li> <p>Banking Systems:  Financial services need HA to ensure uninterrupted access to customer transactions, ATMs, and payment processing services.</p> </li> <li> <p>Telecommunication Networks:  Cellular networks and ISPs use HA to maintain voice, data, and internet services without interruptions.</p> </li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ha-challenges","title":"HA Challenges","text":"<ul> <li>Cost: Implementing HA systems often requires significant investment in redundant hardware and infrastructure.</li> <li>Complexity: Managing and maintaining multiple systems and failover mechanisms increases operational complexity.</li> <li>Testing Failover Mechanisms: Ensuring that failover systems activate correctly in real-world scenarios requires rigorous testing.</li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ha-when-to-use","title":"HA When to Use ?","text":"<ul> <li>When some downtime is acceptable, as long as it's minimal (milliseconds to minutes).</li> <li>Cost-effective for applications where availability is critical but not life-threatening (e.g., web services, banking applications, cloud platforms).</li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#fault-tolerance-ft","title":"Fault Tolerance (FT)","text":"<p>Fault Tolerance refers to the ability of a system, network, or application to continue functioning correctly even when one or more of its components fail. It ensures continuous operation without loss of service, despite hardware, software, or other types of faults occurring in the system. Fault tolerance plays a crucial role in ensuring high reliability and availability of critical systems.</p> <p>Key Principles of Fault Tolerance</p> <ul> <li> <p>Redundancy:  Multiple components are deployed so that if one component fails, another takes over seamlessly. Redundant systems include extra servers, power supplies, storage drives, and networks.</p> </li> <li> <p>Failover:  When a primary component or service fails, the workload automatically \"fails over\" to a backup system with minimal disruption.</p> </li> <li> <p>Error Detection and Correction:  The system includes mechanisms to detect, isolate, and correct errors to maintain proper functioning. This is often implemented using parity bits, checksums, or watchdog timers.</p> </li> <li> <p>Replication:  Critical data is copied across multiple devices or systems (e.g., in distributed systems). This way, even if a fault occurs in one part, other replicas maintain the system\u2019s integrity.</p> </li> <li> <p>Graceful Degradation:  If a fault occurs, the system may reduce performance or disable non-essential services instead of shutting down entirely, thus ensuring the most critical functions remain operational.</p> </li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ft-techniques","title":"FT Techniques:","text":"<ol> <li> <p>Hardware Fault Tolerance:</p> <ul> <li>RAID (Redundant Array of Independent Disks): Data is mirrored or striped across multiple hard drives to prevent data loss from disk failure.</li> <li>Dual Power Supplies: Servers often include multiple power supplies to prevent failure if one unit fails.</li> <li>Hot Swapping: Faulty components like disks or power units can be replaced without shutting down the system.</li> </ul> </li> <li> <p>Software Fault Tolerance:</p> <ul> <li>Checkpoints and Rollbacks: Systems can save checkpoints periodically, and if an error occurs, they revert to the last known good state.</li> <li>Replication in Distributed Systems: Critical services are duplicated across multiple servers to ensure that if one server fails, others take over.</li> </ul> </li> <li> <p>Network Fault Tolerance:</p> <ul> <li>Multiple Network Paths: Routing data over multiple paths ensures that if one link fails, another path is used.</li> <li>Load Balancers: They distribute network traffic across multiple servers or systems, ensuring no single point of failure.</li> </ul> </li> <li> <p>Error Detection and Recovery:</p> <ul> <li>Watchdog Timers: Monitor system processes and restart them if they hang.</li> <li>Checksums and Parity Checks: Verify data integrity and correct transmission errors.</li> </ul> </li> </ol>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ft-real-world-examples","title":"FT Real-World Examples","text":"<ul> <li> <p>Airplane Control Systems:  Modern aircraft use redundant flight control systems, so if one control unit fails, another takes over to ensure passenger safety.</p> </li> <li> <p>Nuclear Power Plants:  Fault tolerance is critical to ensure safe operations. Redundant sensors, control systems, and cooling systems prevent catastrophic failures.</p> </li> <li> <p>Financial Systems:  Banks and payment processing systems must tolerate faults to ensure that transactions are processed without downtime or data corruption.</p> </li> <li> <p>Cloud Computing Services:  Cloud providers like AWS or Google Cloud implement fault tolerance using distributed systems, replication, and redundant storage across multiple locations.</p> </li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ft-challenges","title":"FT Challenges","text":"<ul> <li> <p>Cost:  Building redundant systems is expensive, as it requires additional hardware, software, and management resources.</p> </li> <li> <p>Complexity:  Managing fault-tolerant systems is complex due to the need for real-time monitoring, synchronization, and failover testing.</p> </li> <li> <p>Performance Overhead:  Some fault tolerance techniques, like replication or checkpointing, can introduce performance bottlenecks.</p> </li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ft-in-contrast-to-resilience","title":"FT in Contrast to Resilience","text":"<ul> <li>Fault Tolerance focuses on preventing failures from disrupting operations, often through redundancy.</li> <li>Resilience is about recovering quickly from disruptions it accepts that some failures will occur but emphasizes rapid recovery.</li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ft-when-to-use","title":"FT When to Use ?","text":"<ul> <li>When no downtime or service interruptions are tolerated (e.g., mission-critical systems such as airplane controls, healthcare monitoring, financial transactions).</li> <li>Suitable for life-critical systems where failures could lead to catastrophic outcomes.</li> </ul>"},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#ha-vs-ft","title":"HA vs FT","text":"<p>High Availability (HA) and Fault Tolerance (FT) are two strategies aimed at keeping systems operational, but they approach this goal differently. Here's a detailed comparison:</p> <ul> <li>High Availability ensures systems have minimal downtime by using redundancy and fast recovery (e.g., failover systems).  </li> <li>Fault Tolerance goes a step further it ensures that the system keeps working without any noticeable disruption, even while faults are occurring. </li> </ul> <p>In other words, high availability aims to reduce downtime, whereas fault-tolerant systems aim for zero downtime, even during failures.</p> Aspect High Availability (HA) Fault Tolerance (FT) Definition Ensures minimal downtime by quickly switching to backup systems when a failure occurs. Ensures continuous operation even during failures, with no noticeable interruption. Goal Minimize downtime and ensure service is restored quickly. Eliminate downtime and maintain seamless operation during faults. Approach Uses redundant components and failover systems to switch operations when needed. Uses duplication of systems to ensure tasks are always mirrored on another system. Downtime Small amount of downtime during failover (milliseconds to minutes). No downtime; systems operate continuously, even during faults. Example Use Cases E-commerce websites (e.g., Amazon) that switch servers when one fails. Airplane control systems, which cannot afford any interruptions. Redundancy Type Active-Passive: Backup components are activated only when primary systems fail. Active-Active: All components are working simultaneously, and one continues if the other fails. Cost Less expensive since backup systems are not always active. More expensive due to constant replication and active systems running in parallel. Complexity Easier to implement and manage due to reliance on failover mechanisms. More complex, requiring real-time synchronization and parallel operation. Performance Impact Some performance hit during failover but minimal. Higher overhead, as multiple systems operate simultaneously. Use Case Example Cloud platforms (like AWS) use high availability to ensure that servers recover quickly after a failure. Nuclear power plants employ fault-tolerant systems to keep critical processes running with no interruptions. Failure Handling Handles component failures through redundancy and quick recovery mechanisms. Prevents failure from affecting the system by running identical processes or systems in parallel."},{"location":"techdives/DistrubutedConcepts/HighAvailabilityFaultTolerance/#summary","title":"Summary","text":"<p>In summary, high availability ensures that critical systems are always accessible with minimal interruptions. Organizations rely on HA strategies to meet customer expectations, protect revenue, and ensure business continuity, especially in industries where even a small amount of downtime can have serious consequences and fault tolerance is the ability of a system to keep operating without interruption despite experiencing faults or failures. It is crucial for mission-critical systems in industries like aviation, finance, and healthcare, where downtime or errors could lead to catastrophic outcomes.</p> <p>In essence, High Availability focuses on minimizing downtime by recovering quickly from failures, while Fault Tolerance eliminates downtime altogether by ensuring the system continues running seamlessly. HA is less costly and easier to implement, while FT is expensive and complex but essential for critical environments where even a few seconds of downtime are unacceptable.</p>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/","title":"Docker and Kubernetes","text":""},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#overview","title":"Overview","text":""},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#docker","title":"Docker","text":"<p>Docker is a platform that enables developers to build, package, and run applications in lightweight containers. It ensures applications are portable and can run consistently across different environments, from development to production.  </p> <p>Key Components</p> <ul> <li>Containers:  Encapsulate applications with all their dependencies, ensuring consistency across systems. Containers share the host OS kernel, making them more lightweight than traditional virtual machines.</li> <li>Images:  Immutable templates used to create containers, typically defined in a <code>Dockerfile</code>. Images are layered and reusable.</li> <li>Docker Compose:  A tool to define and manage multi-container Docker applications via a single YAML file, simplifying orchestration on a single machine.</li> </ul>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#kubernetes","title":"Kubernetes","text":"<p>Kubernetes (often abbreviated as K8s) is an open-source platform for automating the deployment, scaling, and management of containerized applications. It abstracts away the complexity of running containers at scale across multiple machines.</p> <p>Key Components</p> <ul> <li>Pods:  The smallest deployable units in Kubernetes. A Pod can host one or more tightly coupled containers.</li> <li>Services:  Define stable network endpoints for Pods, enabling communication between components in the cluster.</li> <li>Cluster:  A group of nodes managed by a control plane that runs applications as Pods across multiple machines for load balancing and reliability.</li> </ul>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#hierarchy-and-relationship","title":"Hierarchy and Relationship","text":""},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#docker-vs-kubernetes","title":"Docker vs Kubernetes","text":"<p>Docker focuses on building, packaging, and running containers. It handles application-level concerns whereas Kubernetes focuses on orchestrating, scaling, and managing containers across distributed environments.</p>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#how-they-work-together","title":"How they Work Together","text":"<ul> <li>Container Runtime: Kubernetes uses Docker as one of its container runtimes, though other options like containerd or CRI-O are available.</li> <li>Complementary Roles: Docker handles container creation, while Kubernetes ensures containers are deployed and managed across the entire cluster efficiently.</li> </ul>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#using-docker-with-kubernetes","title":"Using Docker with Kubernetes","text":"Steps <p>Create a Dockerfile for your application and build the image   Step-1: Build Docker Images<pre><code>docker build -t my-app:latest .\n</code></pre></p> <p>Store the image in a registry (e.g., Docker Hub)   Step-2: Push to Registry<pre><code>docker push my-app:latest\n</code></pre></p> <p>Use the built Docker image in a Kubernetes Deployment YAML file and apply it with:   Deploy on Kubernetes<pre><code>kubectl apply -f deployment.yaml\n</code></pre></p>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#4-creating-and-managing-docker-and-kubernetes-components-individually","title":"4. Creating and Managing Docker and Kubernetes Components Individually","text":""},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#creating-docker-components","title":"Creating Docker Components","text":"<ol> <li> <p>Install Docker:    Follow Docker\u2019s official installation guide for your operating system.</p> </li> <li> <p>Create a Dockerfile:    Example:    <pre><code>FROM python:3.9\nWORKDIR /app\nCOPY . .\nRUN pip install -r requirements.txt\nCMD [\"python\", \"app.py\"]\n</code></pre></p> </li> <li> <p>Build and Run Docker Containers:</p> </li> <li>Build Image:      <pre><code>docker build -t my-app:latest .\n</code></pre></li> <li> <p>Run Container:      <pre><code>docker run -d -p 5000:5000 my-app:latest\n</code></pre></p> </li> <li> <p>Use Docker Compose:</p> </li> <li>Define services in a <code>docker-compose.yml</code>:      <pre><code>version: '3.8'\nservices:\n  web:\n    image: my-app:latest\n    ports:\n      - \"5000:5000\"\n</code></pre></li> <li>Start services with:      <pre><code>docker-compose up\n</code></pre></li> </ol>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#creating-kubernetes-components","title":"Creating Kubernetes Components","text":"<ol> <li> <p>Install Kubernetes:    Use Minikube for local development or create a production cluster using cloud providers like GKE, AKS, or EKS.</p> </li> <li> <p>Define Kubernetes Resources:    Create YAML manifests for Deployments and Services.</p> </li> <li> <p>Deployment YAML:      <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n        - name: my-app\n          image: my-app:latest\n          ports:\n            - containerPort: 5000\n</code></pre></p> </li> <li> <p>Service YAML:      <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-app-service\nspec:\n  type: NodePort\n  ports:\n    - port: 5000\n      targetPort: 5000\n  selector:\n    app: my-app\n</code></pre></p> </li> <li> <p>Deploy to Kubernetes:    <pre><code>kubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n</code></pre></p> </li> </ol>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#5-deployment-scenarios","title":"5. Deployment Scenarios","text":""},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#single-machine-deployment","title":"Single Machine Deployment","text":"<ul> <li> <p>With Docker Compose:   Define services in <code>docker-compose.yml</code> and run:   <pre><code>docker-compose up\n</code></pre></p> </li> <li> <p>With Kubernetes (Using Minikube):  </p> </li> <li>Install Minikube and create a cluster.</li> <li>Apply your Kubernetes manifests with <code>kubectl</code>.</li> </ul>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#multiple-machines-deployment","title":"Multiple Machines Deployment","text":"<ul> <li>Using Docker Swarm:  </li> <li>Initialize the Swarm cluster: <pre><code>docker swarm init\n</code></pre></li> <li> <p>Use overlay networks for service communication across nodes.</p> </li> <li> <p>Using Kubernetes:  </p> </li> <li>Set up a Kubernetes cluster using cloud providers.</li> <li>Use Kubernetes services to enable seamless inter-pod communication.</li> </ul>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#6-communication-between-services","title":"6. Communication Between Services","text":"<ul> <li>Single Machine Communication:</li> <li>Docker Compose: Services communicate using their service names as hostnames.</li> <li> <p>Kubernetes: Pods use DNS names or Service endpoints to communicate.</p> </li> <li> <p>Multiple Machines Communication:</p> </li> <li>Docker Swarm: Overlay networks allow services on different nodes to interact.</li> <li>Kubernetes: The flat networking model enables Pods to communicate across nodes transparently.</li> </ul>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#7-key-differences-between-docker-compose-and-kubernetes","title":"7. Key Differences Between Docker Compose and Kubernetes","text":"Aspect Docker Compose Kubernetes Purpose Local development and testing Production orchestration Configuration Single <code>docker-compose.yml</code> file Multiple YAML files for resources Scaling Manual Automated scaling with <code>kubectl scale</code> High Availability Limited Built-in redundancy and self-healing Use Case Simple applications on one machine Complex workloads across clusters"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#8-additional-considerations","title":"8. Additional Considerations","text":"<ul> <li>Persistent Storage:</li> <li>Docker: Use Docker volumes to store persistent data.</li> <li> <p>Kubernetes: Use Persistent Volumes (PV) and Persistent Volume Claims (PVC).</p> </li> <li> <p>Monitoring and Logging:</p> </li> <li> <p>Use Prometheus and Grafana in Kubernetes for comprehensive monitoring.</p> </li> <li> <p>CI/CD Integration:</p> </li> <li>Integrate Docker and Kubernetes into pipelines using tools like Jenkins or GitLab CI for automated builds and deployments.</li> </ul>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#9-how-to-use-docker-compose-to-get-the-application-from-github-and-build-the-docker-image","title":"9. How to Use Docker Compose to Get the Application from GitHub and Build the Docker Image","text":""},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#getting-from-github-and-using-docker-compose-build-context","title":"Getting from Github and using Docker Compose Build Context","text":"<p>Docker Compose can also use the build context to pull code directly from GitHub when creating an image. Here\u2019s how:</p> <ol> <li>Create a <code>docker-compose.yml</code> with GitHub Repository as the Build Context:</li> </ol> <pre><code>version: '3.8'\nservices:\n  app:\n    build:\n      context: https://github.com/your-username/your-repo.git\n      dockerfile: Dockerfile\n    ports:\n      - \"5000:5000\"\n</code></pre> <ol> <li>Run Docker Compose to Build and Start the Container:</li> </ol> <pre><code>docker-compose up --build\n</code></pre> <p>Note: - This method works only if the GitHub repository is public. For private repositories, you\u2019ll need to provide authentication (e.g., via SSH keys or GitHub tokens). - Docker will pull the latest version from the specified GitHub repository and build the image based on the <code>Dockerfile</code> in the repository.</p>"},{"location":"techdives/DistrubutedSystems/DockerAndK8s/#10-silly-and-practical-questions-numbered","title":"10. Silly and Practical Questions (Numbered)","text":"<ol> <li> <p>Can I use a Docker Compose file with Kubernetes?    Not directly. Kubernetes doesn\u2019t understand Docker Compose syntax, but there are tools like Kompose that can convert Docker Compose files into Kubernetes YAML files.</p> </li> <li> <p>What happens if I try to run a Docker Compose file inside a Kubernetes cluster?    It won\u2019t work. Kubernetes will look at you confused (figuratively), because it expects YAML manifests with its own syntax, not a <code>docker-compose.yml</code>.</p> </li> <li> <p>Why do Kubernetes YAML files look scarier than Docker Compose files?    Kubernetes YAML files are more complex because they handle more advanced scenarios like scaling, networking, and rolling updates, which Docker Compose doesn\u2019t attempt to address.</p> </li> <li> <p>Do I need to uninstall Docker if I switch to Kubernetes?    Nope! Docker is still useful for building and testing images locally, even if you\u2019re deploying to Kubernetes. In fact, Kubernetes can use Docker as a container runtime.</p> </li> <li> <p>Will Docker containers fight with Kubernetes Pods if they run on the same machine?    Nope, they\u2019ll coexist peacefully. Docker containers and Kubernetes Pods can run side by side without conflict. They\u2019re friends, not rivals!</p> </li> <li> <p>Can I copy-paste my Docker Compose file into Kubernetes and hope it works?    Sorry, no shortcuts here. You need to convert the Compose file into Kubernetes resources, either manually or using tools like Kompose.</p> </li> <li> <p>Is Docker Compose faster than Kubernetes because it has fewer YAML files?    Yes, Docker Compose is faster to set up for local development because it\u2019s simpler. But for production-scale orchestration, Kubernetes is much more powerful.</p> </li> <li> <p>How do I know if my container is happy inside a Kubernetes Pod?    Check with this command:    <pre><code>kubectl get pods\n</code></pre>    If the status is <code>Running</code>, your container is content. If you see <code>CrashLoopBackOff</code>, it\u2019s definitely not happy!</p> </li> <li> <p>Can I use Kubernetes without the cloud, or will it complain?    You can use Minikube or kind (Kubernetes in Docker) to run Kubernetes locally on your machine. No cloud required.</p> </li> <li> <p>What\u2019s the difference between <code>docker-compose up</code> and <code>kubectl apply -f</code>?  </p> <ul> <li><code>docker-compose up</code>: Starts containers defined in a <code>docker-compose.yml</code> file.  </li> <li><code>kubectl apply -f</code>: Deploys resources (like Pods, Deployments) described in a Kubernetes YAML file to your cluster.</li> </ul> </li> <li> <p>Do I still need to learn Docker Swarm if I already know Kubernetes?     Not really. Docker Swarm is simpler but not as widely used in production as Kubernetes. Kubernetes has become the de facto standard.</p> </li> <li> <p>Can a single Pod run multiple Docker Compose services?     Yes! A Pod can run multiple containers, similar to how Docker Compose runs multiple services. However, in Kubernetes, these containers should be tightly coupled (e.g., sharing resources).</p> </li> <li> <p>If Docker Compose is easier, why do people torture themselves with Kubernetes?     Kubernetes offers features like scaling, self-healing, and load balancing. It\u2019s overkill for simple projects but essential for large, distributed applications.</p> </li> <li> <p>Is Kubernetes just a fancy way of saying, \u201cI don\u2019t want to use Docker Compose\u201d?     Not exactly. Docker Compose is great for local setups, while Kubernetes is a powerful orchestration tool for running applications across multiple nodes at scale.</p> </li> <li> <p>What\u2019s the difference between a Pod and a Container? Can I use the words interchangeably?     Not quite. A Pod is a wrapper that can contain one or more containers. Pods are the smallest deployable unit in Kubernetes, but a container is just an isolated environment for running applications.</p> </li> <li> <p>If a container crashes in Kubernetes, does Kubernetes get sad?     Nope! Kubernetes will restart the container automatically. That\u2019s part of its self-healing magic.</p> </li> <li> <p>Will my application break if I use a Docker image from 2015?     It might! Older images could have compatibility issues or security vulnerabilities. Use them only if you\u2019re sure they still meet your needs.</p> </li> <li> <p>Is Kubernetes allergic to Windows, or will it run happily there?     Kubernetes supports Windows nodes, but the experience is smoother with Linux. Most people deploy Kubernetes on Linux-based clusters.</p> </li> <li> <p>Can I use both Docker and Kubernetes at the same time? Or will it cause chaos?     Yes, you can use both. Build your containers with Docker, push them to a registry, and deploy them with Kubernetes. No chaos \u2013 just smooth workflows.</p> </li> <li> <p>Why can\u2019t Docker Compose just learn scaling and take over Kubernetes' job?     Docker Compose is intentionally lightweight and simple. Adding Kubernetes-like features would complicate it and defeat its original purpose.</p> </li> <li> <p>How much YAML is too much YAML?     If you start dreaming in YAML, it\u2019s probably too much. But seriously, Kubernetes relies heavily on YAML, so learning to manage it effectively is key.</p> </li> <li> <p>Can Kubernetes work without YAML files? (Please say yes!)     Unfortunately, no. YAML files are essential for defining resources in Kubernetes. You can use Helm charts to simplify it, but YAML is unavoidable.</p> </li> <li> <p>What happens if I forget to push my Docker image before deploying with Kubernetes?     Your deployment will fail because Kubernetes won\u2019t find the image in the registry. Always remember to push!</p> </li> <li> <p>Can I use <code>kubectl</code> commands on Docker containers?     Nope. <code>kubectl</code> is specifically for managing Kubernetes resources. Use <code>docker</code> commands for Docker containers.</p> </li> <li> <p>Is Kubernetes only for tech wizards, or can normal humans use it too?     Normal humans can use it too! The learning curve is steep, but with practice, anyone can master it.</p> </li> <li> <p>Do I need to sacrifice sleep to understand Kubernetes?     Maybe at first. But once you get the hang of it, Kubernetes will become your friend, and sleep will return.</p> </li> <li> <p>Can a Docker container tell the difference between running on Kubernetes and Docker Compose?     Nope! The container itself doesn\u2019t care where it\u2019s running. As long as it gets its dependencies and configuration, it\u2019ll happily run anywhere.</p> </li> <li> <p>Can I run two Docker Compose files on one machine?    Yes, use the <code>-p</code> option to specify different project names for each Compose file.</p> </li> <li> <p>Can services communicate across multiple machines?    Yes, with Docker Swarm or Kubernetes, services can communicate across machines using overlay networks or Kubernetes networking.</p> </li> <li> <p>Is Docker Compose suitable for production?    Not recommended for large-scale production. Use Kubernetes or Docker Swarm instead.</p> </li> <li> <p>How do I set up Kubernetes on a single machine?    Use Minikube to run a local Kubernetes cluster.</p> </li> <li> <p>What file formats are used by Docker and Kubernetes?    Docker uses <code>Dockerfile</code> and <code>docker-compose.yml</code>. Kubernetes uses YAML files for resources like Deployments and Services.</p> </li> </ol>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/","title":"ElasticSearch","text":"<p>Elasticsearch is a search engine based on Apache Lucene. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#elasticsearch-basics-and-fundamentals","title":"ElasticSearch Basics and Fundamentals","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#1-core-concepts","title":"1. Core Concepts:","text":"<p>Diving into Elasticsearch's core concepts is essential for understanding its architecture and functionality. </p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#11-documents-and-indices","title":"1.1 Documents and Indices","text":"<ul> <li>Document: A JSON object with fields representing data.<ul> <li>Example:    <pre><code>{\n  \"title\": \"Learning Elasticsearch\",\n  \"author\": \"John Doe\",\n  \"published_date\": \"2023-01-15\"\n}\n</code></pre></li> </ul> </li> <li>Index: A collection of documents, e.g., \"books\" index.<ul> <li>Creating an index example:    <pre><code>PUT /books\n</code></pre></li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#12-mapping-and-types","title":"1.2 Mapping and Types","text":"<ul> <li>Mapping: Defines field types and structure.<ul> <li>Example:    <pre><code>PUT /books/_mapping\n{\n  \"properties\": {\n    \"title\": { \"type\": \"text\" },\n    \"author\": { \"type\": \"keyword\" },\n    \"published_date\": { \"type\": \"date\" }\n  }\n}\n</code></pre></li> </ul> </li> <li>Type: No longer applicable as each index now supports only one type.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#13-shards-and-replicas","title":"1.3 Shards and Replicas","text":"<ul> <li>Shards: Elasticsearch divides indices into shards to scale horizontally.<ul> <li>Example: Creating an index with custom shards and replicas.    <pre><code>PUT /books\n{\n  \"settings\": {\n    \"number_of_shards\": 3,\n    \"number_of_replicas\": 1\n  }\n}\n</code></pre></li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#14-cluster-nodes-and-roles","title":"1.4 Cluster, Nodes, and Roles","text":"<ul> <li>Cluster: A named grouping of nodes.</li> <li>Nodes: Instances within a cluster, each assigned specific roles.<ul> <li>Master Node: Manages configurations and updates.</li> <li>Data Node: Manages data storage and processing.</li> <li>Client/Coordinator Node: Routes queries, doesn't store data.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#15-elasticsearch-api-actions-crud","title":"1.5 Elasticsearch API Actions (CRUD)","text":"<ul> <li>Indexing (Create/Update):      <pre><code>POST /books/_doc/1\n{\n  \"title\": \"Learning Elasticsearch\",\n  \"author\": \"John Doe\",\n  \"published_date\": \"2023-01-15\"\n}\n</code></pre></li> <li>Retrieving:      <pre><code>GET /books/_doc/1\n</code></pre></li> <li>Updating:      <pre><code>POST /books/_doc/1/_update\n{\n  \"doc\": { \"author\": \"Jane Doe\" }\n}\n</code></pre></li> <li>Deleting:      <pre><code>DELETE /books/_doc/1\n</code></pre></li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#summary-of-the-core-concepts","title":"Summary of the Core Concepts","text":"<ol> <li>Data is divided into documents, stored in indices, and distributed across shards.</li> <li>Nodes work together in a cluster, balancing the load for efficient querying and data redundancy.</li> </ol>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#2-inverted-index","title":"2. Inverted Index","text":"<p>An inverted index is a fundamental data structure in Elasticsearch and other search engines. It optimizes search efficiency by storing a mapping from terms (words) to their locations within documents. Let\u2019s break it down into key components and processes:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#21-core-structure-of-inverted-index","title":"2.1. Core Structure of Inverted Index","text":"<ul> <li>At its heart, an inverted index consists of two parts:<ul> <li>Terms: Each unique word or token in the text.</li> <li>Postings List: A list of documents that contain each term, often including positional data (like the term's location within each document).</li> </ul> </li> </ul> <p>For instance, if a dataset contains the documents:    - Doc 1: \u201cElasticsearch powers search\u201d    - Doc 2: \u201cSearch powers insights\u201d</p> <p>The inverted index would look like this:    <pre><code>\"Elasticsearch\" -&gt; [Doc 1]\n\"powers\" -&gt; [Doc 1, Doc 2]\n\"search\" -&gt; [Doc 1, Doc 2]\n\"insights\" -&gt; [Doc 2]\n</code></pre></p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#22-building-the-inverted-index","title":"2.2. Building the Inverted Index","text":"<p>The process involves several stages:    - Tokenization: Splitting text into words or tokens.    - Normalization: Making tokens consistent, like converting to lowercase.    - Stemming/Lemmatization (optional): Reducing words to their base or root forms.    - Indexing: Populating the index with terms and the corresponding document references.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#23-how-searches-work","title":"2.3. How Searches Work","text":"<p>When a user searches for a term, Elasticsearch retrieves the postings list from the inverted index, quickly locating documents containing that term. For multi-term queries, Elasticsearch can intersect postings lists, using logical operations (e.g., AND, OR) to combine or filter results.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#24-optimizations","title":"2.4. Optimizations","text":"<ul> <li>Frequency and Proximity: Stores additional data, like term frequency (number of times a term appears) and positions, which aids relevance scoring.</li> <li>BKD Trees: Elasticsearch uses BKD trees for optimized spatial and numeric queries, boosting search performance for structured and semi-structured data.</li> <li>Compression: Compresses data in the index to save memory and improve I/O efficiency, especially for large datasets.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#25-benefits","title":"2.5. Benefits","text":"<ul> <li>Speed: Inverted indices provide near-instant retrieval by mapping terms to documents directly.</li> <li>Efficiency: Reduced data retrieval time, especially for full-text searches and large datasets.</li> <li>Scalability: Easily scalable across distributed systems with sharding, enhancing parallel processing.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#summary-of-the-inverted-index","title":"Summary of the Inverted Index","text":"<p>Inverted indices are the foundation of Elasticsearch\u2019s speed and relevance in text search. This structure is tailored for high performance in full-text search scenarios, especially when complex queries and filtering are involved.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#3-analyzers","title":"3. Analyzers","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#31-what-is-an-analyzer","title":"3.1. What is an Analyzer?","text":"<ul> <li>An analyzer in Elasticsearch processes text data both at the time of indexing and during querying. It consists of a tokenizer and a series of token filters.</li> <li>The analyzer breaks down text into searchable units, enabling effective full-text searches by making text uniform and manageable.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#32-components-of-an-analyzer","title":"3.2. Components of an Analyzer","text":"<ul> <li>Tokenizer: The first step in analysis. A tokenizer splits text into individual tokens or words. For instance, the standard tokenizer splits based on whitespace, punctuation, etc.</li> <li>Filters: After tokenization, filters modify the tokens by:<ul> <li>Removing stop words (e.g., \"the,\" \"is\") to reduce noise.</li> <li>Lowercasing to maintain consistency.</li> <li>Stemming or lemmatization to reduce words to their root form, so \"running\" becomes \"run.\"</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#33-built-in-analyzers","title":"3.3. Built-in Analyzers","text":"<ul> <li>Standard Analyzer: Default analyzer, performs basic tokenization, lowercasing, and stop word filtering.</li> <li>Simple Analyzer: Splits text by non-letter characters and lowercases tokens.</li> <li>Whitespace Analyzer: Only splits text by whitespace without additional filtering.</li> <li>Custom Analyzer: You can create custom analyzers to specify a tokenizer and filters tailored to your data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#34-custom-analyzer-configuration","title":"3.4. Custom Analyzer Configuration","text":"<p>Creating a custom analyzer involves defining:    - A tokenizer (e.g., edge-ngram tokenizer for partial word matches).    - A list of token filters to process the tokens (e.g., synonym filters, ASCII folding for diacritical marks).</p> <p>Example configuration:    <pre><code>{\n  \"analysis\": {\n    \"analyzer\": {\n      \"custom_analyzer\": {\n        \"type\": \"custom\",\n        \"tokenizer\": \"whitespace\",\n        \"filter\": [\"lowercase\", \"stop\", \"synonym\"]\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#35-usage-during-indexing-and-querying","title":"3.5. Usage During Indexing and Querying","text":"<ul> <li>Indexing: When data is indexed, the analyzer processes the input text, stores the terms generated, and builds an inverted index.</li> <li>Querying: Analyzers also process the query text so that the terms match the indexed format, ensuring accurate search results.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#36-practical-applications-of-custom-analyzers","title":"3.6. Practical Applications of Custom Analyzers","text":"<ul> <li>Synonym Handling: Custom analyzers can include synonym filters to handle synonyms effectively during searches.</li> <li>Partial Matching: Edge-ngram tokenizers help with autocomplete and partial matching.</li> <li>Language-Specific Analyzers: Built-in language analyzers (e.g., <code>english</code>, <code>french</code>) handle language-specific tokenization and filtering.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#37-benefits-of-analyzers","title":"3.7. Benefits of Analyzers","text":"<ul> <li>Precision: They allow fine control over how text is processed.</li> <li>Performance: Proper use of analyzers can improve query performance by optimizing the text for search requirements.</li> <li>Relevance: They ensure better relevance scoring by normalizing input and query text, removing noise, and emphasizing meaningful terms.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#summary-of-analyzers","title":"Summary of Analyzers.","text":"<p>Analyzers transform raw text into optimized, searchable data, playing a critical role in making Elasticsearch searches accurate and efficient.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#4-elasticsearch-queries","title":"4. ElasticSearch Queries","text":"<p>In Elasticsearch, queries are central to retrieving data. They\u2019re categorized as leaf queries (operating on specific fields) and compound queries (combining multiple queries). Here's a deep dive into each type, with examples to illustrate their functionality:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#41-leaf-queries","title":"4.1 Leaf Queries","text":"<p>These are standalone, field-specific queries (like <code>term</code> and <code>match</code> above) that don\u2019t depend on other queries to function.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#411-match-queries-for-full-text-search","title":"4.1.1 Match Queries (for Full-Text Search)","text":"<ul> <li> <p>Match Query: Used for analyzing full-text fields, capable of handling fuzziness, synonyms, and relevance scoring.</p> <ul> <li>Example: To search for documents with \u201celastic search\u201d in the \"description\" field:    <pre><code>{\n  \"query\": {\n    \"match\": {\n      \"description\": \"elastic search\"\n    }\n  }\n}\n</code></pre></li> </ul> </li> <li> <p>Match Phrase Query: Requires terms to appear in the specified order, useful for exact phrase searches.</p> <ul> <li>Example: To search for the exact phrase \u201celastic search\u201d:    <pre><code>{\n  \"query\": {\n    \"match_phrase\": {\n      \"description\": \"elastic search\"\n    }\n  }\n}\n</code></pre></li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#412-term-queries-for-structured-data","title":"4.1.2. Term Queries (for Structured Data)","text":"<ul> <li>Term Query: Best for exact matches on keyword fields (IDs, tags, enums) without tokenization.<ul> <li>Example: To find documents where the \u201cstatus\u201d field is exactly \u201cactive\u201d:    <pre><code>{\n  \"query\": {\n    \"term\": {\n      \"status\": \"active\"\n    }\n  }\n}\n</code></pre></li> </ul> </li> <li>Terms Query: Allows searching for multiple exact values within a field.<ul> <li>Example: To find documents with statuses of either \"active\" or \"pending\":    <pre><code>{\n  \"query\": {\n    \"terms\": {\n      \"status\": [\"active\", \"pending\"]\n    }\n  }\n}\n</code></pre></li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#42-compound-queries","title":"4.2. Compound Queries","text":"<p>Compound queries allow for complex logic by combining multiple queries, enabling fine-grained control over query conditions and relevance.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#421-bool-query","title":"4.2.1. Bool Query","text":"<p>The most flexible compound query, allowing logic-based combinations:</p> <ul> <li> <p>Must Clause: The <code>must</code> clause ensures that all enclosed queries must match. Think of it as an \"AND\" operation.</p> <ul> <li>Example: This returns documents where both <code>\"title\"</code> contains \"Elasticsearch\" and <code>\"content\"</code> contains \"query\".     <pre><code>{\n    \"query\": {\n        \"bool\": {\n        \"must\": [\n            { \"match\": { \"title\": \"Elasticsearch\" } },\n            { \"match\": { \"content\": \"query\" } }\n        ]\n        }\n    }\n}\n</code></pre></li> </ul> </li> <li> <p>Should Clause: The <code>should</code> clause is a flexible OR operation. If any query in the <code>should</code> clause matches, the document is considered a match. Adding multiple <code>should</code> clauses increases relevance based on how many match.</p> <ul> <li>Example: In this example, documents with either \"search\" or \"indexing\" in the <code>tags</code> field are included.     <pre><code>{\n    \"query\": {\n        \"bool\": {\n        \"should\": [\n            { \"match\": { \"tags\": \"search\" } },\n            { \"match\": { \"tags\": \"indexing\" } }\n        ],\n        \"minimum_should_match\": 1\n        }\n    }\n}\n</code></pre></li> </ul> </li> <li> <p>Must Not Clause: The <code>must_not</code> clause excludes documents that match any query within it, similar to a \"NOT\" operation.</p> <ul> <li>Example: This query includes documents with \"Elasticsearch\" in the title but excludes those with \"archived\" status.     <pre><code>{\n    \"query\": {\n        \"bool\": {\n        \"must\": { \"match\": { \"title\": \"Elasticsearch\" } },\n        \"must_not\": { \"match\": { \"status\": \"archived\" } }\n        }\n    }\n}\n</code></pre></li> </ul> </li> <li> <p>Filter Clause: The <code>filter</code> clause narrows down the result set without affecting relevance scores. It\u2019s optimized for structured queries and often used to improve query performance.</p> <ul> <li>Example: This query matches documents with \"Elasticsearch\" in the title and filters to only those with \"published\" status.     <pre><code>{\n    \"query\": {\n        \"bool\": {\n        \"must\": { \"match\": { \"title\": \"Elasticsearch\" } },\n        \"filter\": { \"term\": { \"status\": \"published\" } }\n        }\n    }\n}\n</code></pre></li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#complex-boolean-query-example","title":"Complex Boolean Query Example","text":"<p>Combining multiple clauses:</p> <p><pre><code>{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        { \"match\": { \"title\": \"Elasticsearch\" } }\n      ],\n      \"should\": [\n        { \"match\": { \"category\": \"tutorial\" } },\n        { \"match\": { \"category\": \"guide\" } }\n      ],\n      \"must_not\": [\n        { \"term\": { \"status\": \"archived\" } }\n      ],\n      \"filter\": [\n        { \"range\": { \"publish_date\": { \"gte\": \"2023-01-01\" } } }\n      ]\n    }\n  }\n}\n</code></pre> This query retrieves documents with \"Elasticsearch\" in the title, optionally boosts relevance if the document is in \"tutorial\" or \"guide\" categories, excludes documents marked as \"archived,\" and only includes documents published after January 1, 2023.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#422-dis-max-query-disjunction-max","title":"4.2.2.  Dis Max Query (disjunction max):","text":"<p>Optimizes for the highest relevance score among multiple queries, often used when querying across similar fields with varied wording. - Example: Searching for the most relevant match between \u201ctitle\u201d and \u201cdescription\u201d fields:     <pre><code>{\n    \"query\": {\n        \"dis_max\": {\n            \"queries\": [\n                { \"match\": { \"title\": \"elastic search\" } },\n                { \"match\": { \"description\": \"elastic search\" } }\n            ]\n        }\n    }\n}\n</code></pre></p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#43-geo-queries","title":"4.3 Geo Queries","text":"<p>Elasticsearch provides several geo-specific queries for filtering and scoring documents based on geographic location:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#431-geo-bounding-box-query","title":"4.3.1 Geo Bounding Box Query","text":"<p>Defines a rectangular area by specifying two corner points (top-left and bottom-right). Documents with locations inside this box are matched.</p> <ul> <li>Example: Find documents within a bounding box.     <pre><code>{\n  \"query\": {\n    \"geo_bounding_box\": {\n      \"location\": {\n        \"top_left\": {\n          \"lat\": 40.73,\n          \"lon\": -74.1\n        },\n        \"bottom_right\": {\n          \"lat\": 40.01,\n          \"lon\": -71.12\n        }\n      }\n    }\n  }\n}\n</code></pre></li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#432-geo-distance-query","title":"4.3.2 Geo Distance Query","text":"<p>Finds documents within a certain distance from a point. Useful for proximity searches, like \"find stores within 10 miles.\"</p> <ul> <li>Example: Search within a 50 km radius.     <pre><code>{\n  \"query\": {\n    \"geo_distance\": {\n      \"distance\": \"50km\",\n      \"location\": {\n        \"lat\": 40.7128,\n        \"lon\": -74.0060\n      }\n    }\n  }\n}\n</code></pre></li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#433-geo-polygon-query","title":"4.3.3 Geo Polygon Query","text":"<p>Searches within a polygon defined by a series of latitude and longitude points, allowing for irregular area shapes.</p> <ul> <li>Example: Match locations within a polygon.     <pre><code>{\n  \"query\": {\n    \"geo_polygon\": {\n      \"location\": {\n        \"points\": [\n          { \"lat\": 40.73, \"lon\": -74.1 },\n          { \"lat\": 40.01, \"lon\": -71.12 },\n          { \"lat\": 39.73, \"lon\": -73.1 }\n        ]\n      }\n    }\n  }\n}\n</code></pre></li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#434-geo-shape-query","title":"4.3.4 Geo Shape Query","text":"<p>The <code>geo_shape</code> query allows for more complex spatial filtering, using pre-defined shapes like circles, polygons, or lines. This is often used with indexed geometries.</p> <ul> <li>Example: Search within a complex shape (circle or custom shape).     <pre><code>{\n  \"query\": {\n    \"geo_shape\": {\n      \"location\": {\n        \"shape\": {\n          \"type\": \"circle\",\n          \"coordinates\": [-74.1, 40.73],\n          \"radius\": \"1000m\"\n        },\n        \"relation\": \"within\"\n      }\n    }\n  }\n}\n</code></pre></li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#435-using-geo-filters-with-bool-queries","title":"4.3.5 Using Geo Filters with Bool Queries","text":"<p>Geo filters are often used in combination with other query types within <code>bool</code> queries, allowing flexible, location-based filtering along with other criteria.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#example-of-a-combined-geo-and-bool-query","title":"Example of a Combined Geo and Bool Query","text":"<p>Finds published documents within a specific area and filters out archived content.</p> <pre><code>{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        { \"term\": { \"status\": \"published\" } }\n      ],\n      \"filter\": {\n        \"geo_distance\": {\n          \"distance\": \"50km\",\n          \"location\": {\n            \"lat\": 40.7128,\n            \"lon\": -74.0060\n          }\n        }\n      },\n      \"must_not\": [\n        { \"term\": { \"status\": \"archived\" } }\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#summary-of-elastic-queries","title":"Summary of Elastic Queries","text":"<ul> <li>Match queries are ideal for full-text fields requiring analysis (e.g., descriptions).</li> <li>Term queries work well with keyword fields needing exact matches (e.g., IDs).</li> <li>Bool queries allow complex logic with filtering and relevance.</li> <li>Dis Max queries maximize relevance across similar fields.</li> <li>Geo Bounding Box for rectangular areas.</li> <li>Geo Distance for proximity.</li> <li>Geo Polygon for custom shapes.</li> <li>Geo Shape for complex spatial data.</li> </ul> <p>These queries, combined thoughtfully, make Elasticsearch highly adaptable to various search needs.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#5-aggregations","title":"5. Aggregations","text":"<p>Elasticsearch\u2019s aggregation framework is divided into metrics and bucket aggregations. Here\u2019s a deep dive into each, with subtypes and examples.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#51-metrics-aggregations","title":"5.1. Metrics Aggregations","text":"<p>These calculate values from field data, like sums or averages.</p> <ul> <li>Avg Aggregation: Computes the average for numeric fields.</li> <li> <p>Example: Calculate average price across documents.      <pre><code>{\n  \"aggs\": {\n    \"avg_price\": { \"avg\": { \"field\": \"price\" } }\n  }\n}\n</code></pre></p> </li> <li> <p>Sum Aggregation: Totals numeric field values.</p> </li> <li> <p>Example: Sum of all sales amounts.      <pre><code>{\n  \"aggs\": {\n    \"total_sales\": { \"sum\": { \"field\": \"amount\" } }\n  }\n}\n</code></pre></p> </li> <li> <p>Min/Max Aggregations: Find minimum or maximum field values.</p> </li> <li> <p>Example: Find the highest score.      <pre><code>{\n  \"aggs\": {\n    \"max_score\": { \"max\": { \"field\": \"score\" } }\n  }\n}\n</code></pre></p> </li> <li> <p>Stats Aggregation: Generates summary stats (min, max, avg, sum, count).</p> </li> <li> <p>Example: Summarize views across articles.      <pre><code>{\n  \"aggs\": {\n    \"article_views\": { \"stats\": { \"field\": \"views\" } }\n  }\n}\n</code></pre></p> </li> <li> <p>Cardinality Aggregation: Counts unique values.</p> </li> <li> <p>Example: Count unique users by ID.      <pre><code>{\n  \"aggs\": {\n    \"unique_users\": { \"cardinality\": { \"field\": \"user_id\" } }\n  }\n}\n</code></pre></p> </li> <li> <p>Percentiles/Percentile Ranks Aggregations: Show value distribution.</p> </li> <li>Example: Get 50<sup>th</sup>, 90<sup>th</sup>, and 99<sup>th</sup> percentiles for response times.      <pre><code>{\n  \"aggs\": {\n    \"response_percentiles\": {\n      \"percentiles\": { \"field\": \"response_time\", \"percents\": [50, 90, 99] }\n    }\n  }\n}\n</code></pre></li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#52-bucket-aggregations","title":"5.2. Bucket Aggregations","text":"<p>These create groups (buckets) of documents based on field values or criteria. Each bucket can contain documents matching conditions and may contain further sub-aggregations.</p> <ul> <li>Terms Aggregation: Groups documents by unique terms.</li> <li> <p>Example: Group documents by category.      <pre><code>{\n  \"aggs\": {\n    \"by_category\": { \"terms\": { \"field\": \"category\" } }\n  }\n}\n</code></pre></p> </li> <li> <p>Range Aggregation: Group documents within defined ranges.</p> </li> <li> <p>Example: Bucket users by age ranges.      <pre><code>{\n  \"aggs\": {\n    \"age_ranges\": {\n      \"range\": { \"field\": \"age\", \"ranges\": [{ \"to\": 20 }, { \"from\": 20, \"to\": 30 }, { \"from\": 30 }] }\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>Date Histogram: Buckets documents based on date intervals (e.g., daily, monthly).</p> </li> <li> <p>Example: Group events by month.      <pre><code>{\n  \"aggs\": {\n    \"monthly_events\": { \"date_histogram\": { \"field\": \"date\", \"calendar_interval\": \"month\" } }\n  }\n}\n</code></pre></p> </li> <li> <p>Histogram Aggregation: Creates buckets based on custom numeric ranges.</p> </li> <li> <p>Example: Histogram of item prices.      <pre><code>{\n  \"aggs\": {\n    \"price_histogram\": { \"histogram\": { \"field\": \"price\", \"interval\": 10 } }\n  }\n}\n</code></pre></p> </li> <li> <p>Filter Aggregation: Buckets documents matching a specific filter.</p> </li> <li> <p>Example: Filter for high-value orders.      <pre><code>{\n  \"aggs\": {\n    \"high_value_orders\": { \"filter\": { \"range\": { \"price\": { \"gt\": 100 } } } }\n  }\n}\n</code></pre></p> </li> <li> <p>Filters Aggregation: Allows multiple filter buckets in a single query.</p> </li> <li> <p>Example: Separate buckets for high and low prices.      <pre><code>{\n  \"aggs\": {\n    \"price_buckets\": {\n      \"filters\": {\n        \"filters\": {\n          \"expensive\": { \"range\": { \"price\": { \"gt\": 100 } } },\n          \"cheap\": { \"range\": { \"price\": { \"lt\": 50 } } }\n        }\n      }\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>Geohash Grid Aggregation: For geolocation-based bucketing, especially with maps.</p> </li> <li>Example: Group location data by geohash grid.      <pre><code>{\n  \"aggs\": {\n    \"geo_buckets\": { \"geohash_grid\": { \"field\": \"location\", \"precision\": 5 } }\n  }\n}\n</code></pre></li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#53-combining-aggregations","title":"5.3. Combining Aggregations","text":"<p>Each aggregation can nest other aggregations, allowing complex analysis structures.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#example-of-a-combined-aggregation","title":"Example of a Combined Aggregation","text":"<p>Calculate the average order amount by city and age range:</p> <pre><code>{\n  \"aggs\": {\n    \"by_city\": {\n      \"terms\": { \"field\": \"city\" },\n      \"aggs\": {\n        \"age_ranges\": {\n          \"range\": { \"field\": \"age\", \"ranges\": [{ \"to\": 20 }, { \"from\": 20, \"to\": 30 }, { \"from\": 30 }] },\n          \"aggs\": {\n            \"avg_order_amount\": { \"avg\": { \"field\": \"order_amount\" } }\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#summary-of-aggregations","title":"Summary of Aggregations","text":"<p>With these aggregations, Elasticsearch becomes a powerful analytics engine, enabling sophisticated data analysis directly within the index.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#6-sorting","title":"6. Sorting","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#61-basic-sorting","title":"6.1. Basic Sorting","text":"<ul> <li>By default, Elasticsearch sorts results by <code>_score</code> (relevance-based sorting).</li> <li>To sort by a specific field, use <code>sort</code> in the query.</li> </ul> <pre><code>{\n  \"sort\": [\n    { \"price\": { \"order\": \"asc\" } }\n  ],\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#62-field-based-sorting","title":"6.2. Field-based Sorting","text":"<ul> <li>Sortable fields should be of numeric, date, or keyword type (for text, use <code>keyword</code> fields).</li> <li>Example sorting by a date field:</li> </ul> <pre><code>{\n  \"sort\": [\n    { \"release_date\": { \"order\": \"desc\" } }\n  ],\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#63-multiple-sort-fields","title":"6.3. Multiple Sort Fields","text":"<ul> <li>Specify multiple sort criteria, with the first sort field taking precedence.</li> </ul> <pre><code>{\n  \"sort\": [\n    { \"price\": { \"order\": \"asc\" } },\n    { \"rating\": { \"order\": \"desc\" } }\n  ],\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#64-nested-sorting","title":"6.4. Nested Sorting","text":"<ul> <li>For nested documents (e.g., arrays of objects), use <code>nested</code> with a path to sort by nested fields.</li> </ul> <pre><code>{\n  \"sort\": [\n    {\n      \"products.price\": {\n        \"order\": \"asc\",\n        \"nested\": {\n          \"path\": \"products\",\n          \"filter\": { \"range\": { \"products.price\": { \"gt\": 10 } } }\n        }\n      }\n    }\n  ],\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#65-geolocation-sorting","title":"6.5. Geolocation Sorting","text":"<ul> <li>Use <code>geo_distance</code> to sort by proximity for <code>geo_point</code> fields.</li> </ul> <pre><code>{\n  \"sort\": [\n    {\n      \"_geo_distance\": {\n        \"location\": \"40.715, -73.988\",\n        \"order\": \"asc\",\n        \"unit\": \"km\"\n      }\n    }\n  ],\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#66-script-based-sorting","title":"6.6. Script-based Sorting","text":"<ul> <li>Script-based sorting allows custom logic using the <code>painless</code> scripting language.</li> </ul> <pre><code>{\n  \"sort\": {\n    \"_script\": {\n      \"type\": \"number\",\n      \"script\": {\n        \"source\": \"doc['price'].value * params.factor\",\n        \"params\": { \"factor\": 1.2 }\n      },\n      \"order\": \"desc\"\n    }\n  },\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#67-missing-values","title":"6.7. Missing Values","text":"<ul> <li>Specify handling for missing values with <code>missing</code>, setting them as the highest or lowest values.</li> </ul> <pre><code>{\n  \"sort\": [\n    { \"price\": { \"order\": \"asc\", \"missing\": \"_last\" } }\n  ],\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#68-sorting-in-aggregations","title":"6.8. Sorting in Aggregations","text":"<ul> <li>In aggregations, sort bucket aggregations by criteria, like by <code>count</code> or custom metrics.</li> </ul> <pre><code>{\n  \"aggs\": {\n    \"top_brands\": {\n      \"terms\": {\n        \"field\": \"brand.keyword\",\n        \"order\": { \"_count\": \"desc\" }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#7-relevance-scoring","title":"7. Relevance Scoring","text":"<p>Elasticsearch's relevance scoring is crucial for ranking documents based on their similarity to a query. Here\u2019s an in-depth look:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#71-scoring-mechanism-and-bm25-algorithm","title":"7.1. Scoring Mechanism and BM25 Algorithm","text":"<p>The BM25 (Best Matching 25) algorithm is Elasticsearch\u2019s default relevance scoring algorithm. BM25 improves upon traditional TF-IDF (Term Frequency-Inverse Document Frequency) by adjusting term frequency saturation and document length normalization, providing more nuanced relevance.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#core-components-of-bm25","title":"Core Components of BM25:","text":"<ul> <li>Term Frequency (TF): Counts how often a term appears in a document. Higher term frequency can increase relevance, but BM25 applies diminishing returns to avoid favoring very high counts excessively.</li> <li>Inverse Document Frequency (IDF): Rare terms across the entire dataset are given higher weight since they provide more unique information about a document.</li> <li>Document Length Normalization: BM25 penalizes longer documents, assuming shorter documents with the same term density are more relevant to the term.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#72-calculating-the-bm25-score","title":"7.2. Calculating the BM25 Score","text":"<p>The BM25 formula combines these components, with two main parameters:    - k1: Controls term frequency saturation (default around 1.2). Higher values give more influence to term frequency.    - b: Controls length normalization (default around 0.75). Higher values penalize longer documents more strongly.    - BM25 Alogirthm</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#73-understanding-scoring-in-elasticsearch-queries","title":"7.3. Understanding Scoring in Elasticsearch Queries","text":"<p>In Elasticsearch, relevance scores are generated by the \"match\" or \"multi_match\" queries. Each document receives a relevance score, and results are ranked based on these scores. You can inspect scores using the <code>\"explain\": true</code> parameter, which details each document\u2019s score and shows how BM25 factors contribute.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#example-query-with-relevance-scoring","title":"Example Query with Relevance Scoring:","text":"<p><pre><code>{\n  \"query\": {\n    \"match\": {\n      \"content\": {\n        \"query\": \"Elasticsearch relevance scoring\",\n        \"boost\": 1.5\n      }\n    }\n  },\n  \"explain\": true\n}\n</code></pre> This query searches for \"Elasticsearch relevance scoring\" in the <code>content</code> field. The <code>\"boost\"</code> parameter can emphasize this field for relevance, while <code>\"explain\": true</code> helps analyze the scoring breakdown.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#74-improving-relevance-with-advanced-techniques","title":"7.4. Improving Relevance with Advanced Techniques","text":"<ul> <li>Field Boosting: Increase relevance by weighting certain fields more heavily.</li> <li>Function Scoring: Custom scoring functions let you adjust scores based on field values, geographic distance, or date recency.</li> <li>Multi-Match Queries: Use multiple fields in a single query, like title and content, to balance relevance from multiple sources.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#75-practical-use-cases-for-bm25-in-elasticsearch","title":"7.5. Practical Use Cases for BM25 in Elasticsearch","text":"<ul> <li>E-commerce: Boost product names over descriptions to prioritize document structure.</li> <li>Content Recommendation: Add boosts to recent articles or content based on reader engagement.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#summary-of-relevance-score","title":"Summary of Relevance Score","text":"<p>Relevance scoring with BM25 is foundational to Elasticsearch\u2019s search quality, offering powerful controls for tuning results to your specific needs. </p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#8-pagination-and-cursors","title":"8. Pagination and Cursors","text":"<p>Pagination in Elasticsearch is essential for handling large result sets efficiently, as it prevents overwhelming the client and server. Elasticsearch offers different methods for pagination, each with specific use cases. Let's break down each method:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#81-basic-pagination-with-from-and-size","title":"8.1. Basic Pagination with <code>from</code> and <code>size</code>","text":"<ul> <li>The <code>from</code> parameter skips a set number of results, while <code>size</code> controls the number of results returned.</li> <li>Use Case: Simple pagination for small datasets.</li> <li>Limitations: Inefficient for large datasets because performance drops as <code>from</code> increases (since Elasticsearch has to load and sort through all documents before the specified offset).</li> </ul> <p>Example:    <pre><code>{\n  \"from\": 20,\n  \"size\": 10,\n  \"query\": { \"match_all\": {} }\n}\n</code></pre>    This retrieves results from the 21<sup>st</sup> to the 30<sup>th</sup> position.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#82-search-after-for-deep-pagination","title":"8.2. Search After for Deep Pagination","text":"<ul> <li>Purpose: Overcomes the limitations of <code>from</code> and <code>size</code> by using a cursor.</li> <li>Uses the <code>search_after</code> parameter to specify a unique field value (like a timestamp or an ID) from the last document of the previous page.</li> <li>Use Case: Suitable for deep pagination (e.g., pages far into the dataset).</li> <li>Limitations: Requires sorted queries; can\u2019t jump directly to a page.</li> </ul> <p>Example:    <pre><code>{\n  \"sort\": [ { \"timestamp\": \"asc\" }, { \"id\": \"asc\" } ],\n  \"size\": 10,\n  \"query\": { \"match_all\": {} },\n  \"search_after\": [1627489200, \"XYZ123\"] \n}\n</code></pre>    Here, <code>search_after</code> takes the values from the <code>timestamp</code> and <code>id</code> fields of the last document on the previous page, ensuring seamless navigation.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#83-scroll-api-for-bulk-data-retrieval","title":"8.3. Scroll API for Bulk Data Retrieval","text":"<ul> <li>Purpose: Efficiently handles large datasets by creating a consistent snapshot of the index to avoid changes affecting results.</li> <li>Use Case: Primarily used for exporting or processing the entire dataset rather than interactive pagination.</li> <li>Limitations: Not ideal for real-time paginated views; holds large segments in memory, which can strain resources.</li> </ul> <p>Example Workflow:    - First, initiate a scroll session:      <pre><code>{\n  \"size\": 100,\n  \"query\": { \"match_all\": {} },\n  \"scroll\": \"1m\" \n}\n</code></pre>    - Use the <code>_scroll_id</code> returned by the initial request to retrieve subsequent pages:      <pre><code>{\n  \"scroll\": \"1m\",\n  \"scroll_id\": \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAA...\"\n}\n</code></pre></p> <p>After each scroll request, repeat until the returned results are empty, which indicates that all documents have been retrieved.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#84-point-in-time-pit-for-real-time-pagination-with-consistency","title":"8.4. Point-in-Time (PIT) for Real-time Pagination with Consistency","text":"<ul> <li>Purpose: Offers a consistent snapshot of the index at a specific point, ensuring paginated results don\u2019t change between requests.</li> <li>Use Case: Good for real-time applications where data changes frequently but consistent pagination is necessary.</li> <li>Limitations: PIT sessions should be short-lived to avoid excessive resource use.</li> </ul> <p>Example Workflow:    - First, initiate a Point-in-Time session:      <pre><code>POST /index_name/_pit?keep_alive=1m\n</code></pre>    - Use the <code>pit_id</code> with <code>search_after</code> for paginated queries:      <pre><code>{\n  \"size\": 10,\n  \"query\": { \"match_all\": {} },\n  \"pit\": { \"id\": \"PIT_ID\", \"keep_alive\": \"1m\" },\n  \"sort\": [ { \"timestamp\": \"asc\" }, { \"id\": \"asc\" } ],\n  \"search_after\": [1627489200, \"XYZ123\"]\n}\n</code></pre>    - Close the PIT session when done:      <pre><code>DELETE /_pit\n</code></pre></p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#85-limitations-and-considerations","title":"8.5. Limitations and Considerations","text":"<ul> <li>Deep Pagination: As the dataset grows, deep pagination can become costly due to increased memory usage. Use <code>search_after</code> or PIT for deeper, efficient pagination.</li> <li>Real-time Constraints: The Scroll API locks data for consistency, so it\u2019s unsuitable for real-time applications. In contrast, <code>search_after</code> and PIT handle real-time updates better.</li> <li>Sort Requirements: Both <code>search_after</code> and PIT require sorted fields to maintain proper order across paginated results.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#86-summary-table-of-pagination-techniques","title":"8.6. Summary Table of Pagination Techniques","text":"Method Use Case Limitations Example Scenarios <code>from</code> &amp; <code>size</code> Simple pagination for small datasets Performance drop for large <code>from</code> values Basic search pages, small datasets <code>search_after</code> Deep pagination without <code>from</code> overhead Requires sorted fields, can\u2019t skip pages Infinite scrolling, data tables with lots of records Scroll API Bulk data export/processing High memory usage, no real-time consistency Data migration, report generation Point-in-Time Consistent real-time pagination Needs frequent re-creation to avoid memory issues Dashboards, applications requiring consistent views <p>Each method serves specific needs, balancing consistency, performance, and real-time capabilities. This setup allows Elasticsearch to handle vast and dynamic datasets while supporting efficient data retrieval.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#9-facets-and-filters","title":"9. Facets and Filters","text":"<p>Faceting creates summaries of data, useful for search result filtering, like categorizing search results by price or brand. Filters, on the other hand, optimize performance by narrowing down documents without affecting scoring.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#91-facets-aggregations","title":"9.1. Facets (Aggregations)","text":"<p>Faceting is a process in Elasticsearch that aggregates search results, providing structured summaries for complex queries. For example, if searching for \"laptops,\" facets can aggregate results by price range, brand, or processor type, allowing users to filter search results dynamically.</p> <ul> <li>Bucket Aggregations: Group documents by certain criteria, creating \u201cbuckets\u201d for each unique value. Common bucket types include:<ul> <li>Terms Aggregation: Summarizes by unique field values (e.g., brand names).</li> <li>Range Aggregation: Creates buckets for numerical ranges (e.g., price ranges).</li> <li>Date Histogram: Buckets documents by date intervals, great for tracking trends over time.</li> </ul> </li> <li>Metric Aggregations: Calculate statistical metrics like count, sum, average, min, and max on fields within buckets, useful for summaries.</li> <li>Multi-Level Aggregations: Nested aggregations allow more complex analyses, like a \"price by brand by location\" breakdown, giving a deeper multi-dimensional view of data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#92-filters-filtering-without-scoring-impact","title":"9.2. Filters: Filtering without Scoring Impact","text":"<p>Filters enable the narrowing of search results by criteria (e.g., price &lt; $500), improving query efficiency and bypassing relevance scoring. They\u2019re often used to pre-process data before a full-text search and work well with caches, resulting in faster query performance.</p> <ul> <li>Filtered Query: Using the <code>bool</code> query, filters can be applied to queries under <code>must</code> or <code>filter</code> clauses. Filters in <code>filter</code> clauses are cached and reusable, significantly boosting speed for repetitive filters (e.g., \"available items only\").</li> <li>Filter Types:<ul> <li>Term Filter: Exact match filtering for structured data, efficient for keywords or IDs.</li> <li>Range Filter: Sets criteria for numeric or date fields.</li> <li>Geo Filters: Filter based on geolocation, such as finding items within a radius.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#93-combining-facets-and-filters-in-search-applications","title":"9.3. Combining Facets and Filters in Search Applications","text":"<p>In complex search interfaces, facets allow users to drill down through categories, while filters further refine their selections without recalculating scores, ensuring responsive user experiences.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#94-sample-implementations","title":"9.4. Sample Implementations","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#941-creating-facets-aggregations","title":"9.4.1. Creating Facets (Aggregations)","text":"<p>To implement facets, you\u2019ll define bucket aggregations to group and categorize data. For instance, creating a facet for \"price range\" and \"brand\" in a search for laptops:</p> <pre><code>GET /products/_search\n{\n  \"query\": {\n    \"match\": { \"description\": \"laptop\" }\n  },\n  \"aggs\": {\n    \"price_ranges\": {\n      \"range\": {\n        \"field\": \"price\",\n        \"ranges\": [\n          { \"to\": 500 },\n          { \"from\": 500, \"to\": 1000 },\n          { \"from\": 1000 }\n        ]\n      }\n    },\n    \"brands\": {\n      \"terms\": { \"field\": \"brand.keyword\" }\n    }\n  }\n}\n</code></pre> <p>This example provides a breakdown of price ranges and a count of each brand, creating flexible filters users can click on to refine results.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#942-using-filters-for-optimized-performance","title":"9.4.2. Using Filters for Optimized Performance","text":"<p>Filters improve performance by narrowing results without scoring. Here\u2019s an example of using a <code>bool</code> query with a <code>filter</code> clause:</p> <pre><code>GET /products/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"match\": { \"description\": \"laptop\" }\n      },\n      \"filter\": [\n        { \"term\": { \"in_stock\": true } },\n        { \"range\": { \"price\": { \"lt\": 1000 } } }\n      ]\n    }\n  }\n}\n</code></pre> <p>In this query, <code>in_stock</code> and <code>price</code> filters optimize search results without affecting scoring.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#95-performance-optimization-techniques","title":"9.5. Performance Optimization Techniques","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#951-caching-filters","title":"9.5.1. Caching Filters","text":"<ul> <li>Filters are often cached by Elasticsearch, particularly if used frequently. Filtering with terms (exact matches) or numeric ranges benefits from caching, as it bypasses repeated computation and improves query speed.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#952-minimize-full-text-search-in-filters","title":"9.5.2. Minimize Full-Text Search in Filters","text":"<ul> <li>Full-text queries like <code>match</code> should only appear in scoring-related queries (e.g., <code>must</code>). Using <code>term</code> or <code>range</code> filters for precise values (like IDs, prices) reduces computational load.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#953-selective-use-of-aggregations","title":"9.5.3. Selective Use of Aggregations","text":"<ul> <li>Aggregations, especially nested ones, can be heavy on resources. Avoid overusing multi-level facets and restrict them to essential fields. For high-cardinality fields (e.g., many unique values), consider filtering or limiting the number of results.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#954-balancing-shard-count","title":"9.5.4. Balancing Shard Count","text":"<ul> <li>Elasticsearch distributes filters and aggregations across shards. While more shards can speed up complex aggregations, too many shards may lead to overhead. Test performance based on index size and query type to determine optimal shard counts.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#cluster-architecture","title":"Cluster Architecture","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#1-cluster-overview-and-node-responsibilities","title":"1. Cluster Overview and Node Responsibilities","text":"<p>Each node type in an Elasticsearch cluster has specialized roles that allow it to handle different aspects of indexing, searching, and managing data. Let's explore the node types in detail.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#11-master-node","title":"1.1. Master Node","text":"<p>The master node is the cluster\u2019s brain, responsible for the overall management and health of the cluster.</p> <ul> <li>Responsibilities:</li> <li>Cluster State Management: Tracks all nodes, indices, and shard locations, ensuring the cluster state is updated consistently.</li> <li>Index and Shard Management: Responsible for creating and deleting indices and for allocating and rebalancing shards. When new nodes are added or removed, the master node redistributes shards to maintain balance and high availability.</li> <li>Settings: Manages cluster-wide settings like shard allocation and replica counts.</li> <li> <p>Health Checks: Constantly checks the health of nodes, removing unresponsive nodes to maintain a stable cluster state.</p> </li> <li> <p>Consensus and Election Process:</p> </li> <li>Elasticsearch uses the Zen Discovery module to elect a master node in case the active master node goes down.</li> <li>Master-eligible nodes participate in elections, where the first node to form a majority connection with other nodes becomes the new master.</li> <li>Fault Tolerance: Having multiple master-eligible nodes increases fault tolerance but only one node actively acts as the master.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#12-data-node","title":"1.2. Data Node","text":"<p>Data nodes are the primary nodes for storing data, processing indexing operations, and executing search and aggregation requests.</p> <ul> <li>Responsibilities:</li> <li>Storage: Holds the actual data and handles shards (both primary and replicas).</li> <li>Indexing and Searching: Executes indexing requests to store new data and processes queries on local data.</li> <li>Shard Management: Each data node hosts a subset of the cluster\u2019s primary and replica shards, handling local searches and aggregations to ensure efficient processing.</li> <li>Scalability and Fault Tolerance: Data nodes scale horizontally, meaning adding more data nodes increases storage and processing capacity, and replication ensures fault tolerance.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#13-coordinating-node","title":"1.3. Coordinating Node","text":"<p>Also known as the client node, the coordinating node acts as a router for client requests, managing query distribution and response aggregation.</p> <ul> <li>Responsibilities:</li> <li>Routing: Breaks down client requests (both indexing and search requests) and forwards them to the relevant data nodes.</li> <li>Response Aggregation: Gathers responses from data nodes and consolidates results to produce a final response to the client.</li> <li>Load Distribution: Since coordinating nodes don\u2019t store data or shards, they focus on reducing load on data nodes, especially in large clusters.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#14-ingest-node","title":"1.4. Ingest Node","text":"<p>Ingest nodes preprocess data before it is indexed, often using ingest pipelines to transform and enrich data.</p> <ul> <li>Responsibilities:</li> <li>Data Transformation: Uses ingest pipelines to manipulate data (e.g., parsing logs, enriching data fields, removing sensitive information).</li> <li>Efficient Preprocessing: By processing data before indexing, ingest nodes reduce the need for expensive data transformations during searches.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#2-cluster-hierarchy-overview","title":"2. Cluster Hierarchy Overview","text":"<p>Each level in the cluster architecture plays a role in organizing and distributing data efficiently across nodes.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#21-cluster","title":"2.1. Cluster","text":"<ul> <li>The cluster is the top-level structure that contains multiple nodes, managing data storage and search operations as a unified system.</li> <li>Shard Allocation: The master node manages shard distribution across data nodes, balancing load and ensuring fault tolerance by replicating shards across nodes.</li> <li>Redundancy and Fault Tolerance: Replica shards provide redundancy, so if a data node goes down, the cluster remains available by rerouting requests to replica shards.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#22-index","title":"2.2. Index","text":"<ul> <li>An index in Elasticsearch is similar to a database table and is the logical grouping of documents that share the same structure.</li> <li>Sharding: Each index is divided into shards (subsets of data) to distribute storage and query load across the cluster.</li> <li>Mappings: Defines the structure of documents in the index, specifying field types and enabling indexing configurations like analyzers.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#23-shards","title":"2.3. Shards","text":"<ul> <li>Shards are the fundamental units of data distribution and parallelism in Elasticsearch.</li> <li>Lucene Index: Each shard is a full Lucene index, allowing it to process and store data independently.</li> <li>Primary and Replica Shards: Each index has a configurable number of primary shards (original data) and replica shards (copies for fault tolerance).</li> <li>Query Parallelism: When a search request is made, each shard executes the query in parallel, and results are merged by the coordinating node.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#24-segments","title":"2.4. Segments","text":"<ul> <li>Shards are broken down into smaller, immutable units called segments. Lucene writes data in segments for efficient searching.</li> <li>Immutable Nature: Once written, segments are not modified. Instead, new data or updates are added to new segments, and Lucene periodically merges segments to optimize performance.</li> <li>Segment Merging: Over time, Elasticsearch merges smaller segments into larger ones to reduce the number of segments, which improves search speed and reduces disk usage.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#25-documents","title":"2.5. Documents","text":"<ul> <li>Basic Data Units: Each document is a JSON object stored in segments, representing an individual record in the index.</li> <li>Field Mappings: The document structure is defined by field mappings, which specify data types and control how each field is indexed and searched.</li> <li>Dynamic and Static Mappings: Elasticsearch supports dynamic mapping for fields that don\u2019t have predefined mappings, although static mappings offer better control over data structure and indexing behavior.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#3-elasticsearch-request-flow-and-processing","title":"3. Elasticsearch Request Flow and Processing","text":"<p>To deeply understand how request flow and cluster operations work in Elasticsearch, let\u2019s walk through each stage of the process in detail:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#31-receiving-a-request","title":"3.1. Receiving a Request","text":"<p>When a client sends a request to Elasticsearch, it can be either a query (search request) or an indexing (write) request. Here\u2019s how this begins:</p> <ul> <li>The client connects to a coordinating node (any node can act as a coordinating node, even though it's sometimes a dedicated role).</li> <li>The coordinating node is responsible for breaking down the request and routing it to the appropriate data nodes.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#32-breaking-down-the-request","title":"3.2. Breaking Down the Request","text":"<ul> <li> <p>Identifying Relevant Shards and Nodes:</p> <ul> <li>For search queries, the coordinating node first identifies the index or indices involved in the query.</li> <li>Each index in Elasticsearch is divided into shards (logical units of data). The coordinating node identifies which shards are relevant to the query.</li> <li>It then routes the query to the nodes hosting those shards. Each shard exists as a primary shard and one or more replica shards for redundancy.</li> </ul> </li> <li> <p>Selecting Shards (Primary or Replica):</p> <ul> <li>For each shard, Elasticsearch will select either the primary shard or a replica shard, distributing the query load across replicas when possible to balance the workload.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#33-execution-at-shard-level","title":"3.3. Execution at Shard Level","text":"<p>At this stage, each shard executes the request locally. This process differs slightly between a search request and an indexing request.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#331-query-execution-search-requests","title":"3.3.1. Query Execution (Search Requests)","text":"<ul> <li> <p>Query Phase:</p> <ul> <li>In the query phase, each shard independently executes the query within its dataset.</li> <li>It retrieves document IDs, scores, and metadata of relevant documents and returns these results to the coordinating node. During this phase, only the necessary information (not the full document contents) is returned, optimizing efficiency.</li> </ul> </li> <li> <p>Fetch Phase:</p> <ul> <li>The coordinating node then initiates a fetch phase, retrieving the actual document data only for the top results.</li> <li>In this phase, the coordinating node consolidates document IDs and metadata, then requests the complete documents from the relevant shards. This two-phase process reduces network traffic, as full documents are only fetched after initial ranking.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#332-indexing-execution-write-requests","title":"3.3.2. Indexing Execution (Write Requests)","text":"<ul> <li> <p>Primary Shard Indexing:</p> <ul> <li>For indexing requests, the coordinating node forwards the request to the relevant primary shard.</li> <li>The primary shard performs the indexing operation first, ensuring data is written correctly.</li> </ul> </li> <li> <p>Replication to Replica Shards:</p> <ul> <li>Once the primary shard successfully indexes the document, it forwards the change to all replica shards.</li> <li>Each replica shard indexes the document in parallel, ensuring consistency across the cluster.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#34-response-consolidation","title":"3.4. Response Consolidation","text":"<p>After the query or indexing operation completes, the coordinating node consolidates the response:</p> <ul> <li> <p>Sorting and Ranking:</p> <ul> <li>For search queries, the coordinating node merges and ranks the results from all shards.</li> <li>Elasticsearch calculates a relevance score for each document based on factors like term frequency and inverse document frequency (TF-IDF) and applies BM25 scoring to determine document relevance.</li> <li>The coordinating node then orders the documents according to their scores and prepares the final list of top results.</li> </ul> </li> <li> <p>Returning the Response:</p> <ul> <li>Once consolidation and sorting are complete, the coordinating node sends the final response back to the client.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#35-indexing-flow-details","title":"3.5. Indexing Flow Details","text":"<p>The indexing flow includes several key mechanisms that ensure data consistency and durability:</p> <ul> <li> <p>Primary-Replica Synchronization:</p> <ul> <li>Every document write (index, delete, or update) is processed on the primary shard first.</li> <li>Once the primary shard successfully indexes or updates the document, it forwards the operation to all replica shards.</li> </ul> </li> <li> <p>Distributed Write-Ahead Log (WAL):</p> <ul> <li>To ensure durability, Elasticsearch writes every indexing operation to a write-ahead log (WAL) on both the primary and replica nodes.</li> <li>The WAL is essentially a transaction log that records all changes before committing them to Lucene\u2019s index structures.</li> <li>This ensures that even if a node crashes before committing changes, the transaction log allows for recovery to a consistent state.</li> </ul> </li> <li> <p>Commit Process:</p> <ul> <li>After a certain threshold of changes, Elasticsearch commits these changes to Lucene. This involves:</li> <li>Creating new segments in the Lucene index.</li> <li>Flushing the WAL and persisting the new segment data, making the data available for query.</li> <li>Committed changes are persistent and survive node restarts, while uncommitted changes are only present in the WAL.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#36-request-flow-and-cluster-operations-summary","title":"3.6. Request Flow and Cluster Operations Summary","text":"<p>To visualize this, here\u2019s a simplified flow of the entire process:</p> <ol> <li>Client Sends Request (Search or Index) \u2192 Coordinating Node Receives Request</li> <li>Coordinating Node Identifies Relevant Shards (and chooses primary or replica shards)</li> <li>Execution on Shards:</li> <li>Query Phase (Search):<ul> <li>Query executed on selected shards.</li> <li>Each shard returns IDs and scores of matching documents.</li> </ul> </li> <li>Indexing Phase (Write):<ul> <li>Document written to the primary shard.</li> <li>Changes forwarded to replica shards.</li> </ul> </li> <li>Fetch Phase (Search):</li> <li>Fetches full documents for the top results.</li> <li>Consolidation and Response:</li> <li>Coordinating node merges, ranks, and sorts results for search.</li> <li>Coordinating node confirms write operation on all replicas for indexing.</li> <li>Final Response Sent to Client</li> </ol>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#37-additional-considerations","title":"3.7. Additional Considerations","text":"<ul> <li>Fault Tolerance and High Availability:</li> <li>Shard Replicas: Multiple replicas ensure availability even if a primary shard goes down.</li> <li> <p>Node Failure Handling: If a node fails, Elasticsearch promotes a replica shard to primary, maintaining data consistency and availability.</p> </li> <li> <p>Cluster State Management:</p> </li> <li>The master node maintains the cluster state (e.g., index settings, shard allocation).</li> <li>This state is communicated to all nodes, so each node is aware of the cluster\u2019s configuration and the locations of shards.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#4-lucene-segments-and-index-structures","title":"4. Lucene, Segments, and Index Structures","text":"<p>To thoroughly understand Elasticsearch's storage and retrieval mechanisms, let\u2019s go deep into Lucene's segments, inverted index, and advanced data structures like BKD trees. Lucene, at its core, powers Elasticsearch, giving it the ability to handle and query massive datasets with impressive speed and efficiency.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#41-lucene-and-segments","title":"4.1. Lucene and Segments","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#411-what-is-a-segment","title":"4.1.1. What is a Segment?","text":"<p>A segment in Lucene is a self-contained, immutable collection of documents that forms a subset of a shard. Each segment is essentially a mini-index with its own data structures, including inverted indexes, stored fields, and other data structures to facilitate efficient searching and retrieval.</p> <ul> <li>Immutable Nature: Once created, a segment cannot be modified. Instead, when new documents are added, they go into new segments.</li> <li>Segment Lifecycle:</li> <li>New documents are first written to a memory buffer.</li> <li>Periodically, Lucene flushes this buffer, creating a new segment on disk.</li> <li>Older segments may be merged with newer ones through the segment merging process.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#412-segment-merging","title":"4.1.2 Segment Merging","text":"<ul> <li>Purpose: To control the number of segments and improve query performance by reducing the overhead of searching across numerous small segments.</li> <li>Process:</li> <li>When segments reach a certain size, Lucene automatically merges smaller segments into larger ones. This process involves re-indexing and rewriting the segments into one larger segment, discarding deleted documents along the way.</li> <li>Merging is a balancing act: it reduces the number of segments, improving search speed, but it also incurs I/O cost.</li> </ul> <p>Example:   - Imagine a shard with 100 small segments. Lucene might merge them into fewer, larger segments (say, 10 segments), consolidating their data and removing any \"marked as deleted\" documents.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#413-advantages-of-segments","title":"4.1.3. Advantages of Segments","text":"<ul> <li>Concurrency: Multiple segments can be queried simultaneously, allowing Elasticsearch to parallelize search operations across segments.</li> <li>Efficiency: Immutability of segments ensures that data doesn't have to be locked for reads, enhancing speed and consistency.</li> <li>Data Deletion: Since segments are immutable, deletions do not remove documents immediately; instead, they are marked for deletion. The segment merge process will then eliminate these \"deleted\" documents.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#42-lucenes-inverted-index","title":"4.2. Lucene\u2019s Inverted Index","text":"<p>The inverted index is Lucene\u2019s most fundamental data structure and is the backbone of Elasticsearch\u2019s fast full-text search capabilities.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#421-structure-of-an-inverted-index","title":"4.2.1. Structure of an Inverted Index","text":"<p>The inverted index allows quick lookups by mapping terms to postings lists (lists of documents containing each term).</p> <ul> <li>Terms: Unique words or tokens extracted from the text fields of documents.</li> <li>Postings Lists: Lists that store document identifiers for each term. Each entry in a postings list links to:</li> <li>Document ID</li> <li>Term frequency within the document (for relevance scoring)</li> <li>Position information (for phrase or proximity queries)</li> </ul> <p>Example:   - Suppose you index the text \"Elasticsearch is scalable search\". The inverted index might look like this:     <pre><code>Term          Documents\n------------------------\n\"Elasticsearch\" [1]\n\"is\"            [1, 2]\n\"scalable\"      [1, 3]\n\"search\"        [1]\n</code></pre></p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#422-advantages-of-inverted-index","title":"4.2.2. Advantages of Inverted Index","text":"<ul> <li>Fast Term Lookup: Quick access to documents containing specific terms, making it ideal for keyword-based and full-text searches.</li> <li>Optimized Relevance Scoring: Lucene uses term frequency-inverse document frequency (TF-IDF) and the BM25 algorithm to compute relevance scores, which improve search result accuracy.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#423-additional-optimizations-in-inverted-index","title":"4.2.3. Additional Optimizations in Inverted Index","text":"<ul> <li>Skip Lists: Lucene uses skip lists within postings lists to speed up queries, especially for large documents. Skip lists allow the query engine to \"skip over\" sections of the postings list, reducing unnecessary comparisons.</li> <li>Positions and Offsets: Positions allow for phrase queries (where terms must appear in sequence) and proximity queries (where terms must be within a certain distance from each other).</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#43-bkd-trees-and-doc-values","title":"4.3. BKD Trees and Doc Values","text":"<p>Apart from the inverted index, Lucene also uses specialized data structures to handle numeric and spatial data.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#431-bkd-trees","title":"4.3.1. BKD Trees","text":"<p>BKD Trees are used in Elasticsearch for indexing and querying numeric, date, and geospatial data, especially for high-cardinality fields (fields with a large number of unique values).</p> <ul> <li> <p>Splitting Mechanism: The tree splits data points along axes at each level, grouping data into smaller ranges or \"blocks.\" Each block holds a set of points within a defined range.</p> </li> <li> <p>Hierarchical Storage: At each level of the tree, the data is divided along a specific dimension, allowing efficient narrowing of the search space during queries.</p> </li> <li> </li> <li>Range Queries: For fields like timestamps, BKD trees allow fast filtering of documents within a date range.</li> <li>Geo-Distance Queries: For <code>geo_point</code> fields, Elasticsearch calculates distances within BKD trees, efficiently handling \"find near\" queries.</li> </ul> <p>Example:   - Suppose you have a field <code>geo_point</code> representing user locations. A BKD tree indexes these coordinates, allowing Elasticsearch to quickly retrieve points within a bounding box or radius without scanning all documents.</p> <ul> <li> </li> <li>Multi-dimensional Support: BKD trees can store high-dimensional points, making them versatile for multi-dimensional data like 3D spatial points or multiple numeric fields.</li> <li>Efficient Storage: Stores blocks instead of individual points, minimizing memory usage.</li> <li>Fast Range Queries: Since data is stored in a hierarchical fashion, range and bounding box queries can quickly navigate through the tree, skipping irrelevant nodes.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#structure-of-a-bkd-tree","title":"Structure of a BKD Tree","text":"<p>BKD trees are essentially a form of a k-d tree (k-dimensional tree), optimized for indexing and searching over multiple dimensions. Each dimension can represent a distinct numeric field (e.g., latitude, longitude, or timestamp).</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#using-bkd-trees-for-queries","title":"Using BKD Trees for Queries","text":"<p>BKD trees efficiently handle:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#advantages-of-bkd-trees","title":"Advantages of BKD Trees","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#432-doc-values","title":"4.3.2. Doc Values","text":"<p>Doc values enable efficient retrieval of field values for sorting, aggregation, and faceting. Instead of retrieving data from inverted indexes (which are optimized for search), doc values provide a columnar storage format that is ideal for analytical tasks.</p> <ul> <li>Columnar Format: Each field\u2019s values are stored together, allowing fast access to all values of a single field across multiple documents.</li> <li> <p>On-Disk Storage: Doc values are stored on disk rather than in memory, allowing efficient memory usage and enabling large datasets to be queried without excessive RAM usage.</p> </li> <li> </li> <li>Numeric Doc Values: For fields with numeric data types, enabling efficient sorting and numeric aggregation (e.g., <code>sum</code>, <code>avg</code>).</li> <li>Binary Doc Values: Used for keyword fields, allowing sorting and aggregation on text data.</li> <li> <p>Geo-point Doc Values: Specifically for geographic points, enabling geo-distance calculations.</p> </li> <li> </li> <li>Sorting: Sorting a results set by a field (e.g., price, timestamp) retrieves the field values directly from doc values.</li> <li>Aggregations: Aggregating data (e.g., calculating the average rating) can access all values of a field across documents, significantly speeding up aggregation operations.</li> <li>Faceting and Filtering: Fast access to field values in columnar format enables Elasticsearch to quickly generate facets and apply filters.</li> </ul> <p>Example:   - Sorting results by <code>price</code> in a large index of products:     - Doc values store <code>price</code> in a single column, which Elasticsearch reads to quickly sort documents without scanning each document individually.</p> <ul> <li> </li> <li> <p>Efficient Sorting and Aggregation: Since doc values are structured columnar data, they allow fast and memory-efficient operations.</p> </li> <li>Reduced Memory Usage: Storing doc values on disk and only loading them as needed minimizes memory consumption.</li> <li>Columnar Efficiency: Doc values allow Elasticsearch to quickly access specific field values across documents, ideal for analytical queries.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#structure-of-doc-values","title":"Structure of Doc Values","text":"Doc values store fields in column-oriented storage rather than row-oriented storage:"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#types-of-doc-values","title":"Types of Doc Values","text":"<p>Doc values are defined by the field type:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#using-doc-values-in-queries","title":"Using Doc Values in Queries","text":"<p>Doc values are essential for operations such as:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#advantages-of-doc-values","title":"Advantages of Doc Values","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#433-summary-of-lucene-data-structures-in-elasticsearch","title":"4.3.3. Summary of Lucene Data Structures in Elasticsearch","text":"Data Structure Purpose Use Cases Benefits Segments Immutable sub-indices within a shard All document storage Concurrent searches, immutability Inverted Index Maps terms to documents Full-text search Fast term lookups BKD Trees Indexes numeric and multidimensional data Geospatial, timestamp queries Efficient range queries Doc Values Columnar storage for fields Sorting, aggregations Optimized memory usage Point Data Types Indexes geographic points (latitude-longitude) Proximity, bounding box queries Fast geospatial indexing"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#44-advanced-data-structures-in-lucene","title":"4.4. Advanced Data Structures in Lucene","text":"<p>Let's dive into the point data types and spatial indexes used in Elasticsearch, especially focusing on how it handles geospatial data with <code>geo_point</code> fields. We\u2019ll look at how Quadtrees and R-trees work, their role in spatial indexing, and how they support geospatial queries such as bounding box and proximity searches.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#441-overview-of-spatial-data-in-elasticsearch","title":"4.4.1. Overview of Spatial Data in Elasticsearch","text":"<p>Elasticsearch supports geospatial data using the <code>geo_point</code> and <code>geo_shape</code> data types: - <code>geo_point</code>: Stores latitude-longitude pairs for points on a map and is primarily used for proximity searches (e.g., \u201cfind locations within 10km\u201d). - <code>geo_shape</code>: Used for more complex shapes, such as polygons or multipoints, and is suitable for defining geographical areas like cities or lakes.</p> <p>Geospatial queries include: - Bounding Box Queries: Searches for documents within a specific rectangle defined by coordinates. - Distance Queries: Searches for documents within a specified radius from a point. - Polygon Queries: Searches for documents within or intersecting with a complex polygonal area.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#442-quadtrees-and-r-trees-in-spatial-indexing","title":"4.4.2. Quadtrees and R-trees in Spatial Indexing","text":"<p>Quadtrees and R-trees are tree-based data structures that organize spatial data by dividing the space into hierarchical grids or regions, allowing efficient geospatial query processing.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#quadtrees","title":"Quadtrees","text":"<p>Quadtrees are hierarchical, 2-dimensional spatial indexes that recursively partition space into four quadrants or nodes, making them highly suitable for spatial data like latitude and longitude pairs.</p> <ul> <li>Structure:</li> <li>Each node (region of space) is divided into four sub-nodes or quadrants.</li> <li> <p>The depth of the tree (how many times it splits) depends on data density, as each quadrant only further divides if it contains more than a specified number of points.</p> </li> <li> <p>How it Works:</p> </li> <li>Indexing: Points are inserted into a quadrant based on their coordinates. If a quadrant exceeds the point threshold, it splits into four sub-quadrants, each storing a subset of the points.</li> <li> <p>Querying: For a bounding box or radius query, the algorithm quickly eliminates entire quadrants that fall outside the search area, only scanning relevant sub-quadrants, drastically reducing search space.</p> </li> <li> <p>Use Cases:</p> </li> <li>Bounding Box Queries: Quadtrees can quickly locate all points within a bounding box by navigating through relevant quadrants.</li> <li>Proximity Queries: Proximity searches are efficient since the tree can \u201czoom in\u201d to specific areas, ignoring distant quadrants.</li> </ul> <p>Example: Imagine we have a city map with thousands of restaurants, each represented as a point (latitude, longitude). - A quadtree organizes the map into quadrants based on restaurant density. Denser regions are divided further to create sub-quadrants. - To find restaurants within a specific neighborhood, the quadtree quickly filters out distant quadrants, only scanning nearby ones, significantly speeding up search.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#advantages-of-quadtrees","title":"Advantages of Quadtrees","text":"<ul> <li>Efficiency: The hierarchical division allows for fast data retrieval.</li> <li>Scalability: Quadtrees adapt to dense data by increasing tree depth, meaning they can efficiently handle varied densities in spatial data.</li> <li>Low Overhead: Quadtrees are relatively simple to implement and optimize for 2D spaces.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#r-trees","title":"R-trees","text":"<p>R-trees are another popular spatial data structure used to index multi-dimensional data (e.g., geographic shapes) by grouping nearby objects in bounding rectangles.</p> <ul> <li>Structure:</li> <li>An R-tree organizes data into bounding rectangles called nodes. Each node represents a group of data points or shapes.</li> <li>These bounding rectangles are arranged hierarchically: each parent node contains child nodes that represent sub-regions.</li> <li> <p>Each leaf node in an R-tree contains actual data points or bounding rectangles for objects (e.g., specific areas on a map).</p> </li> <li> <p>How it Works:</p> </li> <li>Indexing: When a shape or point is added, it\u2019s placed within a bounding rectangle in a leaf node. If the rectangle becomes too crowded, the node splits, creating new bounding rectangles for its child nodes.</li> <li> <p>Querying: For a search (e.g., finding locations within a radius), the R-tree filters bounding rectangles that don\u2019t intersect the search area, allowing the query to narrow down results without exhaustive scans.</p> </li> <li> <p>Use Cases:</p> </li> <li>Polygon Queries: R-trees are ideal for complex shapes like polygons, as each node can hold bounding rectangles for large or complex areas.</li> <li>Intersection or Overlap Queries: R-trees can efficiently check for intersections between shapes, such as finding areas that overlap with a given region.</li> </ul> <p>Example: Consider a map with various regions, like parks, lakes, and neighborhoods, each represented as a polygon. - An R-tree groups these polygons in bounding rectangles based on location. Polygons that are close to each other fall under the same rectangle. - When searching for parks within a 5km radius, the R-tree discards rectangles outside this range, only exploring relevant areas to find matching polygons.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#advantages-of-r-trees","title":"Advantages of R-trees","text":"<ul> <li>Supports Complex Shapes: Suitable for irregular or large polygons, making them valuable for indexing diverse geographic data.</li> <li>Efficient Spatial Queries: Ideal for intersection, containment, and nearest-neighbor queries.</li> <li>Adaptive Structure: R-trees adapt their structure based on the spatial layout of data, minimizing wasted space in the tree.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#443-lucenes-internal-use-of-quadtrees-and-r-trees","title":"4.4.3. Lucene's Internal Use of Quadtrees and R-trees","text":"<p>While Elasticsearch doesn\u2019t directly expose Quadtrees and R-trees as configurations, Lucene, its underlying search library, utilizes versions of these structures to handle spatial indexing efficiently.</p> <ul> <li>Quadtrees in Lucene:</li> <li>Used for simple geospatial data like points, where dividing space into quadrants improves search performance.</li> <li> <p>Points (like those in <code>geo_point</code> fields) benefit from this structure, as it speeds up bounding box queries and basic distance queries.</p> </li> <li> <p>R-trees in Lucene:</p> </li> <li>Suited for <code>geo_shape</code> fields and other complex shapes where simple 2D point indexing isn\u2019t enough.</li> <li>Helps manage and query large polygons, multi-points, and other shapes with irregular boundaries.</li> </ul> <p>Lucene optimizes these data structures to fit within its segment-based storage, allowing them to scale across multiple indices and segments, handling both large-scale geospatial queries and basic point-based distance queries.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#444-spatial-query-processing-in-elasticsearch","title":"4.4.4. Spatial Query Processing in Elasticsearch","text":"<p>Using these data structures, Elasticsearch processes spatial queries as follows:</p> <ol> <li>Bounding Box Query:</li> <li> <p>For a rectangular region, Elasticsearch leverages Quadtrees to restrict the search space to quadrants that intersect with the bounding box. Points or shapes within these quadrants are retrieved.</p> </li> <li> <p>Distance Query:</p> </li> <li> <p>For a proximity search (e.g., finding locations within 5km of a point), the Geo Distance Filter calculates distances from a central point and retrieves points from quadrants or nodes that fall within this radius.</p> </li> <li> <p>Polygon Query:</p> </li> <li>For complex polygons (e.g., \u201cfind all parks within a specific neighborhood\u201d), Elasticsearch uses an R-tree structure to store polygonal shapes in bounding rectangles, allowing fast intersection tests with other regions.</li> </ol>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#445-summary-table-of-spatial-data-structures-in-elasticsearch","title":"4.4.5. Summary Table of Spatial Data Structures in Elasticsearch","text":"Data Structure Purpose Use Cases Key Characteristics Quadtrees Efficient point indexing Bounding box, proximity searches Hierarchical grid of quadrants R-trees Complex shape and polygon indexing Intersection, overlap queries Bounding rectangles with hierarchical nodes BKD Trees Multi-dimensional numeric data Numeric and geo-distance filters Balanced k-d tree with blocks of data points"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#446-practical-applications-and-benefits","title":"4.4.6. Practical Applications and Benefits","text":"<p>These data structures optimize spatial queries in Elasticsearch, allowing it to handle diverse geospatial data efficiently. For example: - Bounding Box Queries are accelerated by Quadtrees, making them ideal for finding all points in a geographic area. - Distance Queries are optimized by both Quadtrees and BKD trees, allowing real-time retrieval of nearby points. - Polygon Queries are handled by R-trees, which efficiently manage irregular shapes and large polygons for accurate intersection checks.</p> <p>By integrating these structures into Lucene, Elasticsearch supports powerful geospatial capabilities across various applications, including mapping services, logistics, and location-based searches. </p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#45-how-lucenes-structures-fit-into-elasticsearchs-query-flow","title":"4.5. How Lucene's Structures Fit into Elasticsearch\u2019s Query Flow","text":"<ol> <li>Document Indexing:</li> <li> <p>As documents are indexed, Lucene tokenizes text fields, stores terms in the inverted index, and creates doc values for fields that require sorting or aggregation.</p> </li> <li> <p>Segment Creation:</p> </li> <li> <p>Documents are grouped into segments, with each segment containing its own inverted index, BKD trees, and doc values.</p> </li> <li> <p>Query Execution:</p> </li> <li>Term-based Queries: The inverted index quickly retrieves documents containing specific terms.</li> <li>Numeric or Geospatial Queries: BKD trees are used to retrieve documents within a certain numeric range or geographic area.</li> <li>Sorting and Aggregation: Doc values facilitate sorting by loading field values column-by-column rather than document-by-document.</li> </ol> <p>Lucene\u2019s well-designed structures\u2014segments, inverted indexes, and multidimensional BKD trees\u2014create the foundation for Elasticsearch\u2019s speed and scalability, enabling it to support complex queries and large datasets efficiently. </p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#5-visual-representation-of-cluster-architecture-hierarchy-flow","title":"5. Visual Representation of Cluster Architecture (Hierarchy Flow)","text":"<pre><code>Elasticsearch Cluster\n\u2514\u2500\u2500 Nodes\n    \u251c\u2500\u2500 Master Node\n    \u2502   \u251c\u2500\u2500 Manages cluster state\n    \u2502   \u2514\u2500\u2500 Handles shard allocation and rebalancing\n    \u251c\u2500\u2500 Data Node\n    \u2502   \u251c\u2500\u2500 Stores data and handles indexing/searching\n    \u2502   \u251c\u2500\u2500 Manages primary and replica shards\n    \u2502   \u2514\u2500\u2500 Processes local queries and aggregations\n    \u251c\u2500\u2500 Coordinating Node\n    \u2502   \u251c\u2500\u2500 Routes client requests to data nodes\n    \u2502   \u251c\u2500\u2500 Aggregates responses from data nodes\n    \u2502   \u2514\u2500\u2500 Sends final response to the client\n    \u2514\u2500\u2500 Ingest Node\n        \u251c\u2500\u2500 Processes and transforms data before indexing\n        \u2514\u2500\u2500 Enriches data with pipelines\n\nIndex\n\u2514\u2500\u2500 Shards (Primary and Replica)\n    \u2514\u2500\u2500 Lucene Index (Each shard is a Lucene index)\n        \u251c\u2500\u2500 Segments (Immutable data units in a shard)\n        \u2502    \u251c\u2500\u2500 Inverted Index\n        \u2502    \u251c\u2500\u2500 Doc Values\n        \u2502    \u2514\u2500\u2500 BKD Trees (for numeric &amp; geo fields)\n        \u2514\u2500\u2500 Documents (JSON objects representing data records)(within segments)\n</code></pre>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#6-summary-of-cluster-roles-and-data-flow","title":"6. Summary of Cluster Roles and Data Flow","text":"Component Description Responsibilities Cluster Top-level structure with multiple nodes Manages overall data distribution, availability, and search Master Node Brain of the cluster Handles cluster state, shard allocation, and fault tolerance Data Node Primary storage and processing node Stores data, handles indexing, querying, and replica management Coordinating Node Routes and aggregates client requests Routes requests to data nodes, aggregates responses, and sends back to clients Ingest Node Data transformation node Preprocesses data with pipelines, ideal for parsing and enrichment Index Logical grouping of documents Organizes data for efficient storage and querying Shard Distributed subset of index data Represents a Lucene index with primary and replica copies Segment Immutable unit in a shard Stores indexed data for fast read access Document Basic data unit in segments JSON object representing individual data records"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#thread-pools","title":"Thread Pools","text":"<p>Diving into Elasticsearch\u2019s search and other thread pools is crucial to understanding its performance and scalability. These pools are essential for managing various tasks like indexing, searching, and handling incoming requests. Let\u2019s go through these pools from end to end, covering configurations, management, and performance metrics to monitor.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#1-overview","title":"1. Overview","text":"<ul> <li>Elasticsearch uses multiple thread pools to handle different types of tasks.</li> <li>Each pool is configured with a specific number of threads, queue sizes, and rejection policies.</li> <li>Key pools include:<ul> <li>Search Pool: Handles search requests and related operations.</li> <li>Index Pool: Manages indexing requests, processing, and writing data.</li> <li>Get Pool: Manages document retrieval requests (like <code>GET</code> requests for individual documents).</li> <li>Bulk Pool: Handles bulk indexing operations.</li> <li>Management Pool: Manages internal maintenance tasks, like merging indices and refreshes.</li> <li>Snapshot Pool: Handles operations related to creating and restoring snapshots.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#2-detailed-breakdown-of-key-pools","title":"2. Detailed Breakdown of Key Pools","text":"<p>Here\u2019s a closer look at each pool, along with common configurations and considerations:</p> <ul> <li> <p>Search Pool</p> <ul> <li>Purpose: Processes search queries, sorting, aggregations, and other search-related tasks.</li> <li>Configuration: </li> <li><code>threads</code>: Generally calculated based on available CPU cores. It can be configured as <code># of processors * 3</code>.</li> <li><code>queue_size</code>: Defines the maximum number of requests that can be queued before rejecting new ones. Default is <code>1000</code>.</li> <li>Tuning Tips: Increase <code>queue_size</code> if you experience high query load, but monitor memory use carefully to avoid <code>OutOfMemory</code> errors.</li> <li>Metrics to Monitor:</li> <li><code>search_pool.active</code>: Shows active threads handling search requests.</li> <li><code>search_pool.queue</code>: Tracks pending search requests.</li> <li><code>search_pool.rejected</code>: Indicates rejected requests due to an overloaded pool.</li> </ul> </li> <li> <p>Index Pool</p> <ul> <li>Purpose: Handles indexing requests to add or update documents.</li> <li>Configuration:</li> <li><code>threads</code>: Typically set to the number of processors.</li> <li><code>queue_size</code>: Default is <code>200</code>. If your indexing rate is high, you may need to increase this.</li> <li>Tuning Tips: Optimize for high throughput if you\u2019re indexing frequently, but monitor for increased latency.</li> <li>Metrics to Monitor:</li> <li><code>index_pool.active</code>: Active threads indexing data.</li> <li><code>index_pool.queue</code>: Number of indexing requests waiting in the queue.</li> <li><code>index_pool.rejected</code>: Tracks rejected indexing requests.</li> </ul> </li> <li> <p>Get Pool</p> <ul> <li>Purpose: Manages retrieval requests like fetching individual documents.</li> <li>Configuration:</li> <li><code>threads</code>: Tied to the number of processors, generally around <code># of processors * 2</code>.</li> <li><code>queue_size</code>: Default is <code>1000</code>.</li> <li>Metrics to Monitor:</li> <li><code>get_pool.active</code>: Active threads processing <code>GET</code> requests.</li> <li><code>get_pool.queue</code>: Queued retrieval requests.</li> <li><code>get_pool.rejected</code>: Indicates if any requests are being rejected.</li> </ul> </li> <li> <p>Bulk Pool</p> <ul> <li>Purpose: Optimizes bulk indexing operations, commonly used for high-throughput data ingestion.</li> <li>Configuration:</li> <li><code>threads</code>: Usually set as <code># of processors * 2</code>.</li> <li><code>queue_size</code>: Often set at <code>50</code> to limit memory usage.</li> <li>Metrics to Monitor:</li> <li><code>bulk_pool.active</code>: Active threads handling bulk operations.</li> <li><code>bulk_pool.queue</code>: Queued bulk requests.</li> <li><code>bulk_pool.rejected</code>: Shows if the bulk pool is rejecting requests due to overload.</li> </ul> </li> <li> <p>Management Pool</p> <ul> <li>Purpose: Manages background tasks like index merging and cleanup operations.</li> <li>Configuration:</li> <li>Configured with <code>1</code> to <code>5</code> threads as these tasks are not frequent.</li> <li>Metrics to Monitor:</li> <li><code>management_pool.active</code>: Active management threads.</li> <li><code>management_pool.queue</code>: Queued management tasks.</li> <li>Tip: Monitor this to ensure background tasks aren\u2019t blocking other resources.</li> </ul> </li> <li> <p>Snapshot Pool</p> <ul> <li>Purpose: Handles backup and snapshot-related tasks, essential for data recovery and backups.</li> <li>Configuration:</li> <li>Configured with a low thread count (1 or 2).</li> <li>Metrics to Monitor:</li> <li><code>snapshot_pool.active</code>: Active threads handling snapshots.</li> <li><code>snapshot_pool.queue</code>: Queued snapshot operations.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#3-configuring-and-tuning-thread-pools","title":"3. Configuring and Tuning Thread Pools","text":"<ul> <li>Heap Size: Ensure your heap size is appropriate for the load. Elasticsearch requires sufficient memory to handle pool tasks without bottlenecks.</li> <li>CPU Allocation: Configure your server's CPU allocation based on thread pool demand. Pools that handle intensive operations, like search and indexing, benefit from additional CPU resources.</li> <li>Queue Size and Rejection Policies:<ul> <li>Increase queue size if you see a consistent rise in queued tasks, but watch for higher memory usage.</li> <li>Rejection policies control what happens when a queue is full; the default policy discards excess requests, but this can be customized if needed.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#4-monitoring-metrics-for-thread-pools","title":"4. Monitoring Metrics for Thread Pools","text":"<ul> <li>Cluster Health and Node Stats: Regularly monitor cluster health metrics for thread pool performance, looking for bottlenecks or rejected tasks.</li> <li>Node-level Monitoring: Elasticsearch provides detailed metrics per node. Monitoring <code>node_stats.thread_pool.*</code> via monitoring tools (like Kibana or Prometheus) helps assess each pool's workload.</li> <li>Typical Metrics:<ul> <li><code>active</code>: Indicates active threads. High values suggest a busy node.</li> <li><code>queue</code>: Shows queued tasks. A consistent rise may indicate that the pool size needs tuning.</li> <li><code>rejected</code>: Rejected tasks are a clear sign of bottlenecks.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#5-example-scenarios-and-best-practices","title":"5. Example Scenarios and Best Practices","text":"<ul> <li>High Search Load: If the search pool is frequently rejecting requests, consider increasing CPU allocation, thread count, or queue size.</li> <li>High Indexing Load: For frequent data ingestion, optimize the bulk and index pools. Consider using the bulk API with a balanced queue size and monitor memory.</li> <li>Snapshot Operations: Schedule snapshots during off-peak hours to reduce the impact on performance, as snapshot operations consume significant I/O.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#6-summary-table-of-pools","title":"6. Summary Table of Pools","text":"Thread Pool Purpose Default Threads Default Queue Size Key Metrics Tuning Tips Search Pool Processes search queries, aggregations <code># of processors * 3</code> 1000 <code>search_pool.active</code>, <code>search_pool.queue</code>, <code>search_pool.rejected</code> Increase <code>queue_size</code> if many queries are queued; monitor memory usage to prevent <code>OutOfMemory</code> issues. Index Pool Handles indexing requests for documents <code># of processors</code> 200 <code>index_pool.active</code>, <code>index_pool.queue</code>, <code>index_pool.rejected</code> For high indexing rates, increase queue size and thread count as necessary. Get Pool Retrieves individual documents <code># of processors * 2</code> 1000 <code>get_pool.active</code>, <code>get_pool.queue</code>, <code>get_pool.rejected</code> Increase <code>queue_size</code> if retrieval requests are high; monitor latency and resource usage. Bulk Pool Processes bulk indexing operations <code># of processors * 2</code> 50 <code>bulk_pool.active</code>, <code>bulk_pool.queue</code>, <code>bulk_pool.rejected</code> Keep <code>queue_size</code> modest to limit memory use; monitor latency during high bulk loads. Management Pool Manages maintenance tasks like merges 1\u20135 5 <code>management_pool.active</code>, <code>management_pool.queue</code> Generally low usage; monitor only if <code>queue</code> is frequently non-empty, indicating background task delays. Snapshot Pool Handles snapshot creation and restoration 1\u20132 5 <code>snapshot_pool.active</code>, <code>snapshot_pool.queue</code> Schedule snapshots during low-activity periods; adjust resources if snapshots interfere with other tasks. <p>These pools are essential to optimizing Elasticsearch\u2019s handling of diverse workloads. Monitoring and adjusting each pool based on your workload ensures better performance and resource management across the Elasticsearch cluster.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#caching","title":"Caching","text":"<p>In Elasticsearch, caching plays a vital role in speeding up queries by storing frequently accessed data at various levels, minimizing I/O operations and improving response times. Here\u2019s a detailed, end-to-end look at caching in Elasticsearch, from the lowest level to the highest, covering each caching mechanism and its role.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#1-types-of-caches-in-elasticsearch","title":"1. Types of Caches in Elasticsearch","text":"<p>There are several caching mechanisms in Elasticsearch, each working at a different level:</p> <ul> <li>Filesystem Cache (OS-level)</li> <li>Shard-level Cache<ul> <li>Field Data Cache</li> <li>Query Cache</li> <li>Request Cache</li> </ul> </li> <li>Node-level Cache<ul> <li>Segment Cache</li> <li>Indices Cache</li> </ul> </li> </ul> <p>Each of these caches serves a specific purpose and optimizes a different aspect of query processing.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#2-filesystem-cache-os-level","title":"2. Filesystem Cache (OS-level)","text":"<ul> <li>Location: Managed by the operating system (OS) outside Elasticsearch.</li> <li>Purpose: The OS-level filesystem cache holds frequently accessed files and segments in memory, reducing the need for repeated disk access.</li> <li>How it Works: Elasticsearch relies on the OS filesystem cache to store files like index segments, which can be memory-mapped to avoid reading from disk. The OS determines which files to cache based on access patterns.</li> <li>Optimization Tips: Ensure that sufficient system memory is available for filesystem caching, as Elasticsearch performs best when a large portion of indices can be cached at this level.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#3-shard-level-cache","title":"3. Shard-level Cache","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#31-field-data-cache","title":"3.1. Field Data Cache","text":"<ul> <li>Purpose: Speeds up operations that require field data, like sorting and aggregations, especially on text fields with <code>keyword</code> or <code>numeric</code> types.</li> <li>How it Works: When a field is accessed for sorting or aggregations, Elasticsearch loads the field data into memory as a field data cache. Field data caching is costly in terms of memory.</li> <li>Eviction Policy: Field data cache is held in memory, and it\u2019s evicted based on the <code>indices.fielddata.cache.size</code> setting. Default eviction strategy is based on the Least Recently Used (LRU) policy.</li> <li>Metrics to Monitor:<ul> <li><code>fielddata.memory_size</code>: Shows the amount of memory used by field data.</li> <li><code>fielddata.evictions</code>: Tracks the number of evictions, which can indicate if your cache size is too small.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#32-query-cache","title":"3.2. Query Cache","text":"<ul> <li>Purpose: Caches the results of frequently used queries to reduce re-execution. Especially useful for filters and term-level queries.</li> <li>How it Works: When the same query is run multiple times, Elasticsearch caches the results at the shard level, so it doesn\u2019t have to re-run the same logic.</li> <li>Query Types Cached: Primarily caches filters like <code>term</code> queries and <code>range</code> queries, but does not cache full-text queries as they are more complex and vary widely.</li> <li>Eviction Policy: LRU-based. Controlled by the <code>indices.queries.cache.size</code> setting (default is 10% of the heap).</li> <li>Metrics to Monitor:<ul> <li><code>query_cache.memory_size</code>: Memory occupied by the query cache.</li> <li><code>query_cache.evictions</code>: Counts the number of evictions due to cache full.</li> <li><code>query_cache.hit_count</code> and <code>query_cache.miss_count</code>: Useful for determining cache effectiveness.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#33-request-cache","title":"3.3. Request Cache","text":"<ul> <li>Purpose: Optimizes entire search requests that involve aggregations and aren\u2019t dependent on recent data changes.</li> <li>How it Works: Unlike the query cache, which stores results of individual query segments, the request cache stores results of entire search requests. It's effective for costly aggregation queries on static data.</li> <li>Conditions: Only applies to requests marked with <code>request_cache=true</code> and doesn\u2019t cache when <code>track_total_hits</code> is enabled.</li> <li>Eviction Policy: Configurable per index with <code>index.requests.cache.enable</code> (enabled by default). Also LRU-based.</li> <li>Metrics to Monitor:<ul> <li><code>request_cache.memory_size</code>: Shows the memory consumed by the request cache.</li> <li><code>request_cache.evictions</code>: Tracks evictions in the request cache.</li> <li><code>request_cache.hit_count</code> and <code>request_cache.miss_count</code>: Indicates request cache hit ratio.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#4-node-level-cache","title":"4. Node-level Cache","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#41-segment-cache","title":"4.1. Segment Cache","text":"<ul> <li>Purpose: Manages Lucene\u2019s in-memory structures, like field terms, postings, and dictionaries, which are essential for indexing and search operations.</li> <li>How it Works: Lucene, the underlying library in Elasticsearch, caches segments of the index in memory to allow for faster retrieval of terms, term frequencies, and position information.</li> <li>Eviction Policy: Handled by Lucene based on access frequency and memory limits. It\u2019s self-managed but benefits from larger heap sizes.</li> <li>Metrics to Monitor:<ul> <li><code>segment.memory_in_bytes</code>: Memory used for cached segments.</li> <li><code>segments.count</code>: Number of segments in the index.</li> </ul> </li> <li>Optimization Tips: Reduce segment merging frequency if memory is limited, but note that a higher number of segments can reduce performance.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#42-indices-cache","title":"4.2 Indices Cache","text":"<ul> <li>Purpose: Stores certain metadata for all indices within the cluster to speed up operations that retrieve or refresh metadata.</li> <li>How it Works: Caches index mappings and settings to avoid repeatedly loading them from the disk, enabling faster index and shard management.</li> <li>Eviction Policy: LRU-based, with cache size managed by the heap space available.</li> <li>Metrics to Monitor: <code>indices.memory</code> and <code>indices.evictions</code> to track the memory usage and evictions for index metadata.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#5-cache-tuning-and-best-practices","title":"5. Cache Tuning and Best Practices","text":"<ul> <li>Heap Size and Garbage Collection (GC): Elasticsearch caches are memory-intensive, so allocate sufficient heap space. Optimal heap size is typically 50% of physical memory, up to 32GB.</li> <li>Cache Sizes: Configure cache sizes based on your workload. If queries are complex, increase <code>query_cache</code> and <code>request_cache</code>. For frequent aggregations, prioritize <code>field data cache</code>.</li> <li>Monitoring and Adjustment: Regularly monitor cache-related metrics. High eviction rates or memory pressure indicate that cache sizes should be increased.</li> <li>Use <code>fscache</code>: The filesystem cache is essential, so configure sufficient memory for the OS to hold index files and segments, avoiding excessive I/O operations.</li> <li>Selective Caching: For frequently accessed static data, explicitly enable request and query caching by setting <code>request_cache=true</code> in your queries or adjusting cache policies at the index level.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#6-summary-table-of-caching-mechanisms","title":"6. Summary Table of Caching Mechanisms","text":"Cache Type Level Purpose Eviction Policy Key Metrics Tuning Tips Filesystem Cache OS Stores files and segments in OS memory Managed by OS N/A Ensure ample OS memory for larger index caching Field Data Cache Shard-level Caches field data for aggregations and sorting LRU-based, configurable <code>fielddata.memory_size</code>, <code>fielddata.evictions</code> Increase size for high aggregation requirements Query Cache Shard-level Caches individual filter query results LRU-based, configurable <code>query_cache.memory_size</code>, <code>query_cache.evictions</code>, <code>query_cache.hit_count</code>, <code>query_cache.miss_count</code> Monitor hit/miss ratios to determine effectiveness Request Cache Shard-level Caches entire search request results LRU-based, per-index <code>request_cache.memory_size</code>, <code>request_cache.evictions</code>, <code>request_cache.hit_count</code>, <code>request_cache.miss_count</code> Best for aggregations on static data Segment Cache Node-level Caches Lucene index segments and postings Managed by Lucene <code>segment.memory_in_bytes</code>, <code>segments.count</code> Larger heap size improves cache efficiency Indices Cache Node-level Caches index metadata (mappings, settings) LRU-based <code>indices.memory</code>, <code>indices.evictions</code> Adjust based on frequency of metadata updates <p>Each caching layer works in tandem to optimize query speed and efficiency, and monitoring these caches is essential for fine-tuning Elasticsearch performance to meet your specific use cases.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#index-life-management-ilm","title":"Index Life Management - ILM","text":"<p>Elasticsearch\u2019s Hot-Warm-Cold (Hot-Warm-Cold-Frozen) architecture is part of its Index Lifecycle Management (ILM) system, designed to optimize storage and cost-efficiency for managing data that has different usage patterns over time. This architecture allows you to store data on different types of nodes (hot, warm, cold, and frozen) based on data retention needs and access frequency. Here\u2019s an in-depth look at each phase and how to effectively manage data with Elasticsearch\u2019s ILM:</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#1-purpose-of-hot-warm-cold-architecture","title":"1. Purpose of Hot-Warm-Cold Architecture","text":"<ul> <li>Optimizes storage costs and resource allocation based on the age and usage pattern of the data.</li> <li>Maximizes query performance for recent data while preserving older data with reduced resource consumption.</li> <li>Enables scalable management of large data volumes across different hardware types or cloud storage.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#2-phases-in-ilm-index-lifecycle-management","title":"2. Phases in ILM (Index Lifecycle Management)","text":"<p>The ILM policy defines actions to transition data through different stages based on time or data access patterns:</p> <ul> <li>Hot Phase: For recent, frequently accessed data.</li> <li>Warm Phase: For less frequently queried but still relevant data.</li> <li>Cold Phase: For older data accessed occasionally.</li> <li>Frozen Phase: For archived data with very low access frequency.</li> <li>Delete Phase: Optionally, data is deleted at the end of its lifecycle.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#3-hot-phase-high-performance-node-configuration","title":"3. Hot Phase (High-Performance Node Configuration)","text":"<ul> <li>Purpose: Stores actively ingested and queried data.</li> <li>Hardware Requirements: High CPU, fast SSD storage, and large memory (RAM) for fast indexing and search.</li> <li>Shard Configuration:<ul> <li>Use a smaller number of larger shards to optimize indexing speed.</li> <li>Allocate more replicas if redundancy and high read performance are necessary.</li> </ul> </li> <li>ILM Actions:<ul> <li>Rollover: Create a new index after a certain data volume or time threshold is met (e.g., daily index rollover).</li> <li>Force Merge: Reduce the number of segments per shard to improve read efficiency.</li> </ul> </li> <li>Common Use Cases: Logging, analytics on recent data, real-time application monitoring.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#4-warm-phase-mid-performance-node-configuration","title":"4. Warm Phase (Mid-Performance Node Configuration)","text":"<ul> <li>Purpose: Stores data that is queried less frequently but is still relevant for analysis.</li> <li>Hardware Requirements: Moderate CPU, lower-cost storage (often SSD or HDD), and less RAM compared to hot nodes.</li> <li>Shard Configuration:<ul> <li>May have fewer replicas compared to the hot phase, given reduced query demands.</li> <li>Shards are consolidated to optimize storage.</li> </ul> </li> <li>ILM Actions:<ul> <li>Shrink: Shrink the index to fewer primary shards to save resources.</li> <li>Force Merge: Further reduce segments for efficiency.</li> <li>Move to Warm Nodes: Transfers data from hot to warm nodes for cost-effective storage.</li> </ul> </li> <li>Common Use Cases: Historical data analysis, infrequent but accessible data, dashboards showing past data trends.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#5-cold-phase-cost-effective-node-configuration","title":"5. Cold Phase (Cost-Effective Node Configuration)","text":"<ul> <li>Purpose: Stores older data that is rarely accessed but still retained for compliance or occasional analysis.</li> <li>Hardware Requirements: Lower-cost HDD storage, lower CPU, and RAM. Cold nodes can tolerate higher latency.</li> <li>Shard Configuration:<ul> <li>Minimal number of replicas, as high availability is less critical.</li> <li>Shards can be larger as search latency is not a priority.</li> </ul> </li> <li>ILM Actions:<ul> <li>Move to Cold Nodes: Moves indices to cold nodes to reduce costs.</li> <li>Freeze Index: Index is searchable but placed in a lower-memory footprint mode.</li> <li>Force Merge to a Single Segment: Further reduces the number of segments.</li> </ul> </li> <li>Common Use Cases: Compliance storage, infrequently accessed logs, backup data for low-priority analysis.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#6-frozen-phase-archival-node-configuration","title":"6. Frozen Phase (Archival Node Configuration)","text":"<ul> <li>Purpose: Stores archived data that is very rarely accessed.</li> <li>Hardware Requirements: Can use very low-cost storage options, including external storage like S3 or other blob storage.</li> <li>Shard Configuration:<ul> <li>Data in the frozen phase is accessed directly from disk without caching in memory.</li> <li>Lowest possible number of replicas, if any.</li> </ul> </li> <li>ILM Actions:<ul> <li>Move to Frozen Nodes: Moves data to frozen nodes or even object storage to further reduce costs.</li> <li>Unfreeze on Query: Data is unarchived only when accessed.</li> </ul> </li> <li>Common Use Cases: Long-term archives, historical records for compliance.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#7-delete-phase-optional-phase","title":"7. Delete Phase (Optional Phase)","text":"<ul> <li>Purpose: Automatically deletes data that has reached the end of its lifecycle.</li> <li>ILM Actions:<ul> <li>Delete Index: Permanently removes data from the cluster.</li> </ul> </li> <li>Common Use Cases: Compliance-driven data retention policies, automated data cleanup.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#8-setting-up-ilm-policies","title":"8. Setting Up ILM Policies","text":"<ul> <li>Define an ILM policy specifying transitions and actions for each phase.</li> <li>Assign the policy to indices at creation, typically through index templates.</li> <li>The ILM policy automatically manages the transition of data through the hot, warm, cold, and frozen phases.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#9-cluster-resource-optimization-with-hot-warm-cold-architecture","title":"9. Cluster Resource Optimization with Hot-Warm-Cold Architecture","text":"<ul> <li>Hot Nodes: Provide high-speed access to recent data, require higher infrastructure investment.</li> <li>Warm Nodes: Optimize costs while maintaining access to recent historical data with moderate query needs.</li> <li>Cold Nodes: Cost-efficient storage for compliance or archival data.</li> <li>Frozen Nodes: Minimal cost storage, including cloud or external storage options for rarely accessed data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#10-example-ilm-policy","title":"10. Example ILM Policy","text":"<p>Here\u2019s an example ILM policy to illustrate phase-based transitions for a log analytics use case:</p> <pre><code>{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\": {\n            \"max_age\": \"7d\",\n            \"max_size\": \"50gb\"\n          },\n          \"set_priority\": {\n            \"priority\": 100\n          }\n        }\n      },\n      \"warm\": {\n        \"min_age\": \"30d\",\n        \"actions\": {\n          \"allocate\": {\n            \"number_of_replicas\": 1\n          },\n          \"forcemerge\": {\n            \"max_num_segments\": 1\n          },\n          \"set_priority\": {\n            \"priority\": 50\n          }\n        }\n      },\n      \"cold\": {\n        \"min_age\": \"90d\",\n        \"actions\": {\n          \"allocate\": {\n            \"require\": {\n              \"data\": \"cold\"\n            }\n          },\n          \"freeze\": {},\n          \"set_priority\": {\n            \"priority\": 0\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"365d\",\n        \"actions\": {\n          \"delete\": {}\n        }\n      }\n    }\n  }\n}\n</code></pre> <ul> <li>Hot Phase: Rollover index every 7 days or 50GB.</li> <li>Warm Phase: Transition after 30 days, reduce segment count, keep one replica.</li> <li>Cold Phase: Transition after 90 days, freeze index to reduce memory usage.</li> <li>Delete Phase: Automatically delete indices older than 365 days.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#11-advantages-of-hot-warm-cold-architecture","title":"11. Advantages of Hot-Warm-Cold Architecture","text":"<ul> <li>Cost Savings: Reduces storage and resource costs by using lower-cost hardware for less-accessed data.</li> <li>Optimized Performance: Ensures high performance for recent data by keeping it on high-speed hot nodes.</li> <li>Automated Management: ILM policies automate data transitions, reducing operational overhead.</li> <li>Flexible Retention: Facilitates retention policies to ensure compliance with data governance and regulatory requirements.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#12-best-practices","title":"12. Best Practices","text":"<ul> <li>Separate Nodes by Type: Use dedicated nodes for each phase to optimize hardware based on the phase requirements.</li> <li>Frequent ILM Review: Regularly review and adjust ILM policies based on access patterns and data growth.</li> <li>Monitor ILM Transitions: Track transition performance to ensure data is moving efficiently between phases.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#13-summary-table","title":"13. Summary Table","text":"Phase Data Usage Hardware ILM Actions Typical Use Cases Hot Active, high access High CPU, SSD, large RAM Rollover, force merge Real-time search, recent logs, app monitoring Warm Mid-range access Moderate CPU, SSD or HDD, RAM Shrink, force merge, reallocate Data analytics on recent history, dashboard views Cold Infrequent access Low CPU, HDD, minimal RAM Freeze, move to cold nodes Compliance storage, infrequent analysis Frozen Rarely accessed Minimal CPU/RAM, cloud storage Unfreeze on access, move to frozen node Long-term archival, compliance data Delete Expired data N/A Delete Data lifecycle cleanup <p>This Hot-Warm-Cold architecture in Elasticsearch enables you to balance cost, performance, and data accessibility across various hardware configurations, ensuring that data is always stored cost-effectively without compromising on necessary access patterns.</p>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#list-of-rest-apis","title":"List of REST APIs","text":"API Endpoint Purpose Description Typical Latency Use Cases Index APIs <code>POST /{index}/_doc</code> Index a Document Adds or updates a document in the specified index. Low (~5-10ms for small docs) Real-time data ingestion, document updates. <code>POST /{index}/_bulk</code> Bulk Indexing Allows indexing, updating, or deleting multiple documents in a single request. Low to Medium (~10-50ms) High-volume data ingestion, ETL processes. <code>POST /{index}/_update/{id}</code> Update a Document Partially updates a document by ID in the specified index. Low to Medium (~10-30ms) Updating specific fields in documents. <code>DELETE /{index}/_doc/{id}</code> Delete a Document Deletes a document by ID from the specified index. Low (~5-10ms) Document removal based on unique IDs. Search APIs <code>GET /{index}/_search</code> Search Documents Executes a search query with optional filters, aggregations, and pagination. Medium to High (~10-100ms, based on complexity) Full-text search, structured queries, analytics. <code>POST /{index}/_search/scroll</code> Scroll Search Enables retrieving large datasets by scrolling through search results. Medium to High (~50-200ms) Pagination for large datasets, data exports. <code>DELETE /_search/scroll</code> Clear Scroll Context Clears scroll contexts to free up resources. Low (~5ms) Resource management after scroll search. <code>POST /_msearch</code> Multi-Search Allows execution of multiple search queries in a single request. Medium to High (~20-150ms) Batch querying, dashboard visualizations. <code>POST /{index}/_count</code> Count Documents Counts the documents matching a query without returning full results. Low (~5-20ms) Quick counts of filtered datasets. Aggregation APIs <code>POST /{index}/_search</code> Aggregation Queries Used with the search API to retrieve aggregated data (e.g., histograms, averages). Medium to High (~20-150ms) Analytics, reporting, data summarization. Cluster and Node APIs <code>GET /_cluster/health</code> Cluster Health Returns health information on the cluster, nodes, and indices. Low (~5ms) Monitoring cluster health and node status. <code>GET /_cluster/stats</code> Cluster Statistics Provides statistics on cluster status, node usage, and storage. Low to Medium (~5-20ms) Cluster-wide monitoring and performance analysis. <code>POST /_cluster/reroute</code> Cluster Reroute Manually reroutes shards in the cluster. Medium (~20-50ms) Shard management and rebalancing. <code>GET /_nodes/stats</code> Node Statistics Returns stats for nodes, including CPU, memory, and thread pools. Low to Medium (~5-20ms) Node health monitoring, resource usage analysis. <code>GET /_cat/nodes</code> List Nodes Provides a list of all nodes in the cluster in a human-readable format. Low (~5ms) Node overview, node status. <code>GET /_cat/indices</code> List Indices Lists all indices with metadata on size, health, and document count. Low (~5ms) Index management and monitoring. Index Management APIs <code>PUT /{index}</code> Create Index Creates a new index with specific settings and mappings. Low (~10-20ms) Index setup and schema definition. <code>DELETE /{index}</code> Delete Index Deletes the specified index. Low (~5-10ms) Index removal, data management. <code>PUT /{index}/_settings</code> Update Index Settings Updates settings (e.g., refresh interval) of an index. Low (~10ms) Dynamic adjustments of index settings. <code>POST /{index}/_refresh</code> Refresh Index Refreshes an index to make recent changes searchable. Medium (~10-30ms) Ensures data is available for search in near-real-time. <code>POST /{index}/_forcemerge</code> Force Merge Index Reduces the number of segments in an index to optimize storage. High (~100ms - 1s+) Optimize index storage, improve search speed. Cache and Memory Management <code>POST /{index}/_cache/clear</code> Clear Index Cache Clears the cache for the specified index. Low (~5ms) Cache management for performance tuning. <code>POST /_flush</code> Flush Index Writes all buffered changes to disk. Medium (~10-30ms) Data durability, cache clearing. <code>POST /{index}/_refresh</code> Refresh Makes recent changes to an index visible to search. Medium (~10-30ms) Near real-time updates in the search index. Snapshot and Backup APIs <code>PUT /_snapshot/{repo}/{snapshot}</code> Create Snapshot Creates a snapshot of indices for backup. High (dependent on index size) Data backup, disaster recovery. <code>GET /_snapshot/{repo}/{snapshot}</code> Get Snapshot Status Checks the status of an existing snapshot. Low (~5ms) Monitor snapshot progress, status checks. <code>DELETE /_snapshot/{repo}/{snapshot}</code> Delete Snapshot Deletes an existing snapshot. Medium (~10-20ms) Snapshot lifecycle management, freeing storage. Security and Role Management <code>POST /_security/role/{role}</code> Create/Update Role Creates or updates a security role with specific permissions. Low (~5-10ms) Access control, role-based permissions. <code>POST /_security/user/{user}</code> Create/Update User Creates or updates a user in Elasticsearch. Low (~5-10ms) User management, access permissions. <code>GET /_security/_authenticate</code> Authenticate User Authenticates the current user. Low (~5ms) Session management, authentication checks."},{"location":"techdives/DistrubutedSystems/ElasticSearch/#additional-notes","title":"Additional Notes","text":"<ul> <li>Latency varies by operation complexity, cluster size, and data volume. Basic CRUD operations and small management tasks typically have lower latencies.</li> <li>Bulk operations optimize high-volume data processing by batching requests, but they may slightly increase latency for individual actions due to combined processing.</li> <li>Search and aggregation latencies increase with query complexity, the number of documents involved, and the number of shards searched.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#capacity-planning-cluster-design","title":"Capacity Planning &amp; Cluster Design","text":"Parameter Formula / Best Practice Description Example Calculation Total Data Nodes $ \\text{Total Shards} \\times \\text{Shard Size} / \\text{Node Disk Capacity} $ Calculate required data nodes based on total shard size and node storage. 20 shards of 30GB each on 600GB nodes \u2192 1 data node Heap Memory Allocation $ \\text{Total Node RAM} \\times 0.5 $ (up to 32GB max) Allocate 50% of node memory to JVM heap, up to 32GB, to optimize memory usage. Node with 64GB RAM \u2192 32GB heap Storage Requirement $ \\text{Total Data Size} \\times (1 + \\text{Replication Factor}) \\times \\text{Retention Period (months)} $ Plan storage capacity based on expected data size and replication. 1TB data, 1 replica, 1-month retention \u2192 2TB Ideal Shard Size 20-50 GB per shard Recommended shard size for optimal performance and manageability. Aim for shards ~30GB each for balanced load Shards per Index $ \\text{Total Data Size} / \\text{Target Shard Size} $ Calculate shard count to avoid excessive shard management overhead. 500GB index, 25GB target shard size \u2192 20 shards Max Shard Count Avoid more than 20 shards per GB of heap Ensure shard count doesn\u2019t exceed a level that can cause memory strain. 32GB heap \u2192 max ~640 shards across all indices Master Nodes Minimum of 3 Dedicated master nodes ensure quorum-based fault tolerance and cluster stability. At least 3 master nodes for high availability Coordinating Nodes 1 per 10 data nodes in large clusters Handle query load without adding data nodes, especially with complex aggregation queries. 50 data nodes \u2192 5 coordinating nodes CPU Requirement 4-8 CPUs per data node Allocate enough CPUs to handle search and indexing operations without bottlenecks. 4-8 CPUs per node for typical workloads Disk I/O Throughput Minimum of 300 MB/s (write-heavy) For write-intensive clusters, ensure sufficient I/O throughput for data nodes. SSDs or fast disks are recommended Disk Usage Threshold Keep below 75% disk usage per node Avoid exceeding 75% disk usage on data nodes to prevent performance degradation. Monitor for 75% threshold, Elasticsearch throttles at ~85% Index Throttle State Throttles at ~85% disk usage Elasticsearch throttles indexing if nodes exceed 85% disk usage. Configure alerts to prevent reaching throttle state Memory Usage - Field Data Cache <code>indices.fielddata.cache.size</code> based on available heap Field data cache size impacts sorting and aggregation speed, stored in memory. Set to 20-30% of available heap for high-aggregation workloads Query Cache Size 10% of heap by default (adjustable) Caches filter queries to speed up repeated search operations. Increase for clusters with frequent repetitive queries Request Cache Size Enabled per index, LRU-based Cache complete search requests, especially useful for aggregation-heavy queries on static data. Enable on indices with frequent aggregation queries Cluster Health <code>GET /_cluster/health</code> (monitor green, yellow, red status) Regularly monitor cluster health to identify potential issues in shard allocation and node status. Alerts for yellow or red statuses to detect unallocated shards Pending Tasks <code>GET /_cluster/pending_tasks</code> Track the number of pending tasks; delays may signal node or cluster overload. Monitor to ensure tasks are processed promptly CPU Usage per Node Track via <code>node.cpu.percent</code> Monitor CPU load on nodes, especially data and coordinating nodes handling heavy queries. Keep below 80% for balanced performance Search Latency Monitor <code>search.fetch_time</code> and <code>search.query_time</code> Search latency metrics indicate performance bottlenecks; high values can suggest tuning is needed. Target &lt;100ms for interactive queries, &lt;500ms for aggregations Indexing Latency Monitor <code>indexing.index_time</code> Tracks indexing speed; high values indicate indexing bottlenecks. Optimize disk I/O if consistently high GC Pause Time Track <code>jvm.gc.collection_time</code> Excessive GC pause time (&gt;100ms) can degrade performance, especially on data nodes. Keep heap usage &lt;75% to avoid frequent GC pauses Disk Utilization <code>disk.used_percent</code> Ensure disk usage remains within optimal limits to prevent resource contention. Monitor for high usage, keep below 75% Heap Usage per Node <code>jvm.heap_used_percent</code> Monitor heap usage across nodes; values near 100% can trigger frequent GC and degrade performance. Keep below 75% for stable performance Shard Count per Node Shards should not exceed 50-75 per data node Optimal shard count balances memory usage and search latency. Distribute shards evenly to avoid bottlenecks Index Rollover Frequency Based on data ingestion and retention policy Use index rollover for high-ingestion use cases to manage shard size and count. Time-based or size-based rollover (e.g., daily, 10GB) Snapshot Frequency Schedule during off-peak hours Regular snapshots for backup without affecting active workloads. Daily or weekly snapshots for disaster recovery Ingest Node CPU Requirement Optimize for transformation-heavy workloads Ingest nodes need higher CPU for ETL tasks before indexing. ~8 CPUs per ingest node for transformation-heavy clusters Write Thread Pool Size Controlled via <code>thread_pool.write.size</code> Configure thread pool size for write-heavy workloads. Default based on available processors; increase for high-write loads Bulk Thread Pool Size Set via <code>thread_pool.bulk.size</code> Bulk operations often have separate thread pools, useful for high-ingestion clusters. Default based on processors; increase if high bulk ingestion Query Throughput Measure <code>search.thread_pool.queue</code> The search queue size indicates if the search load is too high, leading to delays. Keep queue size low to avoid bottlenecks Bulk Queue Size Monitor <code>bulk.thread_pool.queue</code> Large bulk queue size indicates ingestion pressure; tune for high-ingestion needs. Increase queue size or add ingest nodes for bulk-heavy workloads Network Throughput Monitor network interface utilization High network usage can impact inter-node communication, especially during replication. Ensure sufficient network bandwidth for large clusters Network Latency Track round-trip time between nodes Low-latency network is critical for distributed search and replication. &lt;1ms recommended within data centers, 1-5ms for cross-regions"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#questions","title":"Questions","text":""},{"location":"techdives/DistrubutedSystems/ElasticSearch/#1-sql-or-nosql","title":"1. SQL or NoSQL:","text":"<ul> <li>NoSQL: Elasticsearch is a NoSQL database designed for search and analytics on structured and unstructured data.</li> <li>Type of NoSQL: Document-oriented, storing data as JSON documents.</li> <li>Supports Polymorphic?: Yes, Elasticsearch can store documents with varying structures, making it flexible for polymorphic data storage.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#2-main-feature-origin-and-design","title":"2. Main Feature, Origin, and Design:","text":"<ul> <li>Main Feature: Optimized for full-text search, analytics, and distributed data storage.</li> <li>Built For: Real-time search, logging, and analytics, especially for large datasets.</li> <li>Developer: Developed by Shay Banon, later maintained by Elastic.co.</li> <li>Based on: Built on top of Apache Lucene.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#3-olap-or-oltp","title":"3. OLAP or OLTP:","text":"<ul> <li>Primarily OLAP: Elasticsearch is designed for OLAP workloads like analytics, aggregations, and complex search queries.</li> <li>Reason: Its architecture optimizes for high-throughput search and analysis rather than transactional processing.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#4-acid-or-base","title":"4. ACID or BASE:","text":"<ul> <li>BASE: Elasticsearch is eventually consistent and follows BASE principles. It supports near real-time (NRT) search, not strong consistency.</li> <li>ACID: Limited ACID compliance, mostly per-document operations.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#5-cap-theorem","title":"5. CAP Theorem:","text":"<ul> <li>CAP Stance: Elasticsearch prioritizes Availability and Partition tolerance, with eventual Consistency.<ul> <li>Consistency: Provides consistency in the sense that all nodes have the latest data after eventual replication.</li> <li>Availability: If a node fails, Elasticsearch reroutes shards to ensure continuous availability.</li> <li>Partition Tolerance: Designed to operate in distributed environments with node communication issues.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#6-cluster-structure","title":"6. Cluster Structure:","text":"<ul> <li>Cluster: Comprises multiple nodes working together. Nodes store data and perform search and indexing.</li> <li>From Cluster to Records:<ul> <li>Cluster \u2192 Nodes (Master, Data, Coordinating, Ingest) \u2192 Indices \u2192 Shards \u2192 Documents \u2192 Fields/Records.</li> </ul> </li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#7-fundamental-building-blocks","title":"7. Fundamental Building Blocks:","text":"<ul> <li>Cluster \u2192 Nodes \u2192 Indices \u2192 Shards \u2192 Segments \u2192 Documents \u2192 Fields.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#8-multi-master-support","title":"8. Multi-Master Support:","text":"<ul> <li>No, Elasticsearch supports only a single active master node at any time. Multiple master-eligible nodes can be elected, but only one acts as the master.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#9-master-data-node-relation","title":"9. Master-Data Node Relation:","text":"<ul> <li>Follows Master-Slave model: The master node manages cluster state and shard allocation, while data nodes store and manage data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#10-node-structures-in-cluster","title":"10. Node Structures in Cluster:","text":"<ul> <li>Master Nodes: Manage the cluster state.</li> <li>Data Nodes: Store data and execute search and indexing.</li> <li>Coordinating Nodes: Route requests and handle query aggregation.</li> <li>Ingest Nodes: Pre-process documents before indexing.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#11-cluster-scaling-support","title":"11. Cluster Scaling Support:","text":"<ul> <li>Horizontal Scaling: Adding more nodes is preferred for scalability and balancing.</li> <li>Vertical Scaling: Increasing node capacity is less flexible but possible.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#12-high-availability","title":"12. High Availability:","text":"<ul> <li>High availability is achieved through replicas and shard redistribution. If a node fails, replicas ensure data accessibility.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#13-fault-tolerance","title":"13. Fault Tolerance:","text":"<ul> <li>If nodes fail, Elasticsearch automatically reallocates shards to other nodes to ensure continued operation.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#14-replication","title":"14. Replication:","text":"<ul> <li>Each shard has one or more replicas. Replicas provide redundancy and improve read throughput.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#15-partition","title":"15. Partition:","text":"<ul> <li>Data is divided into partitions known as shards, which can be distributed across nodes.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#16-sharding","title":"16. Sharding:","text":"<ul> <li>An index is divided into shards. Sharding allows horizontal scaling by spreading data across nodes.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#17-caching-in-depth","title":"17. Caching in Depth:","text":"<ul> <li>Filesystem Cache: OS-level cache for segments and indices.</li> <li>Shard-level Cache: Field data cache, query cache, and request cache for faster response on repeated queries.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#18-storage-type","title":"18. Storage Type:","text":"<ul> <li>Tree Structure: Uses BKD trees and inverted indices for fast search on structured and unstructured data.</li> <li>Heap and Disk Storage: Field data and segments stored in-memory and disk for efficient retrieval.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#19-segmentpage-approach","title":"19. Segment/Page Approach:","text":"<ul> <li>Segments: Data is written to immutable segments, which are merged periodically.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#20-trees-for-storage","title":"20. Trees for Storage:","text":"<ul> <li>BKD Trees: Used for indexing numeric and geospatial data.</li> <li>Inverted Indices: Store mappings for full-text search.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#21-indexing","title":"21. Indexing:","text":"<ul> <li>How: Data is indexed via inverted indices and BKD trees.</li> <li>Trees Used: BKD trees for numeric and geospatial data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#22-routing","title":"22. Routing:","text":"<ul> <li>Documents are assigned to shards using hashing, ensuring distribution across nodes.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#23-latency","title":"23. Latency:","text":"<ul> <li>Write Latency: Typically 5-10ms.</li> <li>Read Latency: 5-20ms.</li> <li>Indexing Latency: 10-30ms depending on shard count and node capacity.</li> <li>Replication Latency: 20-50ms depending on network and shard replication.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#24-versioning","title":"24. Versioning:","text":"<ul> <li>Elasticsearch supports optimistic concurrency control with versioning at the document level.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#25-locking-and-concurrency","title":"25. Locking and Concurrency:","text":"<ul> <li>Optimistic locking, avoiding traditional locks to allow for distributed updates.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#26-write-ahead-log-wal","title":"26. Write-Ahead Log (WAL):","text":"<ul> <li>Elasticsearch does not use traditional WAL but relies on translog for write durability.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#27-change-data-capture-cdc","title":"27. Change Data Capture (CDC):","text":"<ul> <li>CDC Support: Limited; CDC can be simulated with the use of versioning and update tracking.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#28-query-type-and-query","title":"28. Query Type and Query:","text":"<ul> <li>Types: Full-text, term, range, Boolean, geospatial, and aggregations.</li> <li>In Depth: Supports complex queries, scoring, and aggregations for analytics.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#29-query-optimizers","title":"29. Query Optimizers:","text":"<ul> <li>Elasticsearch optimizes queries by caching, narrowing the search, and efficiently reading segments.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#30-sql-support","title":"30. SQL Support:","text":"<ul> <li>Partial SQL support, primarily for querying via Elasticsearch SQL API.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#31-circuit-breakers","title":"31. Circuit Breakers:","text":"<ul> <li>Protects cluster stability by setting limits on memory use per request, query, or field data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#32-data-retention-lifecycle-management","title":"32. Data Retention / Lifecycle Management:","text":"<ul> <li>Hot-Warm-Cold Architecture: Data can be moved between hot (frequent access), warm (less frequent access), and cold (archived) nodes.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#33-other-features","title":"33. Other Features:","text":"<ul> <li>Use Cases: Log analysis, monitoring, analytics, and search-based applications.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#34-modules-or-libraries","title":"34. Modules or Libraries:","text":"<ul> <li>Extensions: Elasticsearch can be extended with plugins for monitoring, security, and ingestion.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#35-optimization-and-tuning","title":"35. Optimization and Tuning:","text":"<ul> <li>Includes shard allocation, cache configuration, and query tuning.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#36-backup-and-recovery","title":"36. Backup and Recovery:","text":"<ul> <li>Snapshots can be created for backup and restored for recovery.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#37-security","title":"37. Security:","text":"<ul> <li>Role-based access control, SSL/TLS encryption, and audit logging.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#38-migration","title":"38. Migration:","text":"<ul> <li>Tools like reindexing API and snapshot/restore enable data migration between clusters.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#39-recommended-cluster-setup","title":"39. Recommended Cluster Setup:","text":"<ul> <li>Ideal Configuration: Three master-eligible nodes, at least three data nodes, and coordinating nodes as needed.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#40-basic-cluster-setup","title":"40. Basic Cluster Setup:","text":"<ul> <li>Minimum: Three nodes for a small distributed setup, with roles depending on workload.</li> </ul>"},{"location":"techdives/DistrubutedSystems/ElasticSearch/#references","title":"References","text":"<ol> <li>https://www.elastic.co/guide/en/elasticsearch/reference/8.15/index.html</li> <li>https://www.hellointerview.com/learn/system-design/deep-dives/elasticsearch</li> <li>https://j.blaszyk.me/tech-blog/exploring-apache-lucene-index/</li> <li>https://medium.com/swlh/bkd-trees-used-in-elasticsearch-40e8afd2a1a4</li> <li>https://www.paradedb.com/blog/elasticsearch_vs_postgres</li> <li>https://nsvarun14.medium.com/capacity-planning-for-elasticsearch-cde3c0693add</li> <li>https://fdv.github.io/running-elasticsearch-fun-profit/004-cluster-design/004-cluster-design.html</li> <li>https://medium.com/@sureshkumar.pawar/sizing-your-elk-elasticsearch-logstash-kibana-cluster-for-high-performance-398fe6e591d4</li> <li>https://www.infoq.com/articles/similarity-scoring-elasticsearch/</li> <li>https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables</li> <li>https://medium.com/@niteshsaini/how-elasticsearch-calculates-its-relevance-score-e762c6274004</li> </ol>"},{"location":"techdives/DistrubutedSystems/Kafka/","title":"Kafka","text":""},{"location":"techdives/DistrubutedSystems/Kafka/#what-is-kafka","title":"What is Kafka?","text":"<p>Kafka is a distributed event streaming platform that allows applications to publish, store, and consume streams of data in real-time or batch mode. It is designed to handle continuous streams of events or records by functioning as a distributed commit log, where data is written sequentially and can be read independently by multiple consumers.</p> <p>Kafka follows a publish-subscribe model where producers write data to topics divided into partitions, and consumers pull data from those partitions at their own pace. Kafka ensures that data flows reliably between producers and consumers, with fault-tolerant replication and durable storage to prevent data loss.</p> <p>At its heart, Kafka provides three core functionalities: 1. Message Streaming: Enabling systems to send and receive continuous streams of data asynchronously. 2. Durable Storage: Persisting messages on disk, ensuring data is not lost even in case of failures. 3. Distributed Processing: Allowing data to be partitioned and processed across multiple servers for scalability and fault tolerance.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#core-components-and-keywords","title":"Core Components and Keywords","text":"Component / Keyword Description Topic A logical channel for data, used to categorize messages. Topics are divided into partitions for parallelism. Partition A segment of a topic that stores messages in a log structure. It ensures parallel processing. Each partition contains messages with offsets to track their position. Producer A client or application that publishes messages to a Kafka topic. Producers can distribute messages across partitions. Consumer A client or application that subscribes to Kafka topics and reads messages from partitions at their own pace. Broker A Kafka server that stores messages, handles requests, and coordinates with other brokers in a Kafka cluster. Kafka Cluster A group of multiple Kafka brokers working together to provide scalability and fault tolerance. Zookeeper / KRaft Zookeeper is used for metadata management and leader election in older Kafka versions. Newer versions replace Zookeeper with KRaft (Kafka Raft) for native metadata management. Offset A unique identifier for each message within a partition, representing its position in the log. Consumers use offsets to track the messages they have processed. Replication Kafka duplicates partitions across multiple brokers to ensure fault tolerance and data availability. Leader Partition The primary replica of a partition that handles all reads and writes for that partition. Other replicas act as followers. Follower Partition A copy of the leader partition that replicates its data. If the leader fails, a follower can take over. Consumer Group A group of consumers sharing the same group ID, ensuring that each partition is consumed by only one member of the group at any given time. In-Sync Replica (ISR) A replica that is up-to-date with the leader partition. Kafka promotes an ISR as the new leader if the current leader fails. Acknowledgments (ACKs) A producer configuration that defines when a message is considered successfully sent (e.g., only after being replicated to all followers). Retention Policy A configuration that determines how long Kafka retains messages before deleting or compacting them. Messages can be removed based on time or size limits. Log Compaction A process that keeps only the latest version of a key within a topic, useful for data clean-up and long-term storage. Controller A designated broker responsible for managing partition leadership and cluster rebalancing. Kafka Streams A lightweight client library used for processing and analyzing data streams directly within Kafka. Kafka Connect A framework for integrating Kafka with external systems by providing connectors for data ingestion and extraction."},{"location":"techdives/DistrubutedSystems/Kafka/#how-kafka-achieves-high-scalability","title":"How Kafka Achieves High Scalability ?","text":"<p>Kafka\u2019s design is fundamentally scalable, allowing it to handle millions of events per second efficiently. It achieves this by leveraging distributed architecture, partitioning, horizontal scaling, and several load balancing strategies. Let\u2019s explore the mechanisms, architecture, and workflows that enable Kafka to scale end-to-end.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#1-partitioning-the-foundation-of-scalability","title":"1. Partitioning: The Foundation of Scalability","text":"<ul> <li>Partitioning is the primary mechanism through which Kafka ensures horizontal scalability. </li> <li>Each topic in Kafka is divided into partitions, and each partition stores an ordered, immutable sequence of messages.</li> <li>Producers can write messages to different partitions in parallel, improving throughput.</li> <li>Consumers in a consumer group process data independently from different partitions, spreading the load.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#partition-key-and-load-distribution","title":"Partition Key and Load Distribution","text":"<ul> <li>A partition key can be used to determine to which partition a message will be routed.</li> <li>If no key is provided, Kafka defaults to round-robin distribution across partitions.</li> <li>Partitioning ensures both scalability and ordering guarantees within a partition.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#impact-of-more-partitions","title":"Impact of More Partitions","text":"<ul> <li>More partitions increase the parallelism, allowing more producers and consumers to work simultaneously.</li> <li>However, each additional partition incurs overhead (memory, I/O, metadata), so the partition count must be tuned carefully.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#2-distributed-broker-architecture","title":"2. Distributed Broker Architecture","text":"<ul> <li>Kafka is deployed as a cluster of brokers, with each broker responsible for multiple partitions.</li> <li>As Kafka clusters grow, more brokers can be added to distribute the load.</li> <li>Kafka ensures no single broker becomes a bottleneck by distributing topic partitions across all brokers.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#partition-replication-across-brokers","title":"Partition Replication Across Brokers","text":"<ul> <li>Kafka supports partition replication for fault tolerance. Each partition has a leader replica on one broker and follower replicas on other brokers.</li> <li>This means even if one broker handles the leader partition, the workload is distributed across brokers with followers syncing in the background.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#3-horizontal-scaling-add-more-brokers-or-partitions","title":"3. Horizontal Scaling: Add More Brokers or Partitions","text":"<ul> <li>Kafka clusters scale horizontally, meaning new brokers can be added without downtime.</li> <li>As traffic or data volume increases, administrators can:</li> <li>Add brokers: Redistribute partitions across the new brokers.</li> <li>Add partitions: Redistribute topics into new partitions.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#scaling-the-producer-and-consumer-layers","title":"Scaling the Producer and Consumer Layers","text":"<ul> <li>Kafka\u2019s producers and consumers are stateless, meaning they can scale horizontally.</li> <li>Producers write to multiple partitions in parallel.</li> <li> <p>Consumers in a consumer group split the partitions among themselves for parallel processing.</p> </li> <li> <p>When Kafka detects new brokers, partition leadership rebalances automatically to evenly distribute the load across brokers.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#4-producer-scalability-load-balancing-and-batch-processing","title":"4. Producer Scalability: Load Balancing and Batch Processing","text":"<ul> <li>Kafka producers scale by distributing messages across partitions. Producers can use:</li> <li>Round-robin partitioning: Evenly distributing messages to all partitions.</li> <li> <p>Key-based partitioning: Ensuring messages with the same key always go to the same partition for order guarantees.</p> </li> <li> <p>Kafka producers also use batching to group multiple messages into a single request, reducing network overhead and increasing throughput.</p> </li> <li>Asynchronous sends allow producers to continue processing without waiting for acknowledgments, further improving scalability.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#5-consumer-scalability-consumer-groups-and-load-sharing","title":"5. Consumer Scalability: Consumer Groups and Load Sharing","text":"<ul> <li>Kafka scales consumer applications by using consumer groups. A consumer group is a set of consumers working together to process messages from a topic.</li> <li>Each partition in a topic is consumed by only one consumer in the group at any time, ensuring no two consumers in the same group read the same data.</li> <li>More consumers can be added to a group to share the load, provided the number of partitions is larger than or equal to the number of consumers.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#rebalancing-consumers","title":"Rebalancing Consumers","text":"<ul> <li>Kafka dynamically adjusts when new consumers are added or removed from a consumer group by rebalancing partitions across the group. This ensures efficient data processing, even in a changing environment.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#6-efficient-load-balancing-and-rebalancing-mechanisms","title":"6. Efficient Load Balancing and Rebalancing Mechanisms","text":"<ul> <li>Kafka uses partition rebalancing when brokers or consumers are added or removed.</li> <li>The controller broker manages the partition leader assignment and rebalancing.</li> <li>During rebalancing, Kafka ensures minimal disruption by only migrating the necessary partitions, ensuring continuous data flow.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#sticky-partitioning-strategy","title":"Sticky Partitioning Strategy","text":"<ul> <li>Kafka optimizes load balancing by sticky partition assignments, meaning it tries to keep partitions assigned to the same consumer or broker to minimize churn.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#7-network-optimization-and-zero-copy-technology","title":"7. Network Optimization and Zero-Copy Technology","text":"<ul> <li>Kafka relies heavily on zero-copy techniques to achieve high throughput.</li> <li>Using sendfile() system calls, Kafka can move data directly from the disk to the network buffer, reducing CPU usage and latency.</li> <li>This makes Kafka suitable for transferring large volumes of data with minimal resource consumption.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#8-broker-level-optimizations-and-compression","title":"8. Broker-Level Optimizations and Compression","text":"<ul> <li>Kafka brokers use I/O batching and compression to improve scalability:</li> <li>Batching: Brokers accumulate messages in memory and flush them to disk in batches, reducing disk I/O operations.</li> <li> <p>Compression: Messages can be compressed (e.g., with Gzip or Snappy) to reduce the amount of data transferred over the network.</p> </li> <li> <p>Kafka also makes use of page cache to keep frequently accessed data in memory, further optimizing performance.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#9-kafka-controller-and-partition-leadership","title":"9. Kafka Controller and Partition Leadership","text":"<ul> <li>Kafka assigns one broker as the controller broker, which handles:</li> <li>Leader election: Assigning leader partitions across brokers.</li> <li> <p>Metadata updates: Ensuring all brokers have consistent metadata.</p> </li> <li> <p>Dynamic partition leadership reassignment ensures that even when new brokers are added or partitions are migrated, Kafka distributes workload evenly.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#10-handling-backpressure-for-scalability","title":"10. Handling Backpressure for Scalability","text":"<ul> <li>Kafka producers and consumers operate asynchronously, which allows the system to handle backpressure without affecting throughput.</li> <li>Producers continue writing to partitions regardless of consumer lag.</li> <li>Consumers can process messages at their own pace using offsets, without impacting producers or causing system slowdowns.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#11-configuring-for-high-scalability-tuning-parameters","title":"11. Configuring for High Scalability: Tuning Parameters","text":"<ul> <li>Kafka clusters can be optimized for scalability with various tuning parameters:</li> <li>Partition count: More partitions allow more parallel processing.</li> <li>Replication factor: Higher replication ensures fault tolerance, though it also adds overhead.</li> <li>Batch size: Larger batches increase throughput but introduce some latency.</li> <li>Compression: Compressing messages reduces network load but requires more CPU.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#summary-of-kafkas-high-scalability-mechanisms","title":"Summary of Kafka\u2019s High Scalability Mechanisms","text":"Aspect How Kafka Scales Partitioning Divides topics into partitions for parallelism. Distributed Brokers Workload spread across multiple brokers. Horizontal Scaling New brokers or partitions can be added dynamically. Producer Parallelism Producers write to multiple partitions concurrently. Consumer Groups Consumers share partitions for parallel processing. Rebalancing Redistributes workload when brokers/consumers change. Batching &amp; Compression Reduces I/O and network overhead. Zero-Copy Technology Efficient data transfer with low CPU usage."},{"location":"techdives/DistrubutedSystems/Kafka/#how-kafka-achieves-high-availability-and-fault-tolerance","title":"How Kafka Achieves High Availability and Fault Tolerance ?","text":"<p>Kafka\u2019s design for high availability and fault tolerance centers on replication, leader election, distributed brokers, and self-healing mechanisms. Together, these mechanisms ensure Kafka can handle hardware, software, and network failures, while maintaining data integrity, durability, and continuity.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#1-partition-replication-foundation-of-ha-and-ft","title":"1. Partition Replication \u2013 Foundation of HA and FT","text":"<ul> <li>Kafka divides topics into partitions and replicates each partition across multiple brokers.</li> <li>For each partition, there is a leader replica (primary copy) and follower replicas.</li> <li>Replication Factor (set per topic) determines the number of copies for each partition. For example, a replication factor of 3 means one leader and two followers per partition.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#how-replication-ensures-ha-and-ft","title":"How Replication Ensures HA and FT:","text":"<ol> <li>Leader-follower model: Only the leader replica handles read and write requests. Followers passively replicate the leader\u2019s data.</li> <li>Automatic failover: If the leader broker fails, one of the followers (from the in-sync replica set, or ISR) is promoted as the new leader, ensuring the partition remains available.</li> <li>This setup ensures continuous data availability and minimal downtime when individual brokers fail.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Kafka/#2-leader-election-and-failover-mechanism","title":"2. Leader Election and Failover Mechanism","text":"<ul> <li>Kafka assigns one replica as the leader and others as followers for each partition.</li> <li>Zookeeper (or KRaft) coordinates leader election and keeps metadata consistent across brokers.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#leader-election-process-during-failures","title":"Leader Election Process During Failures:","text":"<ol> <li>Detection: Zookeeper (or KRaft) detects a failed broker.</li> <li>Election: The controller broker initiates a leader election for partitions on the failed broker.</li> <li>Promotion: An in-sync follower (replica that\u2019s fully up-to-date) is promoted to leader.</li> <li>Metadata update: Kafka updates cluster metadata to reflect the new leader, ensuring clients redirect requests to the new leader.</li> </ol> <p>This automated and rapid leader election ensures Kafka remains operational with minimal interruption.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#3-in-sync-replicas-isr-ensuring-data-integrity","title":"3. In-Sync Replicas (ISR) \u2013 Ensuring Data Integrity","text":"<ul> <li>Kafka tracks in-sync replicas (ISR), which are replicas fully synchronized with the leader.</li> <li>Kafka only allows ISR replicas to be promoted to leader during failover, ensuring the new leader has the latest data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#role-of-isr-in-minimizing-data-loss","title":"Role of ISR in Minimizing Data Loss:","text":"<ul> <li>Kafka only acknowledges writes to producers if messages are successfully replicated to all ISR replicas (if <code>acks=all</code>).</li> <li>If a replica falls behind, it is temporarily removed from ISR until it catches up, ensuring only fully synced replicas can be promoted to leader.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#4-controller-broker-managing-ha-and-ft-orchestration","title":"4. Controller Broker \u2013 Managing HA and FT Orchestration","text":"<ul> <li>Kafka designates one broker as the controller, responsible for partition leadership management and rebalancing operations.</li> <li>The controller broker coordinates leader elections and metadata updates across the cluster.</li> <li>If the controller broker fails, a new one is elected to maintain continuity without disrupting operations.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#5-distributed-brokers-avoiding-single-points-of-failure","title":"5. Distributed Brokers \u2013 Avoiding Single Points of Failure","text":"<ul> <li>Kafka distributes partitions and their replicas across multiple brokers, ensuring no single broker failure causes data loss.</li> <li>Each broker holds different partitions and replicas, providing load balancing and data redundancy.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#how-broker-distribution-improves-ha-and-ft","title":"How Broker Distribution Improves HA and FT:","text":"<ul> <li>Kafka ensures that no two replicas of the same partition are hosted on the same broker, minimizing risk during a broker failure.</li> <li>If a broker fails, other brokers hosting replicas continue serving data, maintaining availability.</li> <li>Kafka dynamically rebalances partitions and replicas across brokers when a broker joins or leaves the cluster.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#6-acknowledgment-policies-acks-ensuring-data-durability","title":"6. Acknowledgment Policies (ACKs) \u2013 Ensuring Data Durability","text":"<p>Kafka provides acknowledgment modes for tuning data durability against performance. These settings control when a message is considered \u201csuccessfully written\u201d:</p> <ul> <li>acks=0: Producer does not wait for any acknowledgment (fast, but no durability).</li> <li>acks=1: Leader acknowledges after writing to local storage (data loss possible if the leader fails).</li> <li>acks=all: Leader waits until message replication to all ISR replicas, maximizing durability.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#role-of-acks-in-fault-tolerance","title":"Role of ACKs in Fault Tolerance:","text":"<ul> <li>With acks=all, Kafka ensures even if the leader fails immediately after acknowledging, the message is still replicated on follower brokers.</li> <li>This reduces data loss risk and enables safe failover to a new leader.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#7-log-compaction-and-retention-for-data-availability","title":"7. Log Compaction and Retention for Data Availability","text":"<p>Kafka employs log compaction and retention to maintain long-term data availability:</p> <ol> <li>Time-based retention: Kafka retains messages for a configurable period (e.g., 7 days).</li> <li>Size-based retention: Kafka deletes old messages once partition logs reach a certain size.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Kafka/#log-compaction-for-data-recovery","title":"Log Compaction for Data Recovery:","text":"<ul> <li>Log compaction keeps only the latest version of each key. This is essential for stateful applications where the latest state must always be available.</li> <li>Log compaction allows Kafka to replay and recover data even during consumer failures or recovery needs.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#8-handling-split-brain-scenarios-consistency-through-quorums","title":"8. Handling Split-Brain Scenarios \u2013 Consistency Through Quorums","text":"<p>A split-brain scenario happens when a broker loses connectivity with others, risking data inconsistency.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#kafkas-approach-to-preventing-split-brain","title":"Kafka\u2019s Approach to Preventing Split-Brain:","text":"<ul> <li>Kafka removes disconnected brokers from the ISR, preventing them from serving outdated data.</li> <li>Zookeeper (or KRaft) ensures that only one leader per partition exists, preventing conflicting writes.</li> </ul> <p>This quorum-based replication prevents data corruption during network partitions.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#9-self-healing-and-automated-recovery","title":"9. Self-Healing and Automated Recovery","text":"<p>Kafka\u2019s self-healing mechanisms enable it to quickly recover from broker or replica failures:</p> <ul> <li>Controller failover: If the controller broker fails, a new controller is elected automatically.</li> <li>Replica recovery: Kafka automatically adds a failed broker back to ISR once it recovers and synchronizes with the leader.</li> <li>Rebalancing: Kafka reassigns leadership of partitions to healthy brokers during rebalancing to prevent bottlenecks or potential outages.</li> </ul> <p>These self-healing features maintain availability and data consistency without requiring manual intervention.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#10-multi-datacenter-replication-for-disaster-recovery","title":"10. Multi-Datacenter Replication for Disaster Recovery","text":"<p>Kafka supports multi-datacenter replication for cross-region fault tolerance using tools like Kafka MirrorMaker.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#how-multi-cluster-replication-ensures-availability-and-fault-tolerance","title":"How Multi-Cluster Replication Ensures Availability and Fault Tolerance:","text":"<ul> <li>Kafka replicates data across geographically separate clusters to ensure disaster recovery.</li> <li>If an entire Kafka cluster becomes unavailable, the replicated cluster in another data center takes over, ensuring continuity.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#11-client-side-handling-of-failures-for-ha-and-ft","title":"11. Client-Side Handling of Failures for HA and FT","text":"<p>Kafka\u2019s producers and consumers have built-in resilience to handle failures gracefully:</p> <ul> <li>Producers: Retry sends if a leader partition is temporarily unavailable, with updated metadata guiding them to the new leader.</li> <li>Consumers: Retry reads from a new leader if they detect a leader change, and consumer groups dynamically rebalance to share the load among available consumers.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#summary-of-kafkas-high-availability-and-fault-tolerance-mechanisms","title":"Summary of Kafka\u2019s High Availability and Fault Tolerance Mechanisms","text":"Mechanism How It Ensures HA and FT Partition Replication Multiple copies of data across brokers ensure availability even during broker failures. Leader Election Automatically promotes a follower to leader when the leader broker fails. In-Sync Replicas (ISR) Only fully synchronized replicas can be promoted to leader to prevent data loss. Controller Broker Manages partition leadership and rebalancing operations, ensuring consistent cluster state. Distributed Brokers Spreads data across brokers to avoid single points of failure. Dynamic Rebalancing Adjusts workload across brokers and consumers to handle changes or failures smoothly. Acknowledgment Policies (ACKs) Ensures data is safely replicated before acknowledging writes, reducing data loss risk. Log Compaction Maintains the latest data state for recovery during consumer or application failures. Client-Side Recovery Producers and consumers handle broker failures with retries and automatic rebalancing. Network Partition Handling Uses Zookeeper/KRaft to prevent split-brain scenarios and ensure data consistency. Multi-Datacenter Replication Provides disaster recovery and redundancy across regions."},{"location":"techdives/DistrubutedSystems/Kafka/#kafka-features-impacts-on-ha-and-ft","title":"Kafka features Impacts on HA and FT","text":"Feature/Configuration Configuration Details Impact on HA Impact on FT Explanation Partition Replication Set a high replication factor (e.g., <code>3</code> or <code>5</code>) High High Ensures multiple copies of data across brokers; if the leader fails, a follower can be promoted, maintaining data availability and durability. In-Sync Replicas (ISR) Use <code>acks=all</code> to ensure ISR sync before acknowledgments Moderate High Guarantees data consistency by ensuring messages are replicated to all ISR replicas before confirming writes, reducing data loss. Leader Election Mechanism Managed by Zookeeper or KRaft for automatic failover High Moderate Automatically promotes a follower to leader when the current leader fails, minimizing downtime. Controller Broker Redundancy provided by re-election if the current controller fails High Moderate Ensures the orchestrator of metadata and rebalancing has a backup, maintaining consistent cluster operations. Distributed Broker Placement Spread partitions across brokers; no two replicas on the same broker High High Reduces the risk of data unavailability and loss by preventing single points of failure. Rebalancing Strategy Configure partition reassignment for balanced broker load High Low Prevents overload on individual brokers, enhancing availability; this has less impact on data durability. Acknowledgment Policy (ACKs) Set <code>acks=all</code> for highest data durability Low High Ensures writes are only confirmed after replication to all ISR replicas, reducing the risk of data loss. Log Compaction Enable for compacted topics to retain latest state Moderate Moderate Retains the latest state of each key, useful for stateful applications; supports recovery but doesn\u2019t guarantee availability. Retention Policies Configure time-based or size-based retention High Low Maintains historical data for consumer recovery, contributing to high availability if consumers fall behind. Client Retry Mechanisms Configure producer and consumer retries High Low Enables producers and consumers to handle temporary broker unavailability, ensuring continuous operation. Consumer Group Rebalancing Set rebalancing policies to avoid bottlenecks High Low Ensures efficient load distribution among consumers, enhancing availability but minimally impacting data durability. Multi-Datacenter Replication Enable with Kafka MirrorMaker or similar tools High High Provides cross-region redundancy for both availability and fault tolerance, especially critical for disaster recovery. Backpressure Handling Use offset tracking and monitoring Moderate High Allows consumers to fall behind producers without causing data loss, enhancing fault tolerance by protecting against backpressure failures. Split-Brain Handling Managed by Zookeeper/KRaft to avoid conflicting writes Low High Prevents data inconsistency by ensuring only one leader exists per partition, critical for consistency in partitioned network conditions. Log Recovery Enable brokers to rebuild from log segments on restart Moderate High Ensures brokers can recover their state after a crash, minimizing data loss and ensuring continuity post-restart. <p>Kafka\u2019s architecture for high availability and fault tolerance ensures the system remains resilient under various failure scenarios. Through partition replication, leader election, dynamic rebalancing, and multi-datacenter replication, Kafka provides a robust infrastructure with no single points of failure and near-zero downtime, making it reliable for critical real-time data streaming and processing applications.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#what-makes-kafka-unique","title":"What Makes Kafka Unique ?","text":"<p>Append only Log-Based Architecture and High-Throughput with Low-Latency Design two of Kafka\u2019s core features that make it unique. </p>"},{"location":"techdives/DistrubutedSystems/Kafka/#1-log-based-architecture-the-foundation-of-kafkas-data-model","title":"1. Log-Based Architecture: The Foundation of Kafka\u2019s Data Model","text":"<p>Kafka\u2019s log-based architecture is what makes it fundamentally different from traditional messaging systems. It\u2019s built on the concept of a distributed, partitioned, and immutable log, allowing Kafka to scale, preserve data ordering, and enable consumers to replay data as needed. Here\u2019s a deep dive into what this architecture entails and why it\u2019s special.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#how-log-based-architecture-works","title":"How Log-Based Architecture Works","text":"<ol> <li>Topics and Partitions as Logs:</li> <li>In Kafka, each topic is split into partitions, and each partition acts as an independent log.</li> <li>Within a partition, messages are appended sequentially in an ordered, immutable fashion, with each message assigned an offset (a unique, incremental ID).</li> <li> <p>Offsets serve as pointers to each message\u2019s position within the log, making it easy for consumers to track their progress.</p> </li> <li> <p>Immutable Log Storage:</p> </li> <li>Messages in each partition are stored as an append-only log\u2014once written, messages cannot be modified or deleted (unless retention policies specify otherwise).</li> <li> <p>This immutability provides consistency and durability, as every message has a fixed position within the partition log.</p> </li> <li> <p>Replayable and Persistent Data:</p> </li> <li>Kafka\u2019s log structure allows consumers to replay messages from any offset within the retention period. Consumers can reread data for recovery, reprocessing, or analytics without impacting other consumers or producers.</li> <li>Since Kafka retains messages based on time or size-based retention policies, consumers can pick up data where they left off or reprocess older data without affecting ongoing data flows.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Kafka/#why-log-based-architecture-makes-kafka-unique","title":"Why Log-Based Architecture Makes Kafka Unique","text":"<ul> <li> <p>Efficient Ordering: Kafka maintains strict ordering within each partition since messages are written sequentially. This guarantees that messages within a partition are processed in the order they were produced, which is essential for applications like transaction logs and real-time event processing.</p> </li> <li> <p>Parallelism and Scalability: By dividing topics into multiple partitions, Kafka enables horizontal scalability. Each partition can be processed independently by separate consumers, allowing for parallel data processing and high throughput across large datasets.</p> </li> <li> <p>Fault Tolerance and Durability: The log-based structure, combined with replication (having multiple copies of each partition on different brokers), ensures that data remains durable and available even in the event of broker failures.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#kafkas-log-based-architecture-in-practice","title":"Kafka\u2019s Log-Based Architecture in Practice","text":"<ul> <li>Data Lake Ingestion: Kafka\u2019s log-based architecture makes it perfect for acting as a highly durable source of truth in a data lake architecture, where data can be stored in raw form and later reprocessed.</li> <li>Audit Trails and Event Sourcing: Kafka\u2019s immutable, ordered log allows applications to store audit logs or event-sourced data with an unalterable history, which is essential for compliance and traceability.</li> <li>Consumer Independence: Because consumers track their own offsets, they can read at their own pace, without being forced to process data in real-time. This enables flexibility for different applications (e.g., one consumer could process events in real-time, while another could do batch processing from the same log).</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#2-high-throughput-with-low-latency-design","title":"2. High-Throughput with Low-Latency Design","text":"<p>Kafka\u2019s design is optimized for handling millions of events per second with minimal delay, even under heavy load. This high throughput and low latency are achieved through a combination of disk I/O optimizations, data compression, and efficient network handling. Let\u2019s explore these in detail.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#key-components-of-kafkas-high-throughput-low-latency-design","title":"Key Components of Kafka\u2019s High-Throughput, Low-Latency Design","text":"<ol> <li>Sequential Disk I/O:</li> <li>Kafka writes messages to disk sequentially rather than performing random writes. This significantly reduces seek time, as the disk head doesn\u2019t need to jump around to write or read data.</li> <li> <p>Sequential writes take advantage of modern disks\u2019 ability to handle high-speed sequential I/O, especially in SSDs, allowing Kafka to process large volumes of data quickly.</p> </li> <li> <p>Page Cache Usage:</p> </li> <li>Kafka leverages the OS\u2019s page cache to keep frequently accessed data in memory. By utilizing page cache, Kafka avoids direct disk reads for recently accessed data, reducing read latency.</li> <li> <p>For producers writing data, Kafka batches messages in memory before flushing them to disk, improving throughput by reducing the number of disk write operations.</p> </li> <li> <p>Zero-Copy Data Transfer:</p> </li> <li>Kafka uses zero-copy technology, specifically the sendfile() system call, to transfer data directly from disk to network sockets without additional memory copies.</li> <li> <p>This allows Kafka to handle network I/O with minimal CPU usage, reducing latency and increasing throughput, especially for large messages.</p> </li> <li> <p>Batching and Compression:</p> </li> <li>Kafka batches multiple messages into a single disk write or network packet, minimizing the number of I/O operations required.</li> <li> <p>Batching not only increases efficiency but also improves compression rates by reducing network overhead. Kafka supports Gzip, Snappy, and LZ4 compression, reducing data size and thus speeding up data transfer.</p> </li> <li> <p>Network Optimization for Low Latency:</p> </li> <li>Kafka\u2019s network layer is designed to handle high-speed data transfer between producers, brokers, and consumers. Kafka supports asynchronous data processing, allowing producers to continue sending messages without waiting for each acknowledgment, which further reduces latency.</li> <li>Kafka brokers are stateful, meaning they store partition offsets and metadata locally, reducing the need to rely on external systems for routing information. This minimizes delays in routing messages to the correct consumers.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Kafka/#why-kafkas-throughput-and-latency-make-it-special","title":"Why Kafka\u2019s Throughput and Latency Make It Special","text":"<ul> <li>Handling Massive Data Streams: Kafka\u2019s design allows it to ingest millions of events per second across hundreds or thousands of partitions, making it highly scalable and capable of handling enterprise-scale data streams in real-time.</li> <li>Low-Latency Processing: Kafka\u2019s ability to process data with minimal delay is essential for real-time applications where low latency is critical, such as fraud detection, real-time analytics, and financial trading.</li> <li>Reduced Overhead for Producers and Consumers: By using batching, compression, and zero-copy technology, Kafka minimizes the load on producers and consumers, allowing them to process data efficiently without overwhelming system resources.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#kafkas-high-throughput-low-latency-design-in-practice","title":"Kafka\u2019s High-Throughput, Low-Latency Design in Practice","text":"<ul> <li>Real-Time Analytics and Monitoring: Kafka\u2019s ability to process data in near real-time enables real-time monitoring and analytics applications. Organizations can monitor user activity, system performance, or financial transactions in real-time with minimal delay.</li> <li>Microservices Communication: In microservices architectures, Kafka acts as a high-throughput backbone for event-driven communication between services. Kafka\u2019s low-latency design ensures that events are delivered quickly, enabling responsive and reactive service interactions.</li> <li>Data Pipelines and ETL: Kafka\u2019s high throughput supports data pipeline workloads where large volumes of data need to be extracted, transformed, and loaded across different systems. Kafka can handle ETL pipelines with minimal latency, making it suitable for streaming data processing.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Kafka/#summary-of-kafkas-unique-log-based-architecture-and-high-throughput-design","title":"Summary of Kafka\u2019s Unique Log-Based Architecture and High-Throughput Design","text":"Aspect Log-Based Architecture High-Throughput with Low-Latency Design Core Principle Immutable, append-only logs for each partition. Optimized for sequential writes, memory management, and efficient data transfer. Data Storage Messages are stored as ordered, append-only logs in each partition, ensuring data immutability and ordering. Batching, compression, and zero-copy transfer ensure efficient storage and minimal latency in data handling. Fault Tolerance Replication across brokers enables resilience against broker failures, as partitions can be replayed and failover to available replicas. Brokers use page cache and zero-copy I/O to keep data transfer reliable under heavy load, even in the case of high data volumes. Parallelism and Scalability Partitions allow Kafka to scale horizontally, providing parallel processing across producers and consumers, with strict ordering within each partition. Sequential I/O and batching enable Kafka to handle high-throughput workloads, supporting massive parallelism across clients. Use Cases Event sourcing, state recovery, and audit logs where ordered, immutable data is essential. Real-time monitoring, analytics, and streaming data pipelines that require fast ingestion and minimal latency."},{"location":"techdives/DistrubutedSystems/Kafka/#recommended-kafka-settings","title":"Recommended Kafka Settings","text":"<p>Here are the  organized into individual tables based on their sections. Each table provides a summary of the key settings along with recommended values and explanations.</p>"},{"location":"techdives/DistrubutedSystems/Kafka/#1-broker-level-settings","title":"1. Broker-Level Settings","text":"Setting Recommended Value Purpose <code>replication.factor</code> <code>3</code> Ensures redundancy and fault tolerance, allowing partition recovery if a broker fails. <code>min.insync.replicas</code> <code>2</code> Reduces data loss risk by ensuring at least two replicas acknowledge writes. <code>num.partitions</code> <code>6</code> (or based on load) Balances throughput and scalability; more partitions allow greater parallel processing. <code>log.retention.hours</code> <code>168</code> (7 days) Controls how long messages are retained; suitable for standard processing and replay needs. <code>log.segment.bytes</code> <code>1 GB</code> Manages the segment size for optimal disk usage and performance in log rolling. <code>log.cleanup.policy</code> <code>delete</code> or <code>compact</code> <code>delete</code> for default; <code>compact</code> for retaining only the latest version of each key. <code>compression.type</code> <code>producer</code>, <code>snappy</code>, or <code>lz4</code> Saves bandwidth and improves throughput, especially under high data volume conditions."},{"location":"techdives/DistrubutedSystems/Kafka/#2-producer-level-settings","title":"2. Producer-Level Settings","text":"Setting Recommended Value Purpose <code>acks</code> <code>all</code> Ensures that all in-sync replicas acknowledge writes, increasing reliability. <code>retries</code> <code>Integer.MAX_VALUE</code> Handles transient network issues by allowing indefinite retries, preventing message loss. <code>retry.backoff.ms</code> <code>100</code> Introduces a pause between retries, avoiding retry flooding and improving stability. <code>enable.idempotence</code> <code>true</code> Prevents duplicate messages by ensuring exactly-once semantics in data delivery. <code>batch.size</code> <code>32 KB</code> Enhances throughput by accumulating records into batches before sending them. <code>linger.ms</code> <code>5</code> Small linger time allows batches to fill, reducing network overhead without delaying sends. <code>compression.type</code> <code>snappy</code> or <code>lz4</code> Compresses data to reduce payload size, saving bandwidth and reducing transfer time."},{"location":"techdives/DistrubutedSystems/Kafka/#3-consumer-level-settings","title":"3. Consumer-Level Settings","text":"Setting Recommended Value Purpose <code>auto.offset.reset</code> <code>earliest</code> Ensures consumers start reading from the beginning if no offset is committed. <code>max.poll.records</code> <code>500</code> Controls the batch size per poll, balancing throughput and processing time. <code>session.timeout.ms</code> <code>30,000</code> Provides enough time for consumers to process data without triggering unnecessary rebalances. <code>heartbeat.interval.ms</code> <code>10,000</code> Sets the interval for heartbeat checks within the session timeout, reducing rebalance triggers. <code>fetch.min.bytes</code> <code>1 MB</code> Improves fetch efficiency by waiting for a minimum data size before retrieving. <code>fetch.max.bytes</code> <code>50 MB</code> Enables large batch sizes for high-throughput consumers, reducing network calls. <code>enable.auto.commit</code> <code>false</code> Disables automatic offset commits, allowing applications to commit only after processing."},{"location":"techdives/DistrubutedSystems/Kafka/#4-cluster-level-settings-for-high-availability-and-fault-tolerance","title":"4. Cluster-Level Settings for High Availability and Fault Tolerance","text":"Setting Recommended Value Purpose <code>min.insync.replicas</code> <code>2</code> Ensures at least two replicas must be in sync, providing better durability. <code>controlled.shutdown.enable</code> <code>true</code> Enables controlled shutdown, allowing brokers to gracefully transition leadership. <code>unclean.leader.election.enable</code> <code>false</code> Prevents out-of-sync replicas from being elected as leaders, protecting data consistency. <code>num.network.threads</code> <code>8</code> Increases concurrency for network traffic, supporting high-throughput applications. <code>num.io.threads</code> <code>8</code> Increases I/O concurrency, allowing efficient data transfer under heavy load. <code>num.replica.fetchers</code> <code>4</code> Enhances replication speed by allowing multiple fetcher threads for synchronizing replicas."},{"location":"techdives/DistrubutedSystems/Kafka/#5-zookeeper-settings","title":"5. Zookeeper Settings","text":"Setting Recommended Value Purpose <code>zookeeper.session.timeout.ms</code> <code>18,000</code> Prevents frequent Zookeeper disconnections during high loads, stabilizing metadata handling. <code>zookeeper.connection.timeout.ms</code> <code>6,000</code> Ensures reliable connections to Zookeeper, reducing the likelihood of leader election issues."},{"location":"techdives/DistrubutedSystems/Kafka/#6-kraft-kafka-raft-settings","title":"6. KRaft (Kafka Raft) Settings","text":"Setting Recommended Value Purpose <code>process.roles</code> <code>broker,controller</code> Defines the roles of Kafka nodes. A KRaft cluster typically has combined <code>broker</code> and <code>controller</code> roles, but can be split if desired. <code>controller.quorum.voters</code> List of controllers Specifies the list of controller nodes in the form <code>nodeID@hostname:port</code>, where each entry represents a voter in the Raft consensus group. <code>controller.listener.names</code> <code>CONTROLLER</code> Designates the listener name for inter-controller communication in the Raft quorum. <code>controller.heartbeat.interval.ms</code> <code>2,000</code> Sets the interval between heartbeats for controller nodes, ensuring they stay connected and responsive within the Raft quorum. <code>controller.metrics.sample.window.ms</code> <code>30,000</code> Configures the window size for collecting metrics, helping to monitor Raft performance over time. <code>controller.log.dirs</code> <code>/path/to/controller/logs</code> Specifies the directory where controller logs are stored. It\u2019s best to use a dedicated disk for controller logs to avoid I/O contention with brokers. <code>metadata.log.segment.bytes</code> <code>1 GB</code> Controls the segment size for metadata logs, managing disk usage and log rolling frequency for metadata in KRaft mode. <code>metadata.log.retention.bytes</code> <code>-1</code> (unlimited) Configures metadata log retention based on disk space, allowing infinite retention by default. Adjust based on available storage. <code>metadata.log.retention.ms</code> <code>604,800,000</code> (7 days) Retains metadata for a set duration; typically configured for a week to enable rollback in case of issues. <code>controller.socket.timeout.ms</code> <code>30,000</code> Sets the timeout for controller-to-controller connections, ensuring stability during network issues. <code>leader.imbalance.check.interval.seconds</code> <code>300</code> (5 minutes) Defines the interval at which the controller checks for leader imbalance, helping to maintain even load distribution across brokers. <p>Reference Links:</p> <p>https://www.hellointerview.com/learn/system-design/deep-dives/kafka</p>"},{"location":"techdives/DistrubutedSystems/Redis/","title":"Redis","text":"<p>Redis is an open-source, in-memory data structure store that serves as a database, cache, message broker, and streaming engine. Its versatility and high performance make it a popular choice for various applications. This comprehensive guide delves into Redis's architecture, data structures, commands, deployment strategies, and best practices.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#1-introduction-to-redis","title":"1. Introduction to Redis","text":"<p>Redis, short for Remote Dictionary Server, is renowned for its speed and flexibility. Operating primarily in memory, it supports various data structures and offers features like replication, persistence, and high availability.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#2-core-data-structures","title":"2. Core Data Structures","text":""},{"location":"techdives/DistrubutedSystems/Redis/#21-strings","title":"2.1. Strings","text":"<p>Definition: A string in Redis is a binary-safe sequence of bytes. It's the most basic data type in Redis, with a maximum size of 512 MB.</p> <p>Examples: - Set and get a simple string:     <pre><code>SET key \"Hello, World!\"\nGET key\n</code></pre> - Increment a numerical value:     <pre><code>SET counter 10\nINCR counter      // Result: 11\nINCRBY counter 5  // Result: 16\n</code></pre></p> <p>Underlying Data Structure: Dynamic String (SDS - Simple Dynamic String)</p> <p>Time Complexity: - <code>SET key value</code>: O(1) - <code>GET key</code>: O(1) - <code>INCR key</code>: O(1)</p> <p>Best Use Cases: - Caching: Store frequently accessed values. - Counters: Track counts for metrics or events. - Session Data: Store serialized JSON for user sessions.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#22-hashes","title":"2.2. Hashes","text":"<p>Definition: A hash in Redis is a collection of field-value pairs, ideal for representing objects (e.g., user profiles).</p> <p>Examples: - Creating and managing user data in a hash:     <pre><code>HSET user:1001 name \"Alice\" age 30 city \"New York\"\nHGET user:1001 name           // Returns \"Alice\"\nHGETALL user:1001             // Returns all key-value pairs in hash\n</code></pre></p> <p>Underlying Data Structure: Hash Table or ZipList (for small hashes)</p> <p>Time Complexity: - <code>HSET key field value</code>: O(1) (amortized) - <code>HGET key field</code>: O(1) - <code>HGETALL key</code>: O(N) (N being the number of fields in the hash)</p> <p>Best Use Cases: - Storing Objects: Represent complex entities. - Configuration Settings: Store configurations as a set of key-value pairs.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#23-lists","title":"2.3. Lists","text":"<p>Definition: A list is an ordered collection of strings, allowing elements to be added at either end, functioning much like a linked list.</p> <p>Examples: - Using a list to store recent activity:     <pre><code>LPUSH recent_activity \"login\" \"view_profile\" \"logout\"\nLRANGE recent_activity 0 -1   // Fetches all elements in the list\n</code></pre></p> <p>Underlying Data Structure: Linked List or QuickList (optimized for performance and memory usage)</p> <p>Time Complexity: - <code>LPUSH key value</code>: O(1) - <code>LRANGE key start stop</code>: O(S+N) (S being the starting offset and N the number of elements retrieved)</p> <p>Best Use Cases: - Activity Streams: Store recent actions or logs. - Task Queues: Implement FIFO or LIFO queues.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#24-sets","title":"2.4. Sets","text":"<p>Definition: Sets are unordered collections of unique strings, ideal for performing set operations.</p> <p>Examples: - Managing unique tags:     <pre><code>SADD tags \"redis\" \"database\" \"in-memory\"\nSMEMBERS tags                 // Returns all unique tags\n</code></pre></p> <p>Underlying Data Structure: Hash Table or IntSet (for small sets of integers)</p> <p>Time Complexity: - <code>SADD key value</code>: O(1) - <code>SMEMBERS key</code>: O(N) (N being the number of elements in the set) - <code>SINTER key1 key2 ... keyN</code>: O(N*M) (N being the number of sets and M the smallest set)</p> <p>Best Use Cases: - Unique Values: Track unique items like IP addresses. - Social Networks: Represent social relationships (e.g., friends, followers).</p>"},{"location":"techdives/DistrubutedSystems/Redis/#25-sorted-sets","title":"2.5. Sorted Sets","text":"<p>Definition: Similar to sets, but with an associated score that allows elements to be sorted by score.</p> <p>Examples: - Storing leaderboard data:     <pre><code>ZADD leaderboard 100 \"Alice\" 200 \"Bob\"\nZRANGE leaderboard 0 -1 WITHSCORES\n</code></pre></p> <p>Underlying Data Structure: Skip List and Hash Table (for fast access and sorted ordering)</p> <p>Time Complexity: - <code>ZADD key score member</code>: O(log(N)) - <code>ZRANGE key start stop</code>: O(log(N)+M) (M being the number of elements returned)</p> <p>Best Use Cases: - Leaderboards: Rank users based on scores. - Event Prioritization: Sort items by priority or timestamp.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#26-bitmaps","title":"2.6. Bitmaps","text":"<p>Definition: Bitmaps use strings to store and manipulate individual bits, offering efficient binary storage.</p> <p>Examples: - Tracking user flags:     <pre><code>SETBIT user_flags 5 1         // Sets the 6th bit to 1\nGETBIT user_flags 5           // Returns 1\n</code></pre></p> <p>Underlying Data Structure: String (each bit is set or retrieved from the byte representation)</p> <p>Time Complexity: - <code>SETBIT key offset value</code>: O(1) - <code>GETBIT key offset</code>: O(1) - <code>BITCOUNT key</code>: O(N) (N being the length of the string)</p> <p>Best Use Cases: - Feature Flags: Toggle features for users. - Activity Tracking: Record binary states like presence or attendance.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#27-hyperloglogs","title":"2.7. HyperLogLogs","text":"<p>Definition: HyperLogLog is a probabilistic structure for approximating unique element counts.</p> <p>Examples: - Counting unique visitors:     <pre><code>PFADD visitors \"user1\" \"user2\"\nPFCOUNT visitors             // Returns approximate unique count\n</code></pre></p> <p>Underlying Data Structure: Sparse and Dense Data Representations (optimized for low memory usage)</p> <p>Time Complexity: - <code>PFADD key element</code>: O(1) - <code>PFCOUNT key</code>: O(1)</p> <p>Best Use Cases: - Unique Counting: Approximate counts of unique views or visitors. - Low-Memory Use: Ideal for large datasets with memory constraints.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#28-streams","title":"2.8. Streams","text":"<p>Definition: A stream is a log-like data structure for managing continuous data flows, supporting consumer groups.</p> <p>Examples: - Tracking event streams:     <pre><code>XADD mystream * name \"Alice\" action \"login\"\nXREAD COUNT 2 STREAMS mystream 0\n</code></pre></p> <p>Underlying Data Structure: Radix Tree (used for efficient storage and traversal of stream entries)</p> <p>Time Complexity: - <code>XADD key * field value</code>: O(log(N)) (N being the number of items in the stream) - <code>XREAD key start stop</code>: O(log(N)+M) (M being the number of items returned)</p> <p>Best Use Cases: - Event Sourcing: Track ordered events or logs. - Message Queues: Reliable message distribution with consumer groups.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#29-geospatial-indexes","title":"2.9. Geospatial Indexes","text":"<p>Definition: Redis provides commands for storing and querying location data with latitude and longitude.</p> <p>Examples: - Adding and querying locations:     <pre><code>GEOADD cities 13.361389 38.115556 \"Palermo\"\nGEORADIUS cities 15 37 200 km\n</code></pre></p> <p>Underlying Data Structure: Geohash with Sorted Sets (uses sorted sets for indexing)</p> <p>Time Complexity: - <code>GEOADD key longitude latitude member</code>: O(log(N)) - <code>GEORADIUS key longitude latitude radius</code>: O(log(N)+M) (M being the number of results)</p> <p>Best Use Cases: - Location-Based Services: Search and display nearby locations. - Geofencing: Detect whether users enter specific geographic zones.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#3-commands-table","title":"3. Commands Table","text":"Data Structure Definition Example Commands Best Use Cases Time Complexity Strings Binary-safe sequences of bytes for text or binary data. <code>SET key value</code>, <code>GET key</code>, <code>INCR key</code>, <code>DECR key</code>, <code>APPEND key value</code>, <code>STRLEN key</code> Caching, counters, session data <code>SET</code>: O(1), <code>GET</code>: O(1), <code>INCR</code>: O(1), <code>APPEND</code>: O(N) Hashes Collection of key-value pairs, suitable for objects. <code>HSET key field value</code>, <code>HGET key field</code>, <code>HGETALL key</code>, <code>HDEL key field</code>, <code>HLEN key</code> Storing objects, configuration settings <code>HSET</code>: O(1), <code>HGET</code>: O(1), <code>HGETALL</code>: O(N), <code>HLEN</code>: O(1) Lists Ordered collection of strings, acts like a linked list. <code>LPUSH key value</code>, <code>RPUSH key value</code>, <code>LPOP key</code>, <code>RPOP key</code>, <code>LRANGE key start stop</code>, <code>LLEN key</code> Activity streams, task queues <code>LPUSH</code>: O(1), <code>LRANGE</code>: O(S+N), <code>LLEN</code>: O(1) Sets Unordered collections of unique strings, optimized for sets. <code>SADD key value</code>, <code>SREM key value</code>, <code>SMEMBERS key</code>, <code>SISMEMBER key value</code>, <code>SUNION key1 key2</code>, <code>SINTER key1 key2</code> Unique values, social relationships <code>SADD</code>: O(1), <code>SMEMBERS</code>: O(N), <code>SINTER</code>: O(N*M) Sorted Sets Sets with scores, allowing elements to be sorted by score. <code>ZADD key score member</code>, <code>ZRANGE key start stop WITHSCORES</code>, <code>ZREM key member</code>, <code>ZSCORE key member</code>, <code>ZREVRANGE key start stop</code>, <code>ZCOUNT key min max</code> Leaderboards, event prioritization <code>ZADD</code>: O(log(N)), <code>ZRANGE</code>: O(log(N)+M), <code>ZSCORE</code>: O(1) Bitmaps Stores and manipulates bits in a binary-safe string. <code>SETBIT key offset value</code>, <code>GETBIT key offset</code>, <code>BITCOUNT key</code>, <code>BITOP operation destkey key1 key2</code> Feature flags, activity tracking <code>SETBIT</code>: O(1), <code>GETBIT</code>: O(1), <code>BITCOUNT</code>: O(N) HyperLogLogs Probabilistic structure for approximate unique counts. <code>PFADD key element</code>, <code>PFCOUNT key</code>, <code>PFMERGE destkey sourcekey1 sourcekey2</code> Unique counting, low-memory usage <code>PFADD</code>: O(1), <code>PFCOUNT</code>: O(1), <code>PFMERGE</code>: O(N) Streams Log-like structure for managing continuous data flows. <code>XADD key * field value</code>, <code>XREAD COUNT n STREAMS key</code>, <code>XGROUP CREATE key group consumer_id</code>, <code>XACK key group message_id</code>, <code>XDEL key message_id</code>, <code>XINFO key</code>, <code>XLEN key</code>, <code>XTRIM key MAXLEN ~ count</code> Event sourcing, message queues <code>XADD</code>: O(log(N)), <code>XREAD</code>: O(log(N)+M), <code>XGROUP</code>: O(1), <code>XACK</code>: O(1) Geospatial Indexes Stores and queries location data with latitude and longitude. <code>GEOADD key longitude latitude member</code>, <code>GEODIST key member1 member2</code>, <code>GEORADIUS key longitude latitude radius m km</code>, <code>GEORADIUSBYMEMBER key member radius m km</code>, <code>GEOHASH key member</code> Location-based services, geofencing <code>GEOADD</code>: O(log(N)), <code>GEORADIUS</code>: O(log(N)+M)"},{"location":"techdives/DistrubutedSystems/Redis/#4-persistence-and-durability","title":"4. Persistence and Durability","text":"<p>Redis operates primarily as an in-memory database, prioritizing speed and low-latency operations. However, it provides two main persistence mechanisms to ensure data durability:</p> <ul> <li>Snapshotting (RDB): Redis can take periodic snapshots of the data in memory and save them to disk as a \u201cpoint-in-time\u201d snapshot. The RDB file is a compact representation of Redis data at the time of saving. This method is suitable for use cases where:</li> <li>You can afford some data loss if the server crashes between snapshots.</li> <li>Data needs to be saved periodically (e.g., every few minutes).</li> </ul> <p>Advantages: Lower I/O overhead, compact file size.</p> <p>Disadvantages: Risk of data loss between snapshots if Redis crashes.</p> <ul> <li>Append-Only File (AOF): In AOF mode, Redis logs every write operation (like <code>SET</code> or <code>INCR</code>) received by the server, appending each to a file. This approach provides a more durable form of persistence because every operation is logged in real-time or semi-real-time.</li> </ul> <p>Advantages: Better durability, logs every operation for more frequent data persistence.</p> <p>Disadvantages: Larger file sizes, higher I/O usage.</p> <p>Choosing Between RDB and AOF: You can use either or both of these methods in combination based on your application needs. For example, using both allows for rapid recovery (RDB) with high durability (AOF).</p>"},{"location":"techdives/DistrubutedSystems/Redis/#5-replication-and-high-availability","title":"5. Replication and High Availability","text":"<p>Redis supports replication to create replicas of the primary (master) instance, enabling multiple read replicas and providing redundancy.</p> <ul> <li> <p>Master-Replica Replication: A master Redis instance can replicate data to any number of replica instances, which can then serve read-only queries. This setup enhances scalability by spreading read requests across replicas and ensuring data availability in case the primary instance fails.</p> </li> <li> <p>Redis Sentinel: Redis Sentinel is a high-availability solution that monitors Redis instances. It automatically promotes one of the replicas to the master role if the current master goes down, providing automatic failover and notifications. Sentinel also provides monitoring and notifications.</p> </li> </ul> <p>Best for: - Applications requiring high availability with automatic failover. - Scenarios where read-heavy workloads benefit from scaling reads across multiple replicas.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#6-clustering-and-scalability","title":"6. Clustering and Scalability","text":"<p>Redis supports sharding through Redis Cluster, which enables data partitioning across multiple nodes, allowing horizontal scalability and distributed storage. Redis Cluster uses hash slots to determine data distribution across nodes, ensuring no single node contains the entire dataset.</p> <ul> <li> <p>Hash Slot Mechanism: Redis Cluster divides the keyspace into 16,384 hash slots, assigning a subset of these slots to each node. Keys are then hashed into these slots, which determines their storage node.</p> <ol> <li> <p>Hash Slot Mapping: Redis Cluster uses 16,384 slots as a way to divide the keyspace. Every key is assigned to a specific slot by applying a hashing function (called CRC16) that maps the key to one of these 16,384 slots.</p> </li> <li> <p>Multiple Keys per Slot: Each hash slot can contain many keys. This means you can store millions of keys, not just 16,384.</p> </li> <li> <p>Distribution Across Nodes: In a Redis Cluster, each node is responsible for a subset of the 16,384 slots. For example:</p> </li> <li>If you have a 3-node Redis Cluster, each node might manage around 5,461 slots.</li> <li> <p>Redis assigns keys to slots, and the slot location determines which node will store the key.</p> </li> <li> <p>Dynamic Scaling: When more nodes are added to the cluster, the slots are rebalanced, and some slots are reassigned to the new nodes. Redis automatically adjusts the key distribution to accommodate the additional nodes, enabling the cluster to scale horizontally without needing to rewrite keys.</p> </li> </ol> </li> <li> <p>Automatic Failover: Redis Cluster supports failover, ensuring high availability by electing a new primary if a node fails.</p> </li> </ul> <p>Considerations: - Redis Cluster supports most single-key commands, but multi-key operations are restricted unless all keys map to the same slot. - Clustering can increase complexity in handling data operations across nodes but is essential for large datasets needing horizontal scalability.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#7-security-considerations","title":"7. Security Considerations","text":"<p>While Redis is often deployed in secure, private networks, security remains essential, especially for production environments:</p> <ul> <li>Authentication: Redis can require clients to authenticate with the <code>AUTH</code> command. Although not enabled by default, setting up <code>AUTH</code> is recommended for production instances.</li> <li>Network Security: Redis should ideally be bound to localhost (<code>bind 127.0.0.1</code>) and accessed through trusted networks or VPNs, especially if running on public cloud services. Redis supports setting <code>bind</code> and <code>requirepass</code> configuration directives.</li> <li>Encryption: For environments needing encryption, Redis supports TLS/SSL for encrypted communication between clients and servers. This is essential for compliance requirements or if Redis is accessible over the internet.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#8-client-libraries-and-tools","title":"8. Client Libraries and Tools","text":"<p>Redis has a robust ecosystem with libraries for popular programming languages, making it easy to integrate Redis across platforms:</p> <ul> <li>Python: <code>redis-py</code></li> <li>Java: <code>Jedis</code>, <code>Lettuce</code></li> <li>JavaScript: <code>ioredis</code>, <code>node-redis</code></li> <li>Go: <code>go-redis</code></li> </ul> <p>Additionally, Redis CLI and Redis Insight are commonly used tools for managing and monitoring Redis instances.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#9-rediss-single-threaded-nature-and-atomic-operations","title":"9. Redis\u2019s Single-Threaded Nature and Atomic Operations","text":"<p>Redis uses a single-threaded event loop to handle client requests, which makes operations simpler and efficient. This single-threaded model has specific implications:</p> <ul> <li> <p>Atomic Operations: All Redis commands are atomic because Redis processes each command sequentially. Even if multiple clients issue commands simultaneously, Redis processes one command at a time. This ensures that operations like <code>INCR</code> or multi-step transactions are inherently thread-safe and don't require locks.</p> </li> <li> <p>Efficiency: Since Redis is single-threaded, it avoids the complexity of thread management and the overhead of context switching, which helps maintain its high-speed performance. Redis\u2019s speed is due to efficient data structures, in-memory storage, and minimal CPU usage.</p> </li> </ul> <p>Impact on Use Cases: - In scenarios where atomicity is essential, such as counters or distributed locks, Redis's single-threaded nature provides strong consistency guarantees. - For CPU-bound workloads, Redis may be limited by its single-threaded design. However, since Redis is primarily I/O-bound, it scales well for read-heavy or network-intensive applications.</p> <p>Benefits of Single-Threaded Execution: - Simplicity in design and implementation, eliminating race conditions. - Predictable performance with guaranteed atomicity.</p> <p>Drawbacks: - Limited to single-core processing for request handling. For CPU-bound tasks, Redis's single-threading may become a bottleneck, but horizontal scaling (e.g., Redis Cluster) can help distribute the load.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#10-approximate-requests-per-second-rps","title":"10. Approximate Requests Per Second (RPS)","text":"Operation Type Description Approximate RPS per Instance Notes Simple Reads (<code>GET</code>) Basic read operation for retrieving a single value 100,000 - 150,000 RPS Higher performance achievable on optimized hardware Simple Writes (<code>SET</code>) Basic write operation for setting a single key-value pair 100,000 - 150,000 RPS Slightly reduced if using AOF with <code>always</code> persistence Complex Reads (e.g., <code>ZRANGE</code>) Reads on complex data structures like sorted sets 50,000 - 80,000 RPS Lower due to additional computation and memory access Complex Writes (e.g., <code>ZADD</code>) Writes on complex data structures like sorted sets 50,000 - 80,000 RPS Additional processing to maintain sorted order impacts performance With AOF (Append-Only File) Writes with <code>always</code> mode persistence (AOF) 60,000 - 80,000 RPS Slightly reduced due to disk I/O overhead Snapshotting (RDB) Writes with periodic snapshots (RDB) 80,000 - 100,000 RPS Minimal impact on RPS except during snapshotting periods when CPU/I/O load is higher With Redis Cluster Distributed across multiple nodes Millions of RPS (scales with nodes) Redis Cluster allows horizontal scaling, increasing RPS proportionally with additional nodes"},{"location":"techdives/DistrubutedSystems/Redis/#notes","title":"Notes:","text":"<ul> <li>Higher RPS may be achieved on premium hardware with more RAM, SSDs, and faster CPUs.</li> <li>Network Latency also affects RPS in production, especially for distributed deployments or high-frequency access patterns.</li> <li>Redis\u2019s single-threaded nature means each instance handles requests in sequence, making horizontal scaling via Redis Cluster beneficial for handling massive workloads.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#11-use-cases-we-can-use-redis-in","title":"11. Use Cases We Can Use Redis In","text":""},{"location":"techdives/DistrubutedSystems/Redis/#111-caching","title":"11.1. Caching","text":""},{"location":"techdives/DistrubutedSystems/Redis/#overview","title":"Overview","text":"<p>Redis is highly effective as a caching layer, providing extremely low-latency data retrieval that reduces the load on backend databases and improves application performance.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#how-it-works","title":"How It Works","text":"<ol> <li>Cache Common Data: Redis is commonly used to cache data that is expensive to compute or retrieve, such as:</li> <li>API responses</li> <li>Frequently queried database results</li> <li> <p>Configuration settings</p> </li> <li> <p>Expiration and Eviction: Redis supports configurable expiration for keys, which allows cached data to expire after a specific time. It also supports eviction policies (like LRU or LFU) to automatically remove older or less-used items when memory limits are reached.</p> </li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#implementation-steps","title":"Implementation Steps","text":"<ul> <li> <p>Set Up Caching Logic: In your application, implement caching logic where data is first checked in Redis. If the key doesn\u2019t exist in Redis (cache miss), retrieve it from the database, store it in Redis, and serve it to the client.     <pre><code>if not redis.exists(\"user:123\"):\n    data = fetch_from_database(\"user:123\")\n    redis.setex(\"user:123\", 3600, data)  # Cache for 1 hour\n</code></pre></p> </li> <li> <p>Example Commands:     <pre><code>SETEX key value TTL     # Sets a value with an expiration time (TTL)\nGET key                 # Retrieves value\nDEL key                 # Deletes a cached key\n</code></pre></p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#benefits","title":"Benefits","text":"<ul> <li>Improved Performance: Drastically reduces database load and response time for frequently accessed data.</li> <li>Cost Efficiency: Reduces database costs and resources by offloading repeated queries to Redis.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#112-session-management","title":"11.2. Session Management","text":""},{"location":"techdives/DistrubutedSystems/Redis/#overview_1","title":"Overview","text":"<p>Redis is commonly used as a session store for web applications, especially in distributed environments where sharing session data across multiple servers is critical.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#how-it-works_1","title":"How It Works","text":"<ol> <li>Store Session Data: Redis stores session data, often as a hash, using a unique session identifier as the key.</li> <li>Session Expiry: Redis supports setting time-to-live (TTL) for session keys, allowing automatic expiration of inactive sessions.</li> <li>Distributed Access: Applications running on multiple servers can access the same session data via Redis, providing a centralized session store.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#implementation-steps_1","title":"Implementation Steps","text":"<ul> <li> <p>Set Up Session Key: For each user session, generate a unique session ID and store session data in Redis.     <pre><code>HSET session:abc123 user_id 456 name \"Alice\"\nEXPIRE session:abc123 1800   # Session expires after 30 minutes\n</code></pre></p> </li> <li> <p>Example Commands:     <pre><code>HSET session:&lt;session_id&gt; field value   # Sets session data as a hash\nHGETALL session:&lt;session_id&gt;            # Retrieves all session data\nEXPIRE session:&lt;session_id&gt; ttl         # Sets expiration for session\n</code></pre></p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#benefits_1","title":"Benefits","text":"<ul> <li>Scalability: Redis\u2019s low latency allows fast session retrieval, even in high-traffic applications.</li> <li>Data Consistency: Distributed applications can share session states consistently across instances.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#113-real-time-analytics","title":"11.3. Real-Time Analytics","text":""},{"location":"techdives/DistrubutedSystems/Redis/#overview_2","title":"Overview","text":"<p>Redis\u2019s support for data structures like HyperLogLogs, sorted sets, and streams enables it to handle real-time analytics, tracking metrics, counts, and trends without requiring a traditional database.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#how-it-works_2","title":"How It Works","text":"<ol> <li>HyperLogLog for Unique Counts: Track unique visitors, page views, and other metrics using HyperLogLog, which approximates the count of unique items.</li> <li>Sorted Sets for Ranking: Track and rank items based on scores, useful for leaderboards or tracking user activity levels.</li> <li>Streams for Event Data: Redis streams can capture continuous event data, making it possible to analyze data in real time or replay it later.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#implementation-steps_2","title":"Implementation Steps","text":"<ul> <li> <p>HyperLogLog for Unique Visitors:     <pre><code>PFADD visitors:today user123      # Adds a unique user\nPFCOUNT visitors:today            # Gets approximate unique visitor count\n</code></pre></p> </li> <li> <p>Sorted Set for Leaderboards:     <pre><code>ZADD leaderboard 1000 user123     # Adds user with score\nZREVRANGE leaderboard 0 10 WITHSCORES   # Retrieves top 10 users\n</code></pre></p> </li> <li> <p>Stream for Event Tracking:     <pre><code>XADD events * type \"click\" user \"user123\"  # Adds event to stream\nXREAD COUNT 10 STREAMS events 0            # Reads 10 most recent events\n</code></pre></p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#benefits_2","title":"Benefits","text":"<ul> <li>Real-Time Insights: Instantly capture and analyze data for immediate insights.</li> <li>Cost-Effective: Avoids the need for complex and costly analytics platforms for basic tracking.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#114-message-brokering","title":"11.4. Message Brokering","text":""},{"location":"techdives/DistrubutedSystems/Redis/#overview_3","title":"Overview","text":"<p>Redis\u2019s publish/subscribe (pub/sub) feature allows it to act as a lightweight message broker, facilitating real-time communication between distributed applications.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#how-it-works_3","title":"How It Works","text":"<ol> <li>Publisher: A service or application publishes messages to a specific channel.</li> <li>Subscriber: Other services or applications subscribe to that channel to receive messages.</li> <li>Message Delivery: Messages are delivered to all active subscribers listening to the channel at the time of publication.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#implementation-steps_3","title":"Implementation Steps","text":"<ul> <li> <p>Set Up Publisher:     <pre><code>PUBLISH channel_name \"New user registered\"   # Publishes a message to a channel\n</code></pre></p> </li> <li> <p>Set Up Subscriber:     <pre><code>SUBSCRIBE channel_name                      # Subscribes to a channel\n</code></pre></p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#example-commands","title":"Example Commands","text":"<ul> <li> <p>Publish a message:     <pre><code>PUBLISH notifications \"User123 has logged in\"\n</code></pre></p> </li> <li> <p>Subscribe to channel:     <pre><code>SUBSCRIBE notifications\n</code></pre></p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#benefits_3","title":"Benefits","text":"<ul> <li>Real-Time Communication: Ideal for real-time updates, notifications, and event streaming between services.</li> <li>Simplicity: Redis provides pub/sub capabilities without the complexity of dedicated message brokers.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#115-geospatial-applications","title":"11.5. Geospatial Applications","text":""},{"location":"techdives/DistrubutedSystems/Redis/#overview_4","title":"Overview","text":"<p>Redis provides geospatial commands that make it suitable for applications requiring location-based searches and geofencing, such as ride-sharing or delivery tracking.</p> <p>Redis uses a geohashing-like approach to handle geospatial data, but it combines it with sorted sets to enable efficient location-based queries, Redis converts latitude and longitude coordinates into a geohash-like value, which is then stored as a score in a sorted set. This encoding allows Redis to store location data compactly and enables efficient proximity queries.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#how-it-works_4","title":"How It Works","text":"<ol> <li>Store Location Data: Use <code>GEOADD</code> to add locations with latitude, longitude, and an associated member (e.g., user ID or landmark).</li> <li>Location-Based Queries: Redis allows querying locations within a specified radius and finding distances between locations.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#implementation-steps_4","title":"Implementation Steps","text":"<ul> <li> <p>Store Locations:     <pre><code>GEOADD cities 13.361389 38.115556 \"Palermo\"\nGEOADD cities 15.087269 37.502669 \"Catania\"\n</code></pre></p> </li> <li> <p>Retrieve Locations in Radius:     <pre><code>GEORADIUS cities 15 37 100 km           # Finds cities within 100 km of coordinates (15, 37)\nGEORADIUSBYMEMBER cities \"Palermo\" 200 km   # Finds locations within 200 km of \"Palermo\"\n</code></pre></p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#example-commands_1","title":"Example Commands","text":"<ul> <li> <p>Add a Location:     <pre><code>GEOADD locations 40.7128 -74.0060 \"New York\"\n</code></pre></p> </li> <li> <p>Find Nearby Locations:     <pre><code>GEORADIUS locations -74.0060 40.7128 50 km\n</code></pre></p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#benefits_4","title":"Benefits","text":"<ul> <li>Efficient Geospatial Queries: Handle location-based searches and distance calculations directly in Redis.</li> <li>Ideal for Proximity-Based Services: Useful for applications that rely on nearby searches, like delivery and ride-sharing.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#116-summary-table","title":"11.6 Summary Table","text":"Use Case Description Key Commands Benefits Caching Store frequently accessed data for faster retrieval. <code>SETEX</code>, <code>GET</code>, <code>DEL</code> Reduces latency, lowers database load Session Management Store user sessions for distributed web applications. <code>HSET</code>, <code>HGETALL</code>, <code>EXPIRE</code> Fast, centralized session access across servers Real-Time Analytics Track metrics, counts, and trends in real time. <code>PFADD</code>, <code>PFCOUNT</code>, <code>ZADD</code>, <code>XADD</code>, <code>XREAD</code> Provides instant insights, reduces need for dedicated platforms Message Brokering Facilitate real-time communication between services. <code>PUBLISH</code>, <code>SUBSCRIBE</code> Real-time updates, lightweight message broker Geospatial Apps Perform location-based searches and calculations. <code>GEOADD</code>, <code>GEORADIUS</code>, <code>GEORADIUSBYMEMBER</code> Efficient geospatial operations for location-based services"},{"location":"techdives/DistrubutedSystems/Redis/#12-redis-issues","title":"12. Redis Issues","text":"<p>Let's dive deep into some key challenges, such as hot key issues, cache avalanche, cache penetration, cache stampede, and their corresponding solutions.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#121-hot-key-issue","title":"12.1. Hot Key Issue","text":""},{"location":"techdives/DistrubutedSystems/Redis/#description","title":"Description","text":"<p>A hot key issue occurs when a single key in Redis is accessed extremely frequently, causing uneven load distribution. This can happen in applications where certain data (e.g., a trending topic or popular product) is heavily requested. A hot key can overwhelm the Redis server or specific nodes in a Redis Cluster, leading to latency spikes and reduced performance.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#causes","title":"Causes","text":"<ul> <li>Popularity Bias: Some data items are inherently more popular (e.g., trending content).</li> <li>Skewed Data Access Patterns: Certain keys might be accessed far more than others.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#solutions","title":"Solutions","text":"<ol> <li>Replicate the Key:</li> <li> <p>Store multiple copies of the hot key in Redis (e.g., <code>hotkey_1</code>, <code>hotkey_2</code>, <code>hotkey_3</code>). Then, use application logic to randomly pick a replica each time the key is accessed. This distributes the load across multiple keys.</p> </li> <li> <p>Use Redis Cluster:</p> </li> <li> <p>In a Redis Cluster, distribute the load by sharding hot keys across nodes. This may not completely eliminate the issue, but it can help mitigate its impact by spreading access across the cluster.</p> </li> <li> <p>Client-Side Caching:</p> </li> <li> <p>Implement a local cache on the client side or within the application servers to reduce the frequency of requests to Redis. This technique works well when the data is static or changes infrequently.</p> </li> <li> <p>Use a Load-Balancing Proxy:</p> </li> <li>Use a Redis proxy (like Twemproxy or Codis) to balance requests to the hot key across multiple Redis instances.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#122-cache-avalanche","title":"12.2. Cache Avalanche","text":""},{"location":"techdives/DistrubutedSystems/Redis/#description_1","title":"Description","text":"<p>A cache avalanche occurs when many cache keys expire at once, leading to a sudden flood of requests to the backend database as the cache misses accumulate. This can overwhelm the database, causing latency spikes or even outages.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#causes_1","title":"Causes","text":"<ul> <li>Simultaneous Expiration: Many keys are set with the same expiration time, leading to a large volume of cache misses at once.</li> <li>Backend Dependency: High reliance on Redis with insufficient backend capacity.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#solutions_1","title":"Solutions","text":"<ol> <li>Add Randomized Expiry Times:</li> <li> <p>Set expiration times with a randomized offset (e.g., add a few seconds or minutes randomly) to avoid simultaneous expiry. For example:      <pre><code>ttl = 3600 + random.randint(-300, 300)  # 3600 seconds +/- 5 minutes\n</code></pre></p> </li> <li> <p>Cache Pre-Warming:</p> </li> <li> <p>Preload critical data into Redis before it expires. You can use background jobs to check key expiration and refresh data periodically.</p> </li> <li> <p>Lazy Loading with Synchronized Locking:</p> </li> <li> <p>Use a distributed locking mechanism to ensure that only one thread refreshes the data in Redis, while others wait. This can prevent multiple processes from overloading the backend database.</p> </li> <li> <p>Fallback Graceful Degradation:</p> </li> <li>Implement a mechanism that provides stale or default data temporarily if the database is overwhelmed. This approach buys time until the cache is repopulated.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#123-cache-penetration","title":"12.3. Cache Penetration","text":""},{"location":"techdives/DistrubutedSystems/Redis/#description_2","title":"Description","text":"<p>Cache penetration happens when requests for non-existent keys repeatedly bypass the cache and go to the backend database. Since these keys don\u2019t exist, they are never cached, resulting in continuous database requests, increasing the load on the database.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#causes_2","title":"Causes","text":"<ul> <li>Invalid Keys: Frequent requests for keys that are not in the cache or backend database.</li> <li>Malicious Requests: Often caused by bots or attacks requesting non-existent data.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#solutions_2","title":"Solutions","text":"<ol> <li>Cache Null Values:</li> <li> <p>When a request results in a database miss, store a null value in Redis with a short TTL (e.g., 5 minutes). Future requests for the same key will hit Redis instead of the database. Example:      <pre><code>if not redis.exists(\"non_existent_key\"):\n    data = fetch_from_database(\"non_existent_key\")\n    if data is None:\n        redis.setex(\"non_existent_key\", 300, None)  # Cache null for 5 minutes\n</code></pre></p> </li> <li> <p>Input Validation:</p> </li> <li> <p>Filter out clearly invalid requests before querying Redis or the backend. For instance, if certain key patterns are obviously invalid, ignore them early in the request flow.</p> </li> <li> <p>Bloom Filter:</p> </li> <li>Implement a Bloom filter at the cache layer to quickly determine if a key likely exists in the database. This reduces unnecessary database calls by discarding requests for non-existent keys without hitting Redis or the backend.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#124-cache-stampede","title":"12.4. Cache Stampede","text":""},{"location":"techdives/DistrubutedSystems/Redis/#description_3","title":"Description","text":"<p>A cache stampede occurs when multiple threads or clients attempt to update an expired cache key simultaneously, causing a burst of requests to the backend database. This is similar to a cache avalanche but occurs at the key level rather than across all keys.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#causes_3","title":"Causes","text":"<ul> <li>Simultaneous Cache Expiry: Multiple clients try to fetch and set the same key after it expires, resulting in redundant load on the database.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#solutions_3","title":"Solutions","text":"<ol> <li>Mutex Locking:</li> <li> <p>Use a distributed lock (e.g., Redlock) to ensure that only one client refreshes the cache while others wait. This reduces the load on the database:      <pre><code># Pseudocode for acquiring a lock\nif redis.setnx(\"lock:key\", 1):\n    try:\n        # Fetch and cache the data\n        data = fetch_from_database(\"key\")\n        redis.setex(\"key\", 3600, data)\n    finally:\n        redis.delete(\"lock:key\")  # Release the lock\n</code></pre></p> </li> <li> <p>Early Re-Caching (Soft Expiration):</p> </li> <li> <p>Implement soft expiration by setting a short expiration on frequently requested keys and refreshing them asynchronously before they expire. This keeps the data fresh in Redis and avoids a stampede.</p> </li> <li> <p>Leverage Stale Data:</p> </li> <li>Allow clients to use slightly stale data by extending the expiration time if a refresh is already in progress. This minimizes the load on the backend.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#125-memory-and-eviction-issues","title":"12.5. Memory and Eviction Issues","text":""},{"location":"techdives/DistrubutedSystems/Redis/#description_4","title":"Description","text":"<p>Redis operates in memory, so it has a limited capacity. When Redis reaches its memory limit, it must evict keys to free up space, potentially removing critical data. Improper eviction policies can lead to cache churn and data inconsistency.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#causes_4","title":"Causes","text":"<ul> <li>Memory Limits: Redis's memory is full, and eviction is required.</li> <li>Improper Eviction Policies: The chosen policy does not align with the application's data access patterns.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#solutions_4","title":"Solutions","text":"<ol> <li>Choose an Appropriate Eviction Policy:</li> <li> <p>Redis offers multiple eviction policies (<code>noeviction</code>, <code>allkeys-lru</code>, <code>volatile-lru</code>, <code>allkeys-lfu</code>, etc.). Choose one that matches your data access patterns. For instance:</p> <ul> <li>LRU (Least Recently Used): Removes least recently accessed keys, suitable for caching.</li> <li>LFU (Least Frequently Used): Removes keys that are less frequently accessed.</li> </ul> </li> <li> <p>Optimize Data Size:</p> </li> <li> <p>Reduce the memory footprint by optimizing data storage, such as using shorter key names or serializing data efficiently (e.g., storing integers directly rather than as strings).</p> </li> <li> <p>Monitor and Scale:</p> </li> <li> <p>Continuously monitor Redis memory usage with tools like Redis CLI or Redis Insights. If memory usage grows, consider horizontal scaling with Redis Cluster.</p> </li> <li> <p>Use Redis as a Pure Cache:</p> </li> <li>Configure Redis as a pure cache by setting appropriate TTLs on keys and using an eviction policy that maintains the most valuable data.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#126-slow-queries-and-latency-issues","title":"12.6. Slow Queries and Latency Issues","text":""},{"location":"techdives/DistrubutedSystems/Redis/#description_5","title":"Description","text":"<p>Redis is designed for fast access, but certain operations can cause high latency, especially when handling large datasets or complex commands like <code>ZRANGE</code> on large sorted sets.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#causes_5","title":"Causes","text":"<ul> <li>Large Data Sets: Operations on large data sets (e.g., large lists or sorted sets) can cause delays.</li> <li>Blocking Commands: Some commands may block Redis or consume excessive CPU time.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#solutions_5","title":"Solutions","text":"<ol> <li>Optimize Commands:</li> <li> <p>Avoid commands that can block or are computationally expensive. For example, break large list processing into smaller ranges instead of processing the entire list.</p> </li> <li> <p>Monitor Slow Queries:</p> </li> <li> <p>Use the Redis Slow Log to identify and optimize slow commands. Redis provides insights into commands that exceed a specified execution time threshold.</p> </li> <li> <p>Use Sharding or Clustering:</p> </li> <li>Split large datasets across multiple nodes in a Redis Cluster to balance the load and reduce the impact of slow commands on any single node.</li> </ol>"},{"location":"techdives/DistrubutedSystems/Redis/#13-tuning-redis","title":"13. Tuning Redis","text":"Metric Description Tuning Recommendations Commands/Tools Memory Usage Measures the memory consumed by Redis, including all data stored in memory. - Monitor and limit data size per key.  - Use appropriate eviction policies (<code>allkeys-lru</code>, <code>allkeys-lfu</code>, etc.). - Compress data (e.g., shorter key names). - Use Redis <code>MEMORY USAGE</code> to check memory footprint of specific keys. <code>INFO memory</code>, <code>MEMORY USAGE</code> CPU Utilization CPU load on the Redis server, indicating overall processing load. - Reduce CPU-intensive commands (<code>ZRANGE</code> on large sets, large <code>LRANGE</code> operations). - Offload tasks to background or batch processing if possible. - Use pipelining for batch operations. System tools (e.g., <code>top</code>), <code>INFO cpu</code> Cache Hit Ratio The ratio of cache hits to total cache requests (ideally close to 1). - Identify hot keys and cache them effectively. - Increase Redis memory if hit ratio is low due to evictions. - Ensure sufficient TTL to avoid frequent cache misses. <code>INFO stats</code> Evicted Keys Number of keys evicted due to memory limits. - Increase available memory if eviction is high. - Choose an appropriate eviction policy (<code>allkeys-lru</code>, <code>volatile-ttl</code>, etc.). - Adjust key TTLs to prevent frequent eviction of important data. <code>INFO memory</code> Connected Clients Number of clients connected to Redis at any given time. - Increase the <code>maxclients</code> configuration if reaching limits. - Use client-side caching to reduce load on Redis. <code>INFO clients</code>, <code>CLIENT LIST</code> Latency (Command Time) Measures the average response time per command in milliseconds. - Avoid using blocking or heavy commands on large data sets. - Distribute large data across a Redis Cluster. - Monitor slow log for commands that exceed expected time. <code>SLOWLOG GET</code>, <code>INFO commandstats</code> Command Rate Rate of commands per second, which affects overall performance. - Spread load across multiple Redis instances if command rate is high. - Use pipelining to reduce round-trips. - Optimize or reduce the frequency of unnecessary commands. <code>INFO stats</code> Key Expirations Number of keys that expire per second. - Add randomized TTLs to prevent cache avalanches. - Pre-warm critical keys to avoid sudden cache misses. - Monitor TTL settings to ensure balanced expiration. <code>INFO stats</code> Replication Lag Delay in data synchronization between master and replica nodes. - Tune <code>repl-backlog-size</code> for better sync reliability. - Monitor network latency and throughput between master and replica. - Use Redis Sentinel for reliable failover. <code>INFO replication</code>, <code>REPLCONF</code> Data Persistence Durability How frequently Redis saves data to disk (AOF/RDB). - Use RDB for infrequent snapshots; use AOF for higher durability. - Tune AOF rewrite frequency (<code>auto-aof-rewrite-percentage</code>). - Adjust RDB save intervals based on data criticality. <code>CONFIG SET save</code>, <code>CONFIG SET appendonly</code> Keyspace Misses Number of attempts to access non-existent keys. - Cache null values temporarily for non-existent keys to reduce misses. - Add input validation to filter invalid requests. - Use Bloom filters for non-existent keys in high-traffic systems. <code>INFO stats</code>, <code>MEMORY USAGE</code> Redis Slow Log Logs slow-running commands that exceed a threshold. - Use <code>SLOWLOG</code> to monitor commands that exceed time limits. - Adjust commands and optimize keys based on slow log findings. - Tune <code>slowlog-log-slower-than</code> to track performance bottlenecks. <code>SLOWLOG GET</code>, <code>SLOWLOG RESET</code> Network Bandwidth Measures bandwidth usage, impacting latency and speed. - Use Redis clustering to reduce network load on a single instance. - Enable pipelining and compression where possible. - Monitor and minimize network latency for high-frequency queries. System tools (e.g., <code>ifconfig</code>), <code>INFO</code> Eviction Policy Determines which keys Redis evicts first when memory limit is reached. - Choose policies based on use case (<code>allkeys-lru</code>, <code>allkeys-lfu</code> for caching, <code>volatile-ttl</code> for expiring keys first). - Regularly review and adjust TTLs for key eviction optimization. <code>CONFIG SET maxmemory-policy</code>, <code>INFO memory</code> Persistence Overhead Memory and CPU impact due to persistence settings (RDB or AOF). - Adjust <code>save</code> intervals or AOF rewriting to reduce persistence load. - Use a combination of AOF and RDB if the application requires high durability with performance. <code>INFO persistence</code>, <code>CONFIG SET save</code> Cluster Slot Utilization Measures how well data is balanced across Redis Cluster slots. - Rebalance slots if certain nodes handle disproportionate load. - Use Redis Cluster sharding to ensure balanced key distribution. - Regularly monitor slots and reshard as needed. <code>CLUSTER INFO</code>, <code>CLUSTER NODES</code>, <code>CLUSTER REBALANCE</code>"},{"location":"techdives/DistrubutedSystems/Redis/#14-best-practices","title":"14. Best Practices","text":"<p>To make the most of Redis:</p> <ul> <li>Data Modeling: Choose data structures based on the access patterns and data requirements. For example, use hashes for storing objects and lists for task queues.</li> <li>Memory Management: Monitor memory usage, and configure eviction policies (<code>LRU</code>, <code>LFU</code>, etc.) to manage memory limits. Redis provides a range of policies for automatically removing old keys.</li> <li>Backup Strategies: Regularly back up data using RDB snapshots or AOF persistence. This is crucial for recovery in case of data loss.</li> <li>Monitoring: Use Redis monitoring tools (e.g., Redis Insight, Prometheus) to observe performance metrics and set up alerts for potential issues, such as high latency or memory usage.</li> </ul>"},{"location":"techdives/DistrubutedSystems/Redis/#15-questions","title":"15. Questions","text":"<p>Here\u2019s a structured Q&amp;A-style deep dive into Redis to address all of these technical aspects.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#1-sql-or-nosql-if-nosql-what-type-of-nosql","title":"1. SQL or NoSQL? If NoSQL, what type of NoSQL?","text":"<p>Q: Is Redis an SQL or NoSQL database?</p> <p>A: Redis is a NoSQL database. Specifically, it is a key-value store that supports various data structures (e.g., strings, hashes, lists, sets, sorted sets, streams, bitmaps, and geospatial indexes).</p>"},{"location":"techdives/DistrubutedSystems/Redis/#2-type-of-db-supports-polymorphic","title":"2. Type of DB \u2026 Supports Polymorphic?","text":"<p>Q: What type of NoSQL database is Redis, and does it support polymorphism?</p> <p>A: Redis is a key-value in-memory data store with support for a variety of data structures. Redis does not natively support polymorphic types in the way that document-based NoSQL databases do, but you can achieve some level of polymorphism by encoding data in a structured way (e.g., JSON or hash maps).</p>"},{"location":"techdives/DistrubutedSystems/Redis/#3-main-feature-db-built-for-and-who-built-it-and-on-what","title":"3. Main Feature, DB Built For, and Who Built It and on What","text":"<p>Q: What was Redis built for, who built it, and what are its main features?</p> <p>A: Redis was initially created by Salvatore Sanfilippo as a high-performance in-memory database for use cases requiring low-latency, real-time data processing. Redis is built on C, and its main features include in-memory storage, data persistence, flexible data structures, and capabilities for caching, messaging, and real-time analytics.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#4-olap-or-oltp-does-it-support-acid-or-base","title":"4. OLAP or OLTP? Does it support ACID or BASE?","text":"<p>Q: Is Redis OLAP or OLTP, and does it adhere to ACID or BASE properties?</p> <p>A: Redis is generally used in OLTP (Online Transaction Processing) scenarios due to its low-latency and high-throughput design. Redis does not natively support full ACID properties but can achieve atomic operations within individual commands due to its single-threaded nature. It follows the BASE (Basically Available, Soft state, Eventual consistency) model.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#5-cap-theorem-where-does-redis-fall","title":"5. CAP Theorem \u2013 Where does Redis fall?","text":"<p>Q: How does Redis align with the CAP theorem, and what does each part (Consistency, Availability, Partition Tolerance) mean?</p> <p>A: Redis, especially in a clustered setup, adheres to the CP (Consistency and Partition Tolerance) model of the CAP theorem. In a non-clustered single-instance setup, Redis is highly consistent. However, in a clustered setup, it sacrifices some availability for consistency.</p> <ul> <li>Consistency: Ensures that every read receives the most recent write.</li> <li>Availability: Ensures every request receives a response, even if it\u2019s not the latest data.</li> <li>Partition Tolerance: The system continues to operate despite network partitions.</li> </ul> <p>Time Consistency in Redis can be achieved with strict persistence settings and synchronous replication.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#6-cluster-structure-from-cluster-to-records-the-whole-path","title":"6. Cluster Structure \u2013 From Cluster to Records, the Whole Path","text":"<p>Q: What is the structure of a Redis cluster from clusters down to individual records?</p> <p>A: A Redis cluster is organized as follows: - Cluster: Composed of multiple nodes. - Nodes: Each node is responsible for a subset of the keyspace, organized into hash slots (16,384 in total). - Shards: Each node represents a shard of the data and can replicate across replicas. - Keys/Records: Each key is hashed to a specific slot, determining the node responsible for storing it.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#7-the-fundamentals-of-a-cluster-all-building-blocks-from-cluster-to-records","title":"7. The Fundamentals of a Cluster \u2013 All Building Blocks from Cluster to Records","text":"<p>Q: What are the core building blocks of a Redis cluster?</p> <p>A: Core components include: - Nodes: Independent Redis instances in a cluster. - Hash Slots: Redis divides keys into 16,384 slots for distribution across nodes. - Replication: Each primary node can have replicas to ensure data redundancy. - Partitions (Shards): Each node holds a partition of data for horizontal scalability.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#8-multi-master-support","title":"8. Multi-Master Support","text":"<p>Q: Does Redis support multi-master configurations?</p> <p>A: Redis does not support multi-master configurations in its native setup. It uses a single-master architecture per shard to ensure consistency.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#9-master-slave-relationship-in-data-nodes","title":"9. Master-Slave Relationship in Data Nodes","text":"<p>Q: Does Redis follow a master-slave structure between data nodes?</p> <p>A: Yes, in a Redis cluster, each data shard has a single master with one or more replicas (slaves) for redundancy. The slaves serve as read-only replicas unless promoted during failover.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#10-node-structures-in-cluster","title":"10. Node Structures in Cluster","text":"<p>Q: What are the structures of nodes in a Redis cluster?</p> <p>A: In a Redis cluster, each node is responsible for a subset of hash slots, with a master node serving write requests and one or more replicas serving as failover or read-only instances.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#11-cluster-scaling-horizontal-and-vertical","title":"11. Cluster Scaling \u2013 Horizontal and Vertical","text":"<p>Q: Does Redis support horizontal and vertical scaling, and which is preferred?</p> <p>A: Redis supports horizontal scaling (adding more nodes) via sharding in a cluster, which is generally preferred. Vertical scaling (adding more memory/CPU) is also possible but limited by hardware.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#12-high-availability-explanation","title":"12. High Availability \u2013 Explanation","text":"<p>Q: How does Redis provide high availability?</p> <p>A: Redis achieves high availability through replication and Redis Sentinel for monitoring and automatic failover. Redis Cluster further enhances availability by automatically promoting replicas if a primary node fails.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#13-fault-tolerance-explanation","title":"13. Fault Tolerance \u2013 Explanation","text":"<p>Q: What mechanisms does Redis have for fault tolerance?</p> <p>A: Redis ensures fault tolerance through data replication across replicas, and Sentinel monitors the master nodes to trigger failover in case of node failure.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#14-replication","title":"14. Replication","text":"<p>Q: How does replication work in Redis?</p> <p>A: Redis replication is asynchronous by default, with each master node replicating data to one or more replicas. In the event of a master failure, a replica is promoted to master status.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#15-partitioning-and-sharding","title":"15. Partitioning and Sharding","text":"<p>Q: How does Redis handle partitioning and sharding?</p> <p>A: Redis uses hash-based partitioning with 16,384 hash slots to distribute data across nodes. Each key is assigned a hash slot, which maps it to a specific node.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#16-caching-in-depth","title":"16. Caching in Depth","text":"<p>Q: How does Redis perform caching?</p> <p>A: Redis is an in-memory cache, providing low-latency access with various caching strategies (e.g., TTL, eviction policies like LRU and LFU). It supports key expiration and eviction for memory management.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#17-storage-type-trees-used-for-storage","title":"17. Storage Type \u2013 Trees Used for Storage","text":"<p>Q: What storage type and structures does Redis use?</p> <p>A: Redis stores data in memory using simple data structures and does not use B-trees or similar structures. Data is kept in-memory and optionally persisted to disk (AOF/RDB).</p>"},{"location":"techdives/DistrubutedSystems/Redis/#18-segments-or-page-approach","title":"18. Segments or Page Approach?","text":"<p>Q: Does Redis use a segments approach, page approach, or something else?</p> <p>A: Redis does not use segments or page-based storage. Data is stored in-memory and is managed directly by the Redis process.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#19-indexing-how-does-it-work","title":"19. Indexing \u2013 How Does It Work?","text":"<p>Q: How does Redis handle indexing?</p> <p>A: Redis does not use traditional indexing. Instead, it directly maps keys to hash slots in the cluster, providing O(1) access time to each key.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#20-routing","title":"20. Routing","text":"<p>Q: How does Redis route requests to the correct node in a cluster?</p> <p>A: Redis routes requests based on key hashing. The key is hashed to determine its slot, which maps it to a specific node.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#21-latency-including-write-read-indexing-and-replication-latency","title":"21. Latency \u2013 Including Write, Read, Indexing, and Replication Latency","text":"<p>Q: What are Redis\u2019s latency characteristics?</p> <p>A: Redis provides sub-millisecond read/write latency under normal conditions. Replication latency is generally low, though network overhead may add some delay.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#22-versioning","title":"22. Versioning","text":"<p>Q: Does Redis support versioning?</p> <p>A: Redis does not natively support versioning. Application logic may be required to manage version control if needed.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#23-locking-and-concurrency","title":"23. Locking and Concurrency","text":"<p>Q: How does Redis handle locking and concurrency?</p> <p>A: Redis supports distributed locking through the Redlock algorithm for ensuring safe concurrent access across clients.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#24-write-ahead-logging-wal","title":"24. Write-Ahead Logging (WAL)","text":"<p>Q: Does Redis support WAL?</p> <p>A: Redis does not use WAL directly. However, the Append-Only File (AOF) is similar, logging each write operation to ensure persistence.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#25-change-data-capture-cdc-support","title":"25. Change Data Capture (CDC) Support","text":"<p>Q: Does Redis support CDC?</p> <p>A: Redis does not natively support Change Data Capture. External tools may be needed for real-time data change tracking.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#26-query-type-and-query-in-depth","title":"26. Query Type and Query in Depth","text":"<p>Q: What types of queries does Redis support?</p> <p>A: Redis is key-based and supports simple read/write commands without complex query languages. Operations include <code>GET</code>, <code>SET</code>, <code>HGET</code>, <code>ZADD</code>, etc.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#27-query-optimizers","title":"27. Query Optimizers","text":"<p>Q: Does Redis have query optimizers?</p> <p>A: Redis does not have traditional query optimizers, as it operates in O(1) for most key-based lookups.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#28-sql-support","title":"28. SQL Support","text":"<p>Q: Does Redis support SQL?</p> <p>A: Redis does not natively support SQL. However, RedisJSON or other libraries can provide SQL-like querying capabilities.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#29-circuit-breakers","title":"29. Circuit Breakers","text":"<p>Q:</p> <p>Does Redis have built-in circuit breaker support?</p> <p>A: Redis itself does not implement circuit breakers. This is typically handled at the application or middleware layer.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#30-data-retention-and-lifecycle-management","title":"30. Data Retention and Lifecycle Management","text":"<p>Q: How does Redis handle data lifecycle and retention?</p> <p>A: Redis supports TTL on keys, and policies like Least Recently Used (LRU) enable retention management. Redis doesn\u2019t support multi-tier storage.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#31-other-features","title":"31. Other Features","text":"<p>Q: What other features does Redis offer?</p> <p>A: Redis supports data structures like streams for event logging, pub/sub for messaging, and geospatial indexing for location-based queries.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#32-additional-modules","title":"32. Additional Modules","text":"<p>Q: What modules or libraries can be added to Redis?</p> <p>A: Redis offers modules like RedisJSON (for JSON handling), RedisGraph (for graph data), and RedisBloom (for probabilistic data structures).</p>"},{"location":"techdives/DistrubutedSystems/Redis/#33-optimization-and-tuning-of-clusters","title":"33. Optimization and Tuning of Clusters","text":"<p>Q: How do you optimize and tune Redis clusters?</p> <p>A: Key optimizations include appropriate partitioning, replication settings, eviction policies, and monitoring memory/CPU usage.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#34-backup-and-recovery","title":"34. Backup and Recovery","text":"<p>Q: How does Redis handle backup and recovery?</p> <p>A: Redis supports RDB snapshots and AOF for persistence. Backups are easily managed via AOF or manual RDB dumps.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#35-security","title":"35. Security","text":"<p>Q: What are Redis\u2019s security features?</p> <p>A: Redis supports authentication (AUTH command), SSL/TLS encryption, IP whitelisting, and role-based access control.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#36-migration","title":"36. Migration","text":"<p>Q: Does Redis support migration tools?</p> <p>A: Redis offers tools like redis-cli for basic migration, and Redis Enterprise provides more advanced migration capabilities.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#37-recommended-cluster-setup","title":"37. Recommended Cluster Setup","text":"<p>Q: What\u2019s the recommended Redis cluster setup?</p> <p>A: Typically, a Redis Cluster setup starts with 3 master nodes (for redundancy) and 3 replicas for high availability, totaling 6 nodes.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#38-basic-cluster-setup-with-node-numbers-in-distributed-mode","title":"38. Basic Cluster Setup with Node Numbers in Distributed Mode","text":"<p>Q: How does a basic Redis cluster setup look in distributed mode?</p> <p>A: A minimal Redis Cluster in distributed mode consists of 3 master nodes (handling 5,461 slots each) with 1 replica per master for redundancy.</p>"},{"location":"techdives/DistrubutedSystems/Redis/#39-segments-approach-or-page-approach-or-others","title":"39. Segments Approach or Page Approach or others","text":"<p>Q: Does Redis use a segments approach, page approach, or another storage approach?</p> <p>A: Redis does not use a segments or page-based approach as it is an in-memory database. Data is stored directly in memory with no fixed segment or page structure, allowing for rapid access to keys. Redis is optimized for speed, relying on data structures like hash tables and direct in-memory allocation rather than traditional on-disk segment or page methods common in disk-based databases.</p>"},{"location":"techdives/DistrubutedSystems/S3/","title":"Amazon S3 (Simple Storage Service)","text":""},{"location":"techdives/DistrubutedSystems/S3/#1-introduction","title":"1. Introduction","text":"<p>Amazon S3 is a scalable object storage service offered by Amazon Web Services (AWS). It is designed to store and retrieve any amount of data from anywhere on the web, making it suitable for various use cases, including data backup, archiving, big data analytics, and hosting static websites.</p>"},{"location":"techdives/DistrubutedSystems/S3/#2-architecture-and-fundamentals","title":"2. Architecture and Fundamentals","text":"<ul> <li>Objects: The fundamental unit of storage in S3, consisting of data (files) and metadata. Each object is stored in a bucket.</li> <li>Buckets: Containers for storing objects. Each bucket has a unique name across all AWS accounts.</li> <li>S3 utilizes a flat namespace with a unique key for each object. It appears hierarchical (using prefixes) but does not support directories or folders in the traditional sense.</li> <li>S3 provides regional endpoints to reduce latency and improve performance, allowing users to access data from the nearest geographical location.</li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#3-storage-classes","title":"3. Storage Classes","text":"<p>S3 offers a variety of storage classes optimized for different use cases, balancing cost and performance:</p> <ul> <li> <p>S3 Standard: For frequently accessed data, providing high durability and availability.</p> </li> <li> <p>S3 Intelligent-Tiering: Automatically moves data between two access tiers based on changing access patterns, optimizing costs.</p> </li> <li> <p>S3 Standard-IA (Infrequent Access): Lower-cost storage for infrequently accessed data with retrieval fees.</p> </li> <li> <p>S3 One Zone-IA: For infrequently accessed data that does not require multiple availability zone redundancy.</p> </li> <li> <p>S3 Glacier: For archival data, offering retrieval times from minutes to hours.</p> </li> <li> <p>S3 Glacier Deep Archive: The lowest-cost storage option for rarely accessed data, with retrieval times of 12 hours or more.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#data-retrieval-options","title":"Data Retrieval Options","text":"<ul> <li>Expedited: Fast retrieval, suitable for data that needs to be accessed quickly.</li> <li>Standard: Typical retrieval time of several hours.</li> <li>Bulk: Cost-effective for large-scale data retrieval, with a longer retrieval time.</li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#4-durability-availability-and-redundancy","title":"4. Durability, Availability and Redundancy","text":"<ul> <li> <p>Durability: S3 is designed for 99.999999999% (11 nines) durability, ensuring high protection against data loss by automatically storing data across multiple devices in multiple facilities within an AWS Region.</p> </li> <li> <p>Availability: S3 offers 99.99% availability over a given year, ensuring data accessibility when needed.</p> </li> <li> <p>Redundancy: Data is redundantly stored across multiple availability zones, providing resilience against failures.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#5-security-features","title":"5. Security Features","text":"<ul> <li> <p>Identity and Access Management (IAM): Provides fine-grained control over who can access S3 resources and what actions they can perform.</p> </li> <li> <p>Bucket Policies and ACLs: Define permissions at the bucket and object level, allowing public or private access as needed.</p> </li> <li> <p>Encryption: Supports both server-side and client-side encryption to protect data at rest. SSE options include:</p> <ul> <li>SSE-S3: Server-side encryption with S3-managed keys.</li> <li>SSE-KMS: Server-side encryption with AWS Key Management Service (KMS) keys.</li> <li>SSE-C: Server-side encryption with customer-provided keys.</li> </ul> </li> <li> <p>Data Transfer Security: Supports SSL/TLS for data in transit to protect data from interception.</p> </li> <li> <p>Access Logs: Enable server access logging to track requests for access to your S3 resources.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#6-data-management-and-lifecycle-policies","title":"6. Data Management and Lifecycle Policies","text":"<ul> <li> <p>Versioning: Keeps multiple versions of an object, allowing recovery from accidental deletions or overwrites.</p> </li> <li> <p>Lifecycle Management: Automatically transitions objects between storage classes or deletes objects based on defined rules.</p> </li> <li> <p>Event Notifications: Configure notifications for events like object creation or deletion, which can trigger AWS Lambda functions or send messages to Amazon SNS.</p> </li> <li> <p>Object Tags: Use object tagging for better organization and management, including cost allocation for various projects.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#7-performance-and-optimization","title":"7. Performance and Optimization","text":"<ul> <li> <p>Transfer Acceleration: Speeds up uploads and downloads using Amazon CloudFront's globally distributed edge locations.</p> </li> <li> <p>Multipart Upload: Enables the uploading of large objects in parts, improving performance and allowing resuming of uploads in case of network failures.</p> </li> <li> <p>Caching with CloudFront: Integrate with Amazon CloudFront for content delivery, reducing latency and improving performance for global users.</p> </li> <li> <p>Data Consistency: S3 provides strong read-after-write consistency for PUT and DELETE operations, ensuring that data is immediately available after a successful write.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#8-use-cases","title":"8. Use Cases","text":"<ul> <li> <p>Backup and Disaster Recovery: Store backups of critical data and applications to ensure business continuity.</p> </li> <li> <p>Data Lakes: Centralize diverse data sources for analytics and machine learning - OLAP</p> </li> <li> <p>Media Hosting: Store and serve images, videos, and other media files for web and mobile applications.</p> </li> <li> <p>Big Data Analytics: Use S3 to store large datasets for processing with services like Amazon Athena, Amazon EMR, or Amazon Redshift.</p> </li> <li> <p>Static Website Hosting: Serve static websites directly from S3, leveraging its high availability and durability.</p> </li> </ul>"},{"location":"techdives/DistrubutedSystems/S3/#9-best-practices","title":"9. Best Practices","text":"<ul> <li> <p>Organize Data: Use a consistent naming convention for buckets and objects to improve manageability.</p> </li> <li> <p>Monitor Usage: Utilize AWS CloudTrail and AWS CloudWatch to monitor S3 usage and access patterns.</p> </li> <li> <p>Optimize Costs: Regularly review storage classes and utilize lifecycle policies to manage data costs effectively.</p> </li> <li> <p>Implement Security Best Practices: Regularly audit permissions, enable logging, and implement encryption to secure data.</p> </li> <li> <p>Data Governance: Implement data governance strategies to comply with legal and regulatory requirements.</p> </li> </ul>"},{"location":"techdives/GeneralConcepts/git/","title":"Git","text":"<p>Version control is the cornerstone of modern software development, and Git stands as the most widely used version control system in the world. Whether you're a beginner or an experienced if you're a developer understanding Git is crucial for collaborative and individual projects alike. In this article, we'll take a deep dive into Git, covering everything from its basics to its advanced features, to equip you with the knowledge to master it and with a cheat sheet at the end.</p>"},{"location":"techdives/GeneralConcepts/git/#what-is-git","title":"What is Git ?","text":"<p>Git is a distributed version control system that tracks changes in files, enabling multiple developers to collaborate on a project effectively. Created in 2005 by Linus Torvalds, Git was initially designed for managing the Linux kernel's development. Today, it powers everything from small personal projects to massive enterprise software systems.</p> <p>Key features</p> <ul> <li>Distributed: Each user has a complete copy of the project history, ensuring no single point of failure.</li> <li>Fast: Optimized to handle large projects with efficiency.</li> <li>Flexible Branching and Merging: Enables seamless collaboration and experimentation.</li> <li>Data Integrity: Uses SHA-1 cryptographic hashes to ensure data accuracy.</li> <li>Open Source: Freely available and widely supported.</li> </ul>"},{"location":"techdives/GeneralConcepts/git/#installing-git","title":"Installing Git","text":"<p>Getting started with Git begins with installing it on your system. Here's how you can set it up based on your operating system:</p> MacwindowsLinux Use Homebrew to install Git<pre><code>brew install git\n</code></pre> <p>Download Git for Windows from git-scm.com and follow the installer instructions.</p> Install Git using your distribution's package manager<pre><code>sudo apt install git  # For Debian/Ubuntu\nsudo yum install git  # For CentOS/Red Hat\n</code></pre>"},{"location":"techdives/GeneralConcepts/git/#verify-installation","title":"Verify Installation","text":"To confirm Git is installed correctly, run<pre><code>git --version\n</code></pre>"},{"location":"techdives/GeneralConcepts/git/#initial-configuration","title":"Initial Configuration","text":"After installation, configure Git with your name, email, and preferred editor<pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\ngit config --global core.editor \"code\"  # Use VSCode or any editor\n</code></pre>"},{"location":"techdives/GeneralConcepts/git/#getting-started-with-git","title":"Getting Started with Git","text":""},{"location":"techdives/GeneralConcepts/git/#creating-a-new-repository","title":"Creating a New Repository","text":"<p>To start tracking changes in a project, initialize a repository <pre><code>git init\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#clone-an-existing-repository","title":"Clone an Existing Repository","text":"<p>To work on an existing project, clone its repository <pre><code>git clone &lt;repository-url&gt;\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#tracking-changes","title":"Tracking Changes","text":"<p>Stage Changes: Add files to the staging area <pre><code>git add &lt;file&gt;\n</code></pre></p> <p>Commit Changes: Save changes to the repository <pre><code>git commit -m \"&lt;Write a proper commit message&gt;\"\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#checking-repository-status","title":"Checking Repository Status","text":"<p>View the status of your working directory and staged files <pre><code>git status\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#viewing-commit-history","title":"Viewing Commit History","text":"<p>Review the project's history with <pre><code>git log\ngit log --oneline  # Concise view\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#working-with-branches","title":"Working with Branches","text":"<p>Git's branching system is one of its most powerful features. Branches allow you to work on different features or bug fixes without affecting the main codebase.</p>"},{"location":"techdives/GeneralConcepts/git/#creating-switching-branches","title":"Creating Switching Branches","text":"<p>Create a new branch <pre><code>git branch &lt;branch-name&gt;\n</code></pre> Switch to the branch <pre><code>git checkout &lt;branch-name&gt;\ngit switch &lt;branch-name&gt;  # New alternative\n</code></pre> Creating and Switching to the branch <pre><code>git checkout -b &lt;branch-name&gt;\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#merging-branches","title":"Merging Branches","text":"<p>To integrate changes from one branch into another <pre><code>git checkout main # replace main with custom branch\ngit merge &lt;branch-name&gt;\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#handling-merge-conflicts","title":"Handling Merge Conflicts","text":"<p>If Git detects conflicting changes, resolve them manually by editing the affected files. Then <pre><code>git add &lt;file&gt;\ngit commit\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#remote-repositories","title":"Remote Repositories","text":"<p>Remote repositories allow teams to collaborate effectively.</p>"},{"location":"techdives/GeneralConcepts/git/#adding-a-remote","title":"Adding a Remote","text":"<p>Link your local repository to a remote <pre><code>git remote add origin &lt;repository-url&gt;\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#pushing-changes","title":"Pushing Changes","text":"<p>Send your commits to the remote repository <pre><code>git push origin &lt;branch-name&gt;\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#pulling-updates","title":"Pulling Updates","text":"<p>Fetch and integrate changes from the remote repository <pre><code>git pull\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#removing-a-remote","title":"Removing a Remote","text":"<p>If needed, you can remove a remote <pre><code>git remote remove origin\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#advanced-git","title":"Advanced Git","text":""},{"location":"techdives/GeneralConcepts/git/#stashing-changes","title":"Stashing Changes","text":"<p>Temporarily save changes without committing <pre><code>git stash\n</code></pre> Retrieve them later with <pre><code>git stash apply\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#cherry-picking","title":"Cherry-Picking","text":"<p>Apply a specific commit from another branch <pre><code>git cherry-pick &lt;commit-hash&gt;\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#rebasing","title":"Rebasing","text":"<p>Rebase your branch onto another <pre><code>git rebase &lt;branch-name&gt;\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#amending-commits","title":"Amending Commits","text":"<p>Fix the last commit message or contents <pre><code>git commit --amend\n</code></pre></p>"},{"location":"techdives/GeneralConcepts/git/#understanding-git-internals","title":"Understanding Git Internals","text":"<p>Git operates by storing snapshots of your project at each commit, not deltas (differences). The key components of Git's internal storage include:</p> <ul> <li>Blobs: Store file contents.</li> <li>Trees: Represent directory structures.</li> <li>Commits: Point to a tree and reference parent commits.</li> <li>Tags: Reference specific commits.</li> </ul> <p>All data is stored in the <code>.git</code> directory.</p>"},{"location":"techdives/GeneralConcepts/git/#collaboration-workflows","title":"Collaboration Workflows","text":"<p>Teams often adopt workflows to streamline collaboration. Popular ones include:</p> <ul> <li>Uses branches like <code>main</code>, <code>develop</code>, <code>feature</code>, and <code>release</code> for structured development.</li> <li>Developers fork the repository, make changes, and submit pull requests.</li> <li>All changes are merged directly into the <code>main</code> branch, often behind feature flags.</li> </ul>"},{"location":"techdives/GeneralConcepts/git/#common-issues","title":"Common Issues","text":"<ul> <li>Detached HEAD: Fix by switching to a branch:   <pre><code>git switch &lt;branch-name&gt;\n</code></pre></li> </ul>"},{"location":"techdives/GeneralConcepts/git/#best-practices","title":"Best Practices","text":"<ul> <li>Commit often with meaningful messages.</li> <li>Avoid committing sensitive files by using <code>.gitignore</code>.</li> </ul>"},{"location":"techdives/GeneralConcepts/git/#git-cheat-sheet","title":"Git Cheat Sheet","text":"<p>Below are all the essential Git commands.</p> <p>Git Cheat Sheet</p> <pre><code># Git Commands Cheat Sheet\n\n# Configuration\ngit config --global user.name \"Your Name\"       # Set user name\ngit config --global user.email \"your.email@uth.com\" # Set user email\ngit config --global core.editor \"code\"         # Set default editor\ngit config --list                              # View current configuration\n\n# Repository Management\ngit init                                       # Initialize a new repository\ngit clone &lt;repository-url&gt;                     # Clone an existing repository\ngit remote add origin &lt;url&gt;                    # Add remote repository\ngit remote -v                                  # View remote repositories\ngit remote remove &lt;name&gt;                       # Remove a remote\n\n# Staging and Committing\ngit add &lt;file&gt;                                 # Stage specific file\ngit add .                                      # Stage all files\ngit status                                     # Check status of repository\ngit commit -m \"Message\"                        # Commit with message\ngit commit --amend                             # Amend the last commit\n\n# Branching\ngit branch                                     # List branches\ngit branch &lt;branch-name&gt;                       # Create a new branch\ngit checkout &lt;branch-name&gt;                     # Switch to a branch\ngit checkout -b &lt;branch-name&gt;                  # Create and Switch to a branch\ngit switch &lt;branch-name&gt;                       # Modern way to switch branches\ngit branch -d &lt;branch-name&gt;                    # Delete a branch\ngit branch -D &lt;branch-name&gt;                    # Force delete a branch\n\n# Merging\ngit merge &lt;branch-name&gt;                        # Merge a branch into the current branch\n\n# Pulling and Pushing\ngit pull                                       # Fetch and merge from remote repository\ngit pull origin &lt;branch-name&gt;                  # Pull specific branch\ngit push origin &lt;branch-name&gt;                  # Push to remote repository\ngit push --all                                 # Push all branches\ngit push --tags                                # Push tags to remote\n\n# Logs and History\ngit log                                        # View commit history\ngit log --oneline                              # View concise commit history\ngit log --graph                                # View graphical commit history\n\n# Undo Changes\ngit reset HEAD &lt;file&gt;                          # Unstage a file\ngit checkout -- &lt;file&gt;                         # Discard changes in working directory\ngit revert &lt;commit-hash&gt;                       # Undo a specific commit (safe)\ngit reset &lt;commit-hash&gt;                        # Reset to a specific commit (dangerous)\n\n# Stashing\ngit stash                                      # Stash changes\ngit stash list                                 # List stashes\ngit stash apply                                # Apply the last stash\ngit stash drop                                 # Remove the last stash\ngit stash clear                                # Clear all stashes\n\n# Rebasing\ngit rebase &lt;branch-name&gt;                       # Rebase current branch onto another\ngit rebase -i &lt;commit-hash&gt;                    # Interactive rebase\n\n# Tags\ngit tag &lt;tag-name&gt;                             # Create a tag\ngit tag -a &lt;tag-name&gt; -m \"Message\"             # Create an annotated tag\ngit tag -d &lt;tag-name&gt;                          # Delete a tag locally\ngit push origin &lt;tag-name&gt;                     # Push a specific tag\ngit push --tags                                # Push all tags\n\n# Collaboration\ngit fetch                                      # Fetch updates from remote\ngit pull                                       # Fetch and merge updates\ngit pull origin &lt;branch-name&gt;                  # Pull specific branch\ngit push                                       # Push changes to remote\ngit push origin &lt;branch-name&gt;                  # Push specific branch\n\n# Ignoring Files\necho \"filename\" &gt;&gt; .gitignore                  # Add file to .gitignore\ngit rm --cached &lt;file&gt;                         # Stop tracking a file\n\n# Viewing Changes\ngit diff                                       # View unstaged changes\ngit diff --staged                              # View staged changes\ngit diff &lt;commit-hash1&gt; &lt;commit-hash2&gt;         # Compare two commits\n\n# Cherry-Picking\ngit cherry-pick &lt;commit-hash&gt;                  # Apply a specific commit to the current branch\n\n# Aliases\ngit config --global alias.co checkout          # Alias for checkout\ngit config --global alias.br branch            # Alias for branch\ngit config --global alias.cm commit            # Alias for commit\n</code></pre>"}]}